---
title: "input_quality_manuscript"
author: "Erin Campbell & Lillianna Writer"
date: "7/20/2022"
output: html_document
---

```{r}
#read in data that has been mass exported via ELAN; add informative column names
library(tidyverse)
library(ggplot2)
single_column_with_names <- read_delim("/Volumes/pn-opus/VIHI/WorkingFiles/fake_VI_Aug24.txt", 
     delim = "\t", escape_double = FALSE, 
     trim_ws = TRUE,col_names = FALSE) %>%
  rename(tier=X1,
         participant=X2,
         onset_ms=X3,
         offset_ms=X4,
         duration=X5,
         utterance=X6,
         filename=X7,
         filepath=X8)

#wrangle data so that each utterance has a single row, all participant labels appear in a single column, all utterance transcriptions in a single column, xds annotations appear in a single column, all PI annotations appear in a single column)
try_wide <- pivot_wider(single_column_with_names, names_from = "tier", values_from = "utterance") %>%
  unite("xds", contains("xds@"), remove = TRUE, na.rm = TRUE) %>%
  unite("PI", contains("PI"), remove = TRUE, na.rm = TRUE) %>%
  unite("utterance", c("CHI","UC1","FA1", "FA2", "FA3","FA4","FA5", "FAE", "MA1", "MA2","MA3", "MC1", "FC1", "EE1"), remove = TRUE, na.rm = TRUE)

```


```{r}
### ADS/CDS proportion

#get number of counts per each xds type by file
CDS_proportion <- try_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(filename, xds) %>%
  summarise(counts=n())

#just wanna check how many utterances total
mega_total <- sum(CDS_proportion$counts)

#find total number of utterances per file
CDS_total_input_utterances <- try_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(filename) %>%
  summarise(total_utts=n())

#just checking that the number is the same bc i don't trust myself
mega_total2 <- sum(CDS_total_input_utterances$total_utts)

#breakdown by addressee all VI kids as a group
VI_group_props <- try_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(xds) %>%
  summarise(big_number=n())


#lets create a function to convert things into percents (I stole this obvi)
percent <- function(x, digits = 2, format = "f", ...) {      # Create user-defined function
  paste0(formatC(x * 100, format = format, digits = digits, ...), "%")
}

#and now a full table with number of utts per addressee category, totaly utts for that file, and what the percent of each cat comes out as for each kid
proportion_table <- left_join(CDS_proportion, CDS_total_input_utterances)%>%
  mutate(incidence_percent = percent(counts/total_utts))

#this is just the same as the group props but with percentages
VI_group_proportion_table <- VI_group_props %>%
  mutate(group_percent = percent(big_number/mega_total))


ggplot(CDS_proportion, aes(fill = xds, y=counts, x=filename)) +
  geom_bar(position="fill", stat="identity") +
  ggtitle("Proportion of Addressee by Recording") +
  xlab("Recording") + ylab ("Proportion, by number of utterances") +
  scale_fill_discrete(labels=c('Adult-directed', 'Both child and adult', 'Child-directed', 'Other', 'Pet-directed', 'Unsure')) + theme(axis.text.x = element_text(face="bold", color="#000000", size=9, angle=45))

#I need to rename filenames to something that's not the same as lab-internal subj num
```
```{r}
#Overall VI CDS/ADS proportion graph
ggplot(VI_group_proportion_table, aes(fill = xds, y= big_number, x = "")) +
  geom_bar(position = "stack", stat = "identity") + ggtitle("Proportion by Addressee in Speech heard by VI Children") +
  geom_text(aes(label=group_percent), position=position_stack(vjust=0.5)) +
  xlab("All VI children") + ylab ("Proportion, by number of utterances") +
  scale_fill_discrete(labels=c('Adult-directed', 'Both child and adult', 'Child-directed', 'Other', 'Pet-directed', 'Unsure'))
```

```{r}
#we will do the same as above with TD matches (gonna have to do some filtering)
#read in data that has been mass exported via ELAN; add informative column names
TD_single_column_with_names <- read_delim("/Volumes/pn-opus/VIHI/WorkingFiles/fake_TD_August24_no_sep.txt", 
     delim = "\t", escape_double = FALSE, 
     trim_ws = TRUE,col_names = FALSE) %>%
  rename(tier=X1,
         participant=X2,
         onset_ms=X3,
         offset_ms=X4,
         duration=X5,
         utterance=X6,
         filename=X7,
         filepath=X8)

#wrangle data so that each utterance has a single row, all participant labels appear in a single column, all utterance transcriptions in a single column, xds annotations appear in a single column, all PI annotations appear in a single column)
TD_wide_unfiltered <- pivot_wider(TD_single_column_with_names, names_from = "tier", values_from = "utterance") %>%
  unite("xds", contains("xds@"), remove = TRUE, na.rm = TRUE) %>%
  unite("PI", contains("PI"), remove = TRUE, na.rm = TRUE) %>%
  unite("utterance", c("CHI","UC1","UC2","UC3", "UC4", "UC5", "UC6","UC7", "FA1", "FA2", "FA3","FA4","FA5", "FAE", "MA1", "MA2","MA3", "MA4", "MA5", "MA6", "MC1", "MC2", "FC1", "EE1", "FC2", "FA6", "FA7", "FAE"), remove = TRUE, na.rm = TRUE)

  TD_wide <- filter(TD_wide_unfiltered, !filename  %in% c("TD_419_961.eaf", "TD_420_268.eaf", "TD_421_536.eaf", "TD_422_217.eaf", "TD_424_676.eaf", "TD_431_248.eaf", "TD_426_429.eaf", "TD_423_184.eaf", "TD_430_493.eaf", "TD_425_194.eaf", "TD_433_522.eaf", "TD_429_190.eaf", "TD_437_564.eaf", "TD_428_188.eaf", "TD_438_522.eaf", "TD_439_192.eaf", "TD_442_763.eaf", "TD_440_189.eaf", "TD_451_521.eaf", "TD_450_183.eaf", "TD_453_998.eaf", "TD_452_277.eaf", "TD_462_513.eaf", "TD_461_190.eaf", "TD_455_248.eaf", "TD_441_732.eaf", "TD_434_249.eaf", "TD_457_475.eaf", "TD_459_188.eaf", "TD_435_205.eaf", "TD_454_510.eaf"))
```

```{r}
TD_CDS_proportion <- TD_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(filename, xds) %>%
  summarise(counts=n())
```
```{r}
#just wanna check how many utterances total
TD_mega_total <- sum(TD_CDS_proportion$counts)

#find total number of utterances per file
TD_CDS_total_input_utterances <- TD_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(filename) %>%
  summarise(total_utts=n())

#just checking that the number is the same bc i don't trust myself
TD_mega_total2 <- sum(TD_CDS_total_input_utterances$total_utts)

#breakdown by addressee all TD kids as a group
TD_group_props <- TD_wide %>%
  filter(xds %in% c("C","A","B","P", "O", "U"))%>%
  group_by(xds) %>%
  summarise(big_number=n())


#and now a full table with number of utts per addressee category, totaly utts for that file, and what the percent of each cat comes out as for each kid
TD_proportion_table <- left_join(TD_CDS_proportion, TD_CDS_total_input_utterances)%>%
  mutate(incidence_percent = percent(counts/total_utts))

#this is just the same as the group props but with percentages
TD_group_proportion_table <- TD_group_props %>%
  mutate(group_percent = percent(big_number/TD_mega_total))


ggplot(TD_CDS_proportion, aes(fill = xds, y=counts, x=filename)) +
  geom_bar(position="fill", stat="identity") +
  ggtitle("Proportion of Addressee by Recording, TD") +
  xlab("Recording") + ylab ("Proportion, by number of utterances") +
  scale_fill_discrete(labels=c('Adult-directed', 'Both child and adult', 'Child-directed', 'Other', 'Pet-directed', 'Unsure')) + theme(axis.text.x = element_text(face="bold", color="#000000", size=7, angle=0, vjust = 1))

#I need to rename filenames to something that's not the same as lab-internal subj num
```
```{r cute-plot}
#Overall TD CDS/ADS proportion graph
ggplot(TD_group_proportion_table, aes(fill = xds, y= big_number, x = "")) +
  geom_bar(position = "stack", stat = "identity") + ggtitle("Proportion by Addressee in Speech heard by TD Children") +
  geom_text(aes(label=group_percent), position=position_stack(vjust=0.5)) +
  xlab("All TD children") + ylab ("Proportion, by number of utterances") +
  scale_fill_discrete(labels=c('Adult-directed', 'Both child and adult', 'Child-directed', 'Other', 'Pet-directed', 'Unsure'))
```

```{r}
#and then a z-test to compare proportions of CDS
TD_CDS <- as.numeric(TD_group_proportion_table[3, "big_number"])

VI_CDS <- as.numeric(VI_group_proportion_table[3, "big_number"])

CDS_compare <- prop.test(x=c(TD_CDS, VI_CDS), n=c(TD_mega_total, mega_total))
CDS_compare
```
```{r}
#and then a z-test to compare proportions of ADS
TD_ADS <- as.numeric(TD_group_proportion_table[1, "big_number"])

VI_ADS <- as.numeric(VI_group_proportion_table[1, "big_number"])

ADS_compare <- prop.test(x=c(TD_ADS, VI_ADS), n=c(TD_mega_total, mega_total))
ADS_compare
```
```{r}
#and then a z-test to compare proportions of ODS, thinking like electronic speech?
TD_ODS <- as.numeric(TD_group_proportion_table[4, "big_number"])

VI_ODS <- as.numeric(VI_group_proportion_table[4, "big_number"])

ODS_compare <- prop.test(x=c(TD_ODS, VI_ODS), n=c(TD_mega_total, mega_total))
ODS_compare
```
### Methods by Lilli
Procedure

Guardians of participating infants received a LENA wearable audio recorder (CITE) and vest. They were instructed to place the recorder in the vest on the day of their scheduled recording and put the vest on their child from the time they woke up until the recorder automatically shut off (excluding bath and nap times), approximately sixteen hours later. They were also instructed how to pause the recording at any time, but asked to keep these pauses to a minimum. Actual recording length ranged from RANGE (insert mean, SD). 

Processing
### I don't actually know how these are processed up front so I'll come back to this
Audio recordings were processed by LENA software (gives you an its? idk). Each recording was then run through an automated sampler that selected 15- non-overlapping 5-minute segments, randomly distributed across the duration of the file. The process output a codeable ELAN file (.eaf, CITE). Each segment consists of 2 core minutes of annotated time, with 2 minutes of listenable context marked out preceding the annotation clip and 1 minute of additional context following the annotation clip. Each file therefore contains 30 minutes of coded recording time and 75 minutes of total time listened (#isn't there one where that's not true??)  Because these segments were sampled randomly, and not on a high-volubility measure such as conversational turns or adult speech density, the amount of time with codeable speech input varied for each recording. Indeed, across participants (FIND A WAY TO DO MATH WITH # SEGMENTS THAT ARE SILENT) of the 2-minute coding segments contained no speech at all. 

Annotation

Trained annotators listened through each 2-minute segment plus its surrounding context and coded it using the Analyzing Child Language Experiences around the World (ACLEW) Daylong Audio Recording of Children's Linguistic Environments (DARCLE) annotation scheme (CITE). Prior to annotating lab data, annotators are trained on previously coded samples of child recordings and are required to reach 95% overall agreement with the gold standard version of the file for three different age ranges: 0-7 months, 8-18 months, and 19-36 months. For more information about this annotation scheme and the larger project, please see the ACLEW homepage (https://sites.google.com/view/aclewdid/home). Following the first pass, all files were checked by a highly-trained "superchecker" (second author on this paper, Lilli "Always Right" Righter) to ensure the consistency of annotations. (are we gonna do reliability? I don't want to lol)

This annotation scheme is designed to capture both utterances by the target child (henceforth referred to as CHI) and speech in the child's environment, including adults, other children, and pre-recorded electronic speech (e.g. toys, television, the radio). Using ELAN (CITE), annotators segment the duration of each utterance on a separate coding tier for each unique speaker (exceptions: all electronic speech is coded on the same tier, and some speakers who appear briefly in these files were not easily distinguishable from others by annotators naive to their identities, so they may be concatenated on the same tier). Speech by people other than the target child is transcribed using an adapted version of CHAT transcription style (CITE), dubbed minCHAT for the ACLEW project (CITE). Because the majority of target children in the project are pre-lexical or phonetically immature, CHI utterances are not transcribed. 

Each utterance is coded for additional linguistic properties from a set of pre-determined categories. CHI utterances are coded for vocal maturity, lexical status, and multi-word status. Vocal maturity classifies utterances into the following categories: laughing; crying; canonical syllables that contain a consonant-like and vowel-like sound component, including both babbling and identifiable words; non-canonical syllables, which do not contain both consonant and vowel portions, or which do not transition between them in a speech-like way; and unsure, when the vocalization type is unclear. Each vocalization that contains canonical syllables is then coded for lexical status, either containing an identifiable lexical item or not. Finally, each utterance with a lexical item is coded for multi-word status, whether or not it contains more than one unique word type.

Environmental speech is coded for the addressee of each utterance: speech directed to a child, whether or not it is directed to the target child; adult-directed speech; speech directed to both an adult and a child; speech directed to pets or other animals; unclear addressee; or speech directed towards a recipient that doesn't fit into another category (e.g. voice control of Siri or Alexa, speech to a metaphysical entity, or pre-recorded speech such as a television). 

Following ACLEW DARCLE style annotation, each file was converted into a CHAT file (CITE) to use the CLAN automated mean length of utterance (MLU) analysis for each speaker. This analysis finds the average number of morphemes per utterance, using the eng MOR grammar dictionary (CITE).

### Results

We compared the proportions of child-directed speech (CDS) and adult-directed speech (ADS) between the blind children and their sighted matches. Each proportion was calculated as the number of utterances produced by someone *other* than the target child (non-CHI utterances) tagged with a child or an adult addressee, respectively, out of the total number of non-CHI utterances for each sensory group. A two-sample test for equality of proportions revealed no significant difference in the overall proportions of CDS to blind children and CDS to sighted children (*X*^2=`r CDS_compare$statistic`, p=`r printp(CDS_compare$p.value)`, CDS-proportion~blind~=`r CDS_compare$estimate[[2]]`, CDS-proportion~sighted~=`r CDS_compare$estimate[[1]]`). Likewise, there was no difference between the proportion of ADS to blind or sighted children (*X*^2=`r ADS_compare$statistic`, p=`r printp(ADS_compare$p.value)`,  ADS-proportion~blind~=`r ADS_compare$estimate[[2]]`, ADS-proportion~sighted~=`r ADS_compare$estimate[[1]]`).



### random notes
decontextualized speech (not about the here and now)
-less decontextualized speech to blind kids
-how do we code this in VIHI?
less attention shifting? less social engagement? or less flexing of muscle where we learn things through linguistic information alone
