
@article{fenson1994,
	title = {Variability in {Early} {Communicative} {Development}},
	volume = {59},
	issn = {0037976X},
	doi = {10.2307/1166093},
	abstract = {Data from parent reports on 1,803 children–derived from a normative study of the MacArthur Communicative Development Inventories (CDIs)–are used to describe the typical course and the extent of variability in major features of communicative development between 8 and 30 months of age. The two instruments, one designed for 8-16-month-old infants, the other for 16-30-month-old toddlers, are both reliable and valid, confirming the value of parent reports that are based on contemporary behavior and a recognition format. Growth trends are described for children scoring at the 10th-, 25th-, 50th-, 75th-, and 90th-percentile levels on receptive and expressive vocabulary, actions and gestures, and a number of aspects of morphology and syntax. Extensive variability exists in the rate of lexical, gestural, and grammatical development. The wide variability across children in the time of onset and course of acquisition of these skills challenges the meaningfulness of the concept of the modal child. At the same time, moderate to high intercorrelations are found among the different skills both concurrently and predictively (across a 6-month period). Sex differences consistently favor females; however, these are very small, typically accounting for 1\%-2\% of the variance. The effects of SES and birth order are even smaller within this age range. The inventories offer objective criteria for defining typicality and exceptionality, and their cost effectiveness facilitates the aggregation of large data sets needed to address many issues of contemporary theoretical interest. The present data also offer unusually detailed information on the course of development of individual lexical, gestural, and grammatical items and features. Adaptations of the CDIs to other languages have opened new possibilities for cross-linguistic explorations of sequence, rate, and variability of communicative development.},
	number = {5},
	journal = {Monographs of the Society for Research in Child Development},
	author = {Fenson, Larry and Dale, Philip S. and Reznick, J. Steven and Bates, Elizabeth and Thal, Donna J. and Pethick, Stephen J. and Tomasello, Michael and Mervis, Carolyn B. and Stiles, Joan},
	year = {1994},
	pmid = {7845413},
	note = {Publisher: JSTOR},
	pages = {i},
}

@book{landau1985,
	address = {Cambridge, MA, US},
	series = {Language and experience:  {Evidence} from the blind child},
	title = {Language and experience:  {Evidence} from the blind child},
	isbn = {978-0-674-51025-8},
	shorttitle = {Language and experience},
	abstract = {We ask in this book how children learn which of the words in their language encode which of the meanings. We accept as self-evident that any explanation of this learning must take nonlinguistic experience as relevant: When children hear words spoken by adults, they also observe objects, scenes, and events. Yet the issues here are quite perplexing because, at least to first inspection, heard words seem to map only very inexactly onto the child's observations of objects, scenes, and events.  In light of such difficulties, we tried to get some insight into how the child constructs the right mappings between words and the world by examining a situation in which the opportunities to observe the world are diminished: the case of langauge learning by congenitally blind children.  There is an evidently unshakable tradition which asserts that the blind must in principle be defective in their learning—of language, of space, and more.  We shall document that these a priori opinions cannot survive confrontation with the reality of language learning in congenitally blind children. Blind learners not only learn the forms of language but their meanings as well; their speech cannot be characterized as replete with "verbalisms" (the clinical term for blind learners' putative use of certain words as "sound without meaning"). (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Harvard University Press},
	author = {Landau, Barbara and Gleitman, Lila R.},
	year = {1985},
	note = {Pages: xi, 250},
	keywords = {Blind, Congenital Disorders, Language Development},
	file = {Snapshot:/Users/eec35/Zotero/storage/LXWYNHJ8/1985-97756-000.html:text/html},
}

@article{andersen1993,
	title = {The impact of input: language acquisition in the visually impaired},
	volume = {13},
	issn = {0142-7237},
	shorttitle = {The impact of input},
	url = {https://doi.org/10.1177/014272379301303703},
	doi = {10.1177/014272379301303703},
	abstract = {Variation in language development between blind and sighted children may result from a diminution of experience or differences in linguistic input, or it may be a product of other factors. Researchers argue about the relative weighting of these. We examine this argument by reviewing data and findings from our studies of blind children's language and we evaluate the possible impact of input, both environmental and linguistic. We show that variation cannot be uniquely attributed to either of these, but find evidence that experiential input may influence some areas while linguistic input more strongly affects others. Moreover, there is a complex interaction between these. We also find independent adaptive strategies by the children, pointing to a plasticity in the acquisition process itself.},
	language = {en},
	number = {37},
	urldate = {2021-04-16},
	journal = {First Language},
	author = {Andersen, Elaine S. and Dunlea, Anne and Kekelis, Linda},
	month = feb,
	year = {1993},
	note = {tex.ids= andersen1993a
publisher: SAGE Publications Ltd},
	pages = {23--49},
	file = {SAGE PDF Full Text:/Users/eec35/Zotero/storage/BVKJDFN2/Andersen et al. - 1993 - The impact of input language acquisition in the v.pdf:application/pdf},
}

@article{kekelis1984,
	title = {Family {Communication} {Styles} and {Language} {Development}},
	volume = {78},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X8407800202},
	doi = {10.1177/0145482X8407800202},
	abstract = {This study examines the effects of visual impairment on parent/child interaction. Six children (aged 1 to 3 years) with varying degrees of vision were video-recorded in naturalistic interactions with their families. Results indicate that caregivers of the blind provide highly directive input, offer relatively few descriptions, and initiate a greater proportion of topics than their children, focusing almost exclusively on child-centered topics. The special needs of blind children (e.g., for locomotor stimulation) as well as the absence of visual cues from and to the child motivate many of these modifications. We propose alternative ways for families to engage in satisfying interactions with their blind children.},
	language = {en},
	number = {2},
	urldate = {2021-06-21},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Kekelis, Linda S. and Andersen, Elaine S.},
	month = feb,
	year = {1984},
	note = {Publisher: SAGE Publications Inc},
	pages = {54--65},
}

@article{hoff2002,
	title = {How children use input to acquire a lexicon},
	volume = {73},
	issn = {0009-3920},
	doi = {10.1111/1467-8624.00415},
	abstract = {The contributions of social processes and computational processes to early lexical development were evaluated. A re-analysis and review of previous research cast doubt on the sufficiency of social approaches to word learning. An empirical investigation of the relation of social-pragmatic and data-providing features of input to the productive vocabulary of sixty-three 2-year-old children revealed benefits of data provided in mother-child conversation, but no effects of social aspects of those conversations. The findings further revealed that the properties of data that benefit lexical development in 2-year-olds are quantity, lexical richness, and syntactic complexity. The nature of the computational mechanisms implied by these findings is discussed. An integrated account of the roles of social and computational processes to lexical development is proposed.},
	language = {eng},
	number = {2},
	journal = {Child Development},
	author = {Hoff, Erika and Naigles, Letitia},
	year = {2002},
	pmid = {11949900},
	keywords = {Child, Preschool, Female, Follow-Up Studies, Humans, Infant, Language Development, Male, Mother-Child Relations, Social Environment, Verbal Behavior, Verbal Learning, Vocabulary},
	pages = {418--433},
}

@article{dirks2020,
	title = {Talk with me! {Parental} linguistic input to toddlers with moderate hearing loss},
	volume = {47},
	issn = {0305-0009, 1469-7602},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/talk-with-me-parental-linguistic-input-to-toddlers-with-moderate-hearing-loss/B444170912B4A3AB5D1087CB16ABFF44},
	doi = {10.1017/S0305000919000667},
	abstract = {This study examined the quantity and quality of parental linguistic input to toddlers with moderate hearing loss (MHL) compared with toddlers with normal hearing (NH). The linguistic input to eighteen toddlers with MHL and twenty-four toddlers with NH was examined during a 10-minute free-play activity in their home environment. Results showed that toddlers with MHL were exposed to an equivalent amount of parental linguistic input compared to toddlers with NH. However, parents of toddlers with MHL used less high-level facilitative language techniques, used less mental state language, and used shorter utterances than parents of toddlers with NH. Quantity and quality measures of parental linguistic input were positively related to the expressive language abilities of toddlers with MHL.},
	language = {en},
	number = {1},
	urldate = {2022-08-24},
	journal = {Journal of Child Language},
	author = {Dirks, Evelien and Stevens, Angela and Kok, Sigrid and Frijns, Johan and Rieffe, Carolien},
	month = jan,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	keywords = {hearing loss, language development, parental linguistic input},
	pages = {186--204},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/BX8PAZ5P/Dirks et al. - 2020 - Talk with me! Parental linguistic input to toddler.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/L8S488TN/B444170912B4A3AB5D1087CB16ABFF44.html:text/html},
}

@article{yoshinaga-itano2020,
	title = {Early {Intervention}, {Parent} {Talk}, and {Pragmatic} {Language} in {Children} {With} {Hearing} {Loss}},
	volume = {146},
	issn = {0031-4005},
	url = {https://doi.org/10.1542/peds.2020-0242F},
	doi = {10.1542/peds.2020-0242F},
	abstract = {Pragmatic language skills form the foundation for conversational competence, whereas deficits in this area are associated with behavioral problems and low literacy skills. Children who are deaf or hard of hearing demonstrate significant delays in this critical area of language. Our purpose with this research was to identify variables associated with pragmatic language ability in children who are deaf or hard of hearing.This was a longitudinal study of 124 children with bilateral hearing loss between 4 and 7 years of age living in Colorado. As part of a comprehensive speech and language assessment, pragmatic language skills were evaluated annually by using the Pragmatics Checklist.The children’s pragmatic skills increased significantly with age. Higher levels of pragmatic language ability at 7 years of age were predicted by (1) meeting Early Hearing Detection and Intervention 1-3-6 guidelines (hearing screening by 1 month, identification of hearing loss by 3 months, and receiving intervention by 6 months of age), (2) greater quantity of parent talk, (3) higher nonverbal intelligence, (4) lesser degrees of hearing loss, and (5) higher maternal education.With the findings of this study, we underscore the importance of pediatricians and other health care professionals counseling parents about the value of adherence to the Early Hearing Detection and Intervention 1-3-6 guidelines with regard to intervention outcomes. The strong association between amount of child-directed parent talk in the first 4 years of life and pragmatic language outcomes at 7 years of age emphasizes the need for professionals to encourage parents to talk to their children as much as possible.},
	number = {Supplement\_3},
	urldate = {2022-08-24},
	journal = {Pediatrics},
	author = {Yoshinaga-Itano, Christine and Sedey, Allison L. and Mason, Craig A. and Wiggin, Mallene and Chung, Winnie},
	month = nov,
	year = {2020},
	pages = {S270--S277},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/PUXS9I6Q/Yoshinaga-Itano et al. - 2020 - Early Intervention, Parent Talk, and Pragmatic Lan.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/MFTYMEX2/Early-Intervention-Parent-Talk-and-Pragmatic.html:text/html},
}

@article{gilkerson2018,
	title = {Language {Experience} in the {Second} {Year} of {Life} and {Language} {Outcomes} in {Late} {Childhood}},
	volume = {142},
	issn = {0031-4005},
	url = {https://doi.org/10.1542/peds.2017-4276},
	doi = {10.1542/peds.2017-4276},
	abstract = {Quantity of talk and interaction in the home during early childhood is correlated with socioeconomic status (SES) and can be used to predict early language and cognitive outcomes. We tested the effectiveness of automated early language environment estimates for children 2 to 36 months old to predict cognitive and language skills 10 years later and examined effects for specific developmental age periods.Daylong audio recordings for 146 infants and toddlers were completed monthly for 6 months, and the total number of daily adult words and adult-child conversational turnswere automatically estimated with Language Environment Analysis software. Follow-up evaluations at 9 to 14 years of age included language and cognitive testing. Language exposure for 3 age groups was assessed: 2 to 17 months, 18 to 24 months, and ≥25 months. Pearson correlations and multiple linear regression analyses were conducted.Conversational turn counts at 18 to 24 months of age accounted for 14\% to 27\% of the variance in IQ, verbal comprehension, and receptive and/or expressive vocabulary scores 10 years later after controlling for SES. Adult word counts between 18 and 24 months were correlated with language outcomes but were considerably weakened after controlling for SES.These data support the hypothesis that early talk and interaction, particularly during the relatively narrow developmental window of 18 to 24 months of age, can be used to predict school-age language and cognitive outcomes. With these findings, we underscore the need for effective early intervention programs that support parents in creating an optimal early language learning environment in the home.},
	number = {4},
	urldate = {2022-08-24},
	journal = {Pediatrics},
	author = {Gilkerson, Jill and Richards, Jeffrey A. and Warren, Steven F. and Oller, D. Kimbrough and Russo, Rosemary and Vohr, Betty},
	month = oct,
	year = {2018},
	pages = {e20174276},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/CW2IWIEY/Gilkerson et al. - 2018 - Language Experience in the Second Year of Life and.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/6TU8J3WY/37424.html:text/html},
}

@article{rowe2008,
	title = {Child-directed speech: relation to socioeconomic status, knowledge of child development and child vocabulary skill*},
	volume = {35},
	issn = {1469-7602, 0305-0009},
	shorttitle = {Child-directed speech},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/childdirected-speech-relation-to-socioeconomic-status-knowledge-of-child-development-and-child-vocabulary-skill/9A6AE54D0489EECB7F665B04DC61D365},
	doi = {10.1017/S0305000907008343},
	abstract = {This study sought to determine why American parents from different socioeconomic backgrounds communicate in different ways with their children. Forty-seven parent–child dyads were videotaped engaging in naturalistic interactions in the home for ninety minutes at child age 2 ; 6. Transcripts of these interactions provided measures of child-directed speech. Children's vocabulary comprehension skills were measured using the Peabody Picture Vocabulary Test at 2 ; 6 and one year later at 3 ; 6. Results indicate that: (1) child-directed speech with toddlers aged 2 ; 6 predicts child vocabulary skill one year later, controlling for earlier toddler vocabulary skill; (2) child-directed speech relates to socioeconomic status as measured by income and education; and (3) the relation between socioeconomic status and child-directed speech is mediated by parental knowledge of child development. Potential mechanisms through which parental knowledge influences communicative behavior are discussed.},
	language = {en},
	number = {1},
	urldate = {2022-08-24},
	journal = {Journal of Child Language},
	author = {Rowe, Meredith L.},
	month = feb,
	year = {2008},
	note = {Publisher: Cambridge University Press},
	pages = {185--205},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/K29Y4MTK/Rowe - 2008 - Child-directed speech relation to socioeconomic s.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/9E737PLN/9A6AE54D0489EECB7F665B04DC61D365.html:text/html},
}

@article{ambrose2014,
	title = {Linguistic {Input}, {Electronic} {Media}, and {Communication} {Outcomes} of {Toddlers} {With} {Hearing} {Loss}},
	volume = {35},
	issn = {1538-4667},
	url = {https://journals.lww.com/ear-hearing/Fulltext/2014/03000/Linguistic_Input,_Electronic_Media,_and.1.aspx},
	doi = {10.1097/AUD.0b013e3182a76768},
	abstract = {Objectives: 
        The objectives of this study were to examine the quantity of adult words, adult–child conversational turns, and electronic media in the auditory environments of toddlers who are hard of hearing (HH) and to examine whether these factors contributed to variability in children’s communication outcomes.
        Design: 
        Participants were 28 children with mild to severe hearing loss. Full-day recordings of children’s auditory environments were collected within 6 months of their second birthdays by using Language ENvironment Analysis technology. The system analyzes full-day acoustic recordings, yielding estimates of the quantity of adult words, conversational turns, and electronic media exposure in the recordings. Children’s communication outcomes were assessed via the receptive and expressive scales of the Mullen Scales of Early Learning at 2 years of age and the Comprehensive Assessment of Spoken Language at 3 years of age.
        Results: 
        On average, the HH toddlers were exposed to approximately 1400 adult words per hour and participated in approximately 60 conversational turns per hour. An average of 8\% of each recording was classified as electronic media. However, there was considerable within-group variability on all three measures. Frequency of conversational turns, but not adult words, was positively associated with children’s communication outcomes at 2 and 3 years of age. Amount of electronic media exposure was negatively associated with 2-year-old receptive language abilities; however, regression results indicate that the relationship was fully mediated by the quantity of conversational turns.
        Conclusions: 
        HH toddlers who were engaged in more conversational turns demonstrated stronger linguistic outcomes than HH toddlers who were engaged in fewer conversational turns. The frequency of these interactions was found to be decreased in households with high rates of electronic media exposure. Optimal language-learning environments for HH toddlers include frequent linguistic interactions between parents and children. To support this goal, parents should be encouraged to reduce their children’s exposure to electronic media.},
	language = {en-US},
	number = {2},
	urldate = {2022-08-24},
	journal = {Ear and Hearing},
	author = {Ambrose, Sophie E. and VanDam, Mark and Moeller, Mary Pat},
	month = apr,
	year = {2014},
	pages = {139--147},
	file = {Accepted Version:/Users/eec35/Zotero/storage/IUCXTFFD/Ambrose et al. - 2014 - Linguistic Input, Electronic Media, and Communicat.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/MDPP4Z24/Linguistic_Input,_Electronic_Media,_and.1.html:text/html},
}

@inproceedings{ganek2016,
	address = {Umeå, Sweden},
	title = {The {Language} {ENvironment} {Analysis} ({LENA}) system: {A} literature review},
	shorttitle = {The {Language} {ENvironment} {Analysis} ({LENA}) system},
	url = {https://aclanthology.org/W16-6504},
	urldate = {2022-08-24},
	booktitle = {Proceedings of the joint workshop on {NLP} for {Computer} {Assisted} {Language} {Learning} and {NLP} for {Language} {Acquisition}},
	publisher = {LiU Electronic Press},
	author = {Ganek, Hillary and Eriks-Brophy, Alice},
	month = nov,
	year = {2016},
	pages = {24--32},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/Q7KWMP5J/Ganek and Eriks-Brophy - 2016 - The Language ENvironment Analysis (LENA) system A.pdf:application/pdf},
}

@article{macwhinney2018,
	title = {{CLAN} {Manual}},
	url = {https://talkbank.org/manuals/CLAN.pdf},
	doi = {10.21415/T5G10R},
	urldate = {2022-08-24},
	author = {MacWhinney, Brian},
	year = {2018},
	note = {Publisher: TalkBank},
	file = {MacWhinney - 2018 - CLAN Manual.pdf:/Users/eec35/Zotero/storage/Y2BLB8ID/MacWhinney - 2018 - CLAN Manual.pdf:application/pdf},
}

@article{soderstrom2021,
	title = {Developing a {Cross}-{Cultural} {Annotation} {System} and {MetaCorpus} for {Studying} {Infants}’ {Real} {World} {Language} {Experience}},
	volume = {7},
	issn = {2474-7394},
	url = {https://doi.org/10.1525/collabra.23445},
	doi = {10.1525/collabra.23445},
	abstract = {Recent issues around reproducibility, best practices, and cultural bias impact naturalistic observational approaches as much as experimental approaches, but there has been less focus on this area. Here, we present a new approach that leverages cross-laboratory collaborative, interdisciplinary efforts to examine important psychological questions. We illustrate this approach with a particular project that examines similarities and differences in children’s early experiences with language. This project develops a comprehensive start-to-finish analysis pipeline by developing a flexible and systematic annotation system, and implementing this system across a sampling from a “metacorpus” of audiorecordings of diverse language communities. This resource is publicly available for use, sensitive to cultural differences, and flexible to address a variety of research questions. It is also uniquely suited for use in the development of tools for automated analysis.},
	number = {1},
	urldate = {2022-08-24},
	journal = {Collabra: Psychology},
	author = {Soderstrom, Melanie and Casillas, Marisa and Bergelson, Elika and Rosemberg, Celia and Alam, Florencia and Warlaumont, Anne S. and Bunce, John},
	month = may,
	year = {2021},
	note = {tex.ids= soderstrom2021a},
	pages = {23445},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/E9KQKVLD/Soderstrom et al. - 2021 - Developing a Cross-Cultural Annotation System and .pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/QCHXUJ3N/Developing-a-Cross-Cultural-Annotation-System-and.html:text/html},
}

@article{macwhinney2019,
	title = {{CHAT} {Manual}},
	url = {https://talkbank.org/manuals/CHAT.pdf},
	doi = {10.21415/3MHN-0Z89},
	language = {en},
	urldate = {2022-08-24},
	author = {MacWhinney, Brian},
	year = {2019},
	note = {Publisher: TalkBank},
	file = {2019 - CHAT Manual.pdf:/Users/eec35/Zotero/storage/9FZEG3ZU/2019 - CHAT Manual.pdf:application/pdf},
}

@article{rowe2012,
	title = {A {Longitudinal} {Investigation} of the {Role} of {Quantity} and {Quality} of {Child}-{Directed} {Speech} in {Vocabulary} {Development}},
	volume = {83},
	issn = {1467-8624},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2012.01805.x},
	doi = {10.1111/j.1467-8624.2012.01805.x},
	abstract = {Quantity and quality of caregiver input was examined longitudinally in a sample of 50 parent–child dyads to determine which aspects of input contribute most to children’s vocabulary skill across early development. Measures of input gleaned from parent–child interactions at child ages 18, 30, and 42 months were examined in relation to children’s vocabulary skill on a standardized measure 1 year later (e.g., 30, 42, and 54 months). Results show that controlling for socioeconomic status, input quantity, and children’s previous vocabulary skill; using a diverse and sophisticated vocabulary with toddlers; and using decontextualized language (e.g., narrative) with preschoolers explains additional variation in later vocabulary ability. The differential effects of various aspects of the communicative environment at several points in early vocabulary development are discussed.},
	language = {en},
	number = {5},
	urldate = {2022-08-25},
	journal = {Child Development},
	author = {Rowe, Meredith L.},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8624.2012.01805.x},
	pages = {1762--1774},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/27799FS9/Rowe - 2012 - A Longitudinal Investigation of the Role of Quanti.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/RKR2LYRI/j.1467-8624.2012.01805.html:text/html},
}

@article{gergle2004,
	title = {Language {Efficiency} and {Visual} {Technology}: {Minimizing} {Collaborative} {Effort} with {Visual} {Information}},
	volume = {23},
	issn = {0261-927X},
	shorttitle = {Language {Efficiency} and {Visual} {Technology}},
	url = {https://doi.org/10.1177/0261927X04269589},
	doi = {10.1177/0261927X04269589},
	abstract = {When collaborators work on a physical task, seeing a common workspace transforms their language use and reduces their overall collaborative effort. This article shows how visual information can make communication more efficient. In an experiment, dyads collaborated on building a puzzle. They communicated without a shared visual space, using a shared space featuring immediately updated visual information, and using a shared space featuring delayed visual updating. Having the shared visual space helps collaborators understand the current state of their task and enables them to ground their conversations efficiently, as seen in the ways in which participants adapted their discourse processes to their level of shared visual information. These processes are associated with faster and better task performance. Delaying the visual update reduces benefits and degrades performance. The shared visual space is more useful when tasks are visually complex or when participants have no simple vocabulary for describing their environments.},
	language = {en},
	number = {4},
	urldate = {2022-08-25},
	journal = {Journal of Language and Social Psychology},
	author = {Gergle, Darren and Kraut, Robert E. and Fussell, Susan R.},
	month = dec,
	year = {2004},
	note = {Publisher: SAGE Publications Inc},
	keywords = {communication, collaboration, computer-supported collaborative work, discourse, shared visual space},
	pages = {491--517},
	file = {SAGE PDF Full Text:/Users/eec35/Zotero/storage/Z3WEMQZP/Gergle et al. - 2004 - Language Efficiency and Visual Technology Minimiz.pdf:application/pdf},
}

@book{kimball1975,
	address = {New York San Francisco London},
	title = {Syntax and semantics},
	isbn = {978-0-12-785423-6},
	language = {xxx},
	publisher = {Academic press, Harcourt Brace Jovanovich},
	author = {Kimball, John P. and Morgan, Jerry L. and Cole, Peter},
	year = {1975},
	file = {Grice-Logic.pdf:/Users/eec35/Zotero/storage/5UDQ4UQI/Grice-Logic.pdf:application/pdf},
}

@article{ostarek2019,
	title = {Sighted people’s language is not helpful for blind individuals’ acquisition of typical animal colors},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/44/21972},
	doi = {10.1073/pnas.1912302116},
	abstract = {How do you learn what things look like if you cannot see? Kim et al. (1) tackle this intriguing question by assessing knowledge about animal appearance in blind and sighted individuals. The authors evaluated 2 plausible hypotheses: The learn-from-description hypothesis that blind individuals learn directly from sighted people’s descriptions (e.g., “elephants are gray”) and the learn-from-kind hypothesis that blind people infer visual animal properties from knowledge they have about the animal’s taxonomic class (e.g., a crow is a bird and birds have feathers).

While group differences were observed for all visual properties, blindness had the largest effect on color knowledge: Only sighted participants consistently grouped animals with the same canonical color together. This striking difference between blind and sighted participants … 

[↵][1]1To whom correspondence may be addressed. Email: markus.ostarek\{at\}mpi.nl.

 [1]: \#xref-corresp-1-1},
	language = {en},
	number = {44},
	urldate = {2021-02-06},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ostarek, Markus and Paridon, Jeroen van and Montero-Melis, Guillermo},
	month = oct,
	year = {2019},
	pmid = {31615880},
	note = {Publisher: National Academy of Sciences
Section: Letter},
	pages = {21972--21973},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/F8PWMVR3/Ostarek et al. - 2019 - Sighted people’s language is not helpful for blind.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/796DGIEI/21972.html:text/html},
}

@article{jara-ettinger2021,
	title = {The social basis of referential communication: {Speakers} construct physical reference based on listeners’ expected visual search},
	issn = {1939-1471},
	shorttitle = {The social basis of referential communication},
	doi = {10.1037/rev0000345},
	abstract = {A foundational assumption of human communication is that speakers should say as much as necessary, but no more. Yet, people routinely produce redundant adjectives and their propensity to do so varies cross-linguistically. Here, we propose a computational theory, whereby speakers create referential expressions designed to facilitate listeners’ reference resolution, as they process words in real time. We present a computational model of our account, the Incremental Collaborative Efficiency (ICE) model, which generates referential expressions by considering listeners’ real-time incremental processing and reference identification. We apply the ICE framework to physical reference, showing that listeners construct expressions designed to minimize listeners’ expected visual search effort during online language processing. Our model captures a number of known effects in the literature, including cross-linguistic differences in speakers’ propensity to over-specify. Moreover, the ICE model predicts graded acceptability judgments with quantitative accuracy, systematically outperforming an alternative, brevity-based model. Our findings suggest that physical reference production is best understood as driven by a collaborative goal to help the listener identify the intended referent, rather than by an egocentric effort to minimize utterance length. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	journal = {Psychological Review},
	author = {Jara-Ettinger, Julian and Rubio-Fernandez, Paula},
	year = {2021},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Pragmatics, Communication, Social Cognition, Audiences, Computational Modeling, Visual Search},
	pages = {No Pagination Specified--No Pagination Specified},
	file = {Snapshot:/Users/eec35/Zotero/storage/VY84QYHX/2022-16904-001.html:text/html},
}

@article{hawkins2021,
	title = {The {Division} of {Labor} in {Communication}: {Speakers} {Help} {Listeners} {Account} for {Asymmetries} in {Visual} {Perspective}},
	volume = {45},
	issn = {1551-6709},
	shorttitle = {The {Division} of {Labor} in {Communication}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12926},
	doi = {10.1111/cogs.12926},
	abstract = {Recent debates over adults' theory of mind use have been fueled by surprising failures of perspective-taking in communication, suggesting that perspective-taking may be relatively effortful. Yet adults routinely engage in effortful processes when needed. How, then, should speakers and listeners allocate their resources to achieve successful communication? We begin with the observation that the shared goal of communication induces a natural division of labor: The resources one agent chooses to allocate toward perspective-taking should depend on their expectations about the other's allocation. We formalize this idea in a resource-rational model augmenting recent probabilistic weighting accounts with a mechanism for (costly) control over the degree of perspective-taking. In a series of simulations, we first derive an intermediate degree of perspective weighting as an optimal trade-off between expected costs and benefits of perspective-taking. We then present two behavioral experiments testing novel predictions of our model. In Experiment 1, we manipulated the presence or absence of occlusions in a director–matcher task. We found that speakers spontaneously modulated the informativeness of their descriptions to account for “known unknowns” in their partner's private view, reflecting a higher degree of speaker perspective-taking than previously acknowledged. In Experiment 2, we then compared the scripted utterances used by confederates in prior work with those produced in interactions with unscripted directors. We found that confederates were systematically less informative than listeners would initially expect given the presence of occlusions, but listeners used violations to adaptively make fewer errors over time. Taken together, our work suggests that people are not simply “mindblind”; they use contextually appropriate expectations to navigate the division of labor with their partner. We discuss how a resource-rational framework may provide a more deeply explanatory foundation for understanding flexible perspective-taking under processing constraints.},
	language = {en},
	number = {3},
	urldate = {2022-08-25},
	journal = {Cognitive Science},
	author = {Hawkins, Robert D. and Gweon, Hyowon and Goodman, Noah D.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12926},
	keywords = {Pragmatics, Communication, Resource rationality, Theory of mind},
	pages = {e12926},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/TXLY2MDT/Hawkins et al. - 2021 - The Division of Labor in Communication Speakers H.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/YA737ZH2/cogs.html:text/html},
}

@article{rubio-fernandez2019,
	title = {Overinformative {Speakers} {Are} {Cooperative}: {Revisiting} the {Gricean} {Maxim} of {Quantity}},
	volume = {43},
	issn = {1551-6709},
	shorttitle = {Overinformative {Speakers} {Are} {Cooperative}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12797},
	doi = {10.1111/cogs.12797},
	abstract = {A pragmatic account of referential communication is developed which presents an alternative to traditional Gricean accounts by focusing on cooperativeness and efficiency, rather than informativity. The results of four language-production experiments support the view that speakers can be cooperative when producing redundant adjectives, doing so more often when color modification could facilitate the listener's search for the referent in the visual display (Experiment 1a). By contrast, when the listener knew which shape was the target, speakers did not produce redundant color adjectives (Experiment 1b). English speakers used redundant color adjectives more often than Spanish speakers, suggesting that speakers are sensitive to the differential efficiency of prenominal and postnominal modification (Experiment 2). Speakers were also cooperative when using redundant size adjectives (Experiment 3). Overall, these results show how discriminability affects a speaker's choice of referential expression above and beyond considerations of informativity, supporting the view that redundant speakers can be cooperative.},
	language = {en},
	number = {11},
	urldate = {2022-08-25},
	journal = {Cognitive Science},
	author = {Rubio-Fernandez, Paula},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12797},
	keywords = {Audience design, Cooperativeness, Efficiency, Informativity, Redundancy, Referential communication},
	pages = {e12797},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/P3YX2B9S/Rubio-Fernandez - 2019 - Overinformative Speakers Are Cooperative Revisiti.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/WXLEZU6R/cogs.html:text/html},
}

@article{grigoroglou2016,
	title = {Are children flexible speakers? {Effects} of typicality and listener needs in children’s event descriptions},
	abstract = {Do children take into account their addressees’ needs in spontaneous production? Developmental evidence for speaker adjustments is mixed. Some studies show that children are often under-informative when communicating with ignorant addressees but other studies demonstrate successes in children’s ability to integrate another person’s perspective. We asked whether children adapt their event descriptions depending on (a) the typicality of event components, and (b) the listener’s visual access to the events. We found that children’s ability to use information about the listener’s visual perspective to make specific adjustments to event descriptions emerged only in highly interactive contexts, in which participants collaborated towards mutual goals.},
	language = {en},
	journal = {Cognitive Science},
	author = {Grigoroglou, Myrto and Edu, Udel and Papafragou, Anna},
	year = {2016},
	pages = {6},
	file = {Grigoroglou et al. - Are children flexible speakers Effects of typical.pdf:/Users/eec35/Zotero/storage/RNNMIXKN/Grigoroglou et al. - Are children flexible speakers Effects of typical.pdf:application/pdf},
}

@article{anderson2021,
	title = {Linking {Quality} and {Quantity} of {Parental} {Linguistic} {Input} to {Child} {Language} {Skills}: {A} {Meta}-{Analysis}},
	volume = {92},
	issn = {1467-8624},
	shorttitle = {Linking {Quality} and {Quantity} of {Parental} {Linguistic} {Input} to {Child} {Language} {Skills}},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13508},
	doi = {10.1111/cdev.13508},
	abstract = {This meta-analysis examined associations between the quantity and quality of parental linguistic input and children’s language. Pooled effect size for quality (i.e., vocabulary diversity and syntactic complexity; k = 35; N = 1,958; r = .33) was more robust than for quantity (i.e., number of words/tokens/utterances; k = 33; N = 1,411; r = .20) of linguistic input. For quality and quantity of parental linguistic input, effect sizes were stronger when input was observed in naturalistic contexts compared to free play tasks. For quality of parental linguistic input, effect sizes also increased as child age and observation length increased. Effect sizes were not moderated by socioeconomic status or child gender. Findings highlight parental linguistic input as a key environmental factor in children’s language skills.},
	language = {en},
	number = {2},
	urldate = {2022-09-07},
	journal = {Child Development},
	author = {Anderson, Nina J. and Graham, Susan A. and Prime, Heather and Jenkins, Jennifer M. and Madigan, Sheri},
	year = {2021},
	note = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.13508},
	pages = {484--501},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/G6J5766S/Anderson et al. - 2021 - Linking Quality and Quantity of Parental Linguisti.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/BBEESTS4/cdev.html:text/html},
}

@article{yurovsky2016,
	title = {Linguistic input is tuned to children’s developmental level},
	abstract = {Children rapidly learn a tremendous amount about language despite limitations imposed on them by their developing cognitive abilities. One possible explanation for this rapid learning is that caregivers tune the language they produce to these limitations, titrating the complexity of their speech to developmentally-appropriate levels. We test this hypothesis in a large-scale corpus analysis, measuring the contingency between parents’ and children’s speech over the ﬁrst 5 years. Our results support the linguistic tuning hypothesis, showing a high degree of mostly parent-led coordination early in development that decreases as children become more proﬁcient language learners and users.},
	language = {en},
	journal = {Cognitive Science},
	author = {Yurovsky, Daniel and Doyle, Gabriel and Frank, Michael C},
	year = {2016},
	pages = {6},
	file = {Yurovsky et al. - Linguistic input is tuned to children’s developmen.pdf:/Users/eec35/Zotero/storage/ENK6XPMY/Yurovsky et al. - Linguistic input is tuned to children’s developmen.pdf:application/pdf},
}

@article{rowe2020,
	title = {Analyzing input quality along three dimensions: interactive, linguistic, and conceptual},
	volume = {47},
	issn = {0305-0009, 1469-7602},
	shorttitle = {Analyzing input quality along three dimensions},
	url = {http://www.cambridge.org/core/journals/journal-of-child-language/article/analyzing-input-quality-along-three-dimensions-interactive-linguistic-and-conceptual/83C958963F3746EA109D54BD1B8E13A6},
	doi = {10.1017/S0305000919000655},
	abstract = {This paper provides an overview of the features of caregiver input that facilitate language learning across early childhood. We discuss three dimensions of input quality: interactive, linguistic, and conceptual. All three types of input features have been shown to predict children's language learning, though perhaps through somewhat different mechanisms. We argue that input best designed to promote language learning is interactionally supportive, linguistically adapted, and conceptually challenging for the child's age/level. Furthermore, input features interact across dimensions to promote learning. Some but not all qualities of input vary based on parent socioeconomic status, language, or culture, and contexts such as book-reading or pretend play generate uniquely facilitative input features. The review confirms that we know a great deal about the role of input quality in promoting children's development, but that there is much more to learn. Future research should examine input features across the boundaries of the dimensions distinguished here.},
	language = {en},
	number = {1},
	urldate = {2022-09-08},
	journal = {Journal of Child Language},
	author = {Rowe, Meredith L. and Snow, Catherine E.},
	month = jan,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	keywords = {caregiver input, conversational responsiveness, decontextualized language, extended discourse, linguistic complexity, semantic contingency},
	pages = {5--21},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/G8ZAQA6X/Rowe and Snow - 2020 - Analyzing input quality along three dimensions in.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/XEGFECUG/83C958963F3746EA109D54BD1B8E13A6.html:text/html},
}

@article{huttenlocher2010,
	title = {Sources of variability in children's language growth},
	volume = {61},
	issn = {1095-5623},
	doi = {10.1016/j.cogpsych.2010.08.002},
	abstract = {The present longitudinal study examines the role of caregiver speech in language development, especially syntactic development, using 47 parent-child pairs of diverse SES background from 14 to 46 months. We assess the diversity (variety) of words and syntactic structures produced by caregivers and children. We use lagged correlations to examine language growth and its relation to caregiver speech. Results show substantial individual differences among children, and indicate that diversity of earlier caregiver speech significantly predicts corresponding diversity in later child speech. For vocabulary, earlier child speech also predicts later caregiver speech, suggesting mutual influence. However, for syntax, earlier child speech does not significantly predict later caregiver speech, suggesting a causal flow from caregiver to child. Finally, demographic factors, notably SES, are related to language growth, and are, at least partially, mediated by differences in caregiver speech, showing the pervasive influence of caregiver speech on language growth.},
	language = {eng},
	number = {4},
	journal = {Cognitive Psychology},
	author = {Huttenlocher, Janellen and Waterfall, Heidi and Vasilyeva, Marina and Vevea, Jack and Hedges, Larry V.},
	month = dec,
	year = {2010},
	pmid = {20832781},
	pmcid = {PMC2981670},
	keywords = {Speech, Vocabulary, Infant, Female, Humans, Male, Language Development, Child, Preschool, Longitudinal Studies, Caregivers, Critical Period, Psychological},
	pages = {343--365},
	file = {Accepted Version:/Users/eec35/Zotero/storage/8TIT4ZRN/Huttenlocher et al. - 2010 - Sources of variability in children's language grow.pdf:application/pdf},
}

@article{goldstein2008,
	title = {Social feedback to infants' babbling facilitates rapid phonological learning},
	volume = {19},
	issn = {0956-7976},
	doi = {10.1111/j.1467-9280.2008.02117.x},
	abstract = {Infants' prelinguistic vocalizations are rarely considered relevant for communicative development. As a result, there are few studies of mechanisms underlying developmental changes in prelinguistic vocal production. Here we report the first evidence that caregivers' speech to babbling infants provides crucial, real-time guidance to the development of prelinguistic vocalizations. Mothers of 9.5-month-old infants were instructed to provide models of vocal production timed to be either contingent or noncontingent on their infants' babbling. Infants given contingent feedback rapidly restructured their babbling, incorporating phonological patterns from caregivers' speech, but infants given noncontingent feedback did not. The new vocalizations of the infants in the contingent condition shared phonological form but not phonetic content with their mothers' speech. Thus, prelinguistic infants learned new vocal forms by discovering phonological patterns in their mothers' contingent speech and then generalizing from these patterns.},
	language = {eng},
	number = {5},
	journal = {Psychological Science},
	author = {Goldstein, Michael H. and Schwade, Jennifer A.},
	month = may,
	year = {2008},
	pmid = {18466414},
	keywords = {Infant, Female, Humans, Language Development, Phonetics, Speech Perception, Verbal Learning, Mothers, Social Behavior, Imitative Behavior, Infant Behavior, Feedback, Psychological, Maternal Behavior, Speech Acoustics},
	pages = {515--523},
}

@article{donnellan2020,
	title = {Infants' intentionally communicative vocalizations elicit responses from caregivers and are the best predictors of the transition to language: {A} longitudinal investigation of infants' vocalizations, gestures and word production},
	volume = {23},
	issn = {1467-7687},
	shorttitle = {Infants' intentionally communicative vocalizations elicit responses from caregivers and are the best predictors of the transition to language},
	doi = {10.1111/desc.12843},
	abstract = {What aspects of infants' prelinguistic communication are most valuable for learning to speak, and why? We test whether early vocalizations and gestures drive the transition to word use because, in addition to indicating motoric readiness, they (a) are early instances of intentional communication and (b) elicit verbal responses from caregivers. In study 1, 11 month olds (N = 134) were observed to coordinate vocalizations and gestures with gaze to their caregiver's face at above chance rates, indicating that they are plausibly intentionally communicative. Study 2 tested whether those infant communicative acts that were gaze-coordinated best predicted later expressive vocabulary. We report a novel procedure for predicting vocabulary via multi-model inference over a comprehensive set of infant behaviours produced at 11 and 12 months (n = 58). This makes it possible to establish the relative predictive value of different behaviours that are hierarchically organized by level of granularity. Gaze-coordinated vocalizations were the most valuable predictors of expressive vocabulary size up to 24 months. Study 3 established that caregivers were more likely to respond to gaze-coordinated behaviours. Moreover, the dyadic combination of infant gaze-coordinated vocalization and caregiver response was by far the best predictor of later vocabulary size. We conclude that practice with prelinguistic intentional communication facilitates the leap to symbol use. Learning is optimized when caregivers respond to intentional vocalizations with appropriate language.},
	language = {eng},
	number = {1},
	journal = {Developmental Science},
	author = {Donnellan, Ed and Bannard, Colin and McGillion, Michelle L. and Slocombe, Katie E. and Matthews, Danielle},
	month = jan,
	year = {2020},
	pmid = {31045301},
	keywords = {Language, Vocabulary, Infant, Female, Humans, Male, social communication, Lexicon, Language Development, Communication, Caregivers, Gestures, infancy, learning, Infant Behavior, Fixation, Ocular, parenting},
	pages = {e12843},
	file = {Accepted Version:/Users/eec35/Zotero/storage/LUK8QRHS/Donnellan et al. - 2020 - Infants' intentionally communicative vocalizations.pdf:application/pdf},
}

@article{romeo2018,
	title = {Beyond the 30-{Million}-{Word} {Gap}: {Children}'s {Conversational} {Exposure} {Is} {Associated} {With} {Language}-{Related} {Brain} {Function}},
	volume = {29},
	issn = {1467-9280},
	shorttitle = {Beyond the 30-{Million}-{Word} {Gap}},
	doi = {10.1177/0956797617742725},
	abstract = {Children's early language exposure impacts their later linguistic skills, cognitive abilities, and academic achievement, and large disparities in language exposure are associated with family socioeconomic status (SES). However, there is little evidence about the neural mechanisms underlying the relation between language experience and linguistic and cognitive development. Here, language experience was measured from home audio recordings of 36 SES-diverse 4- to 6-year-old children. During a story-listening functional MRI task, children who had experienced more conversational turns with adults-independently of SES, IQ, and adult-child utterances alone-exhibited greater left inferior frontal (Broca's area) activation, which significantly explained the relation between children's language exposure and verbal skill. This is the first evidence directly relating children's language environments with neural language processing, specifying both an environmental and a neural mechanism underlying SES disparities in children's language skills. Furthermore, results suggest that conversational experience impacts neural language processing over and above SES or the sheer quantity of words heard.},
	language = {eng},
	number = {5},
	journal = {Psychological Science},
	author = {Romeo, Rachel R. and Leonard, Julia A. and Robinson, Sydney T. and West, Martin R. and Mackey, Allyson P. and Rowe, Meredith L. and Gabrieli, John D. E.},
	month = may,
	year = {2018},
	pmid = {29442613},
	pmcid = {PMC5945324},
	keywords = {language, Language, LENA, Child, Female, Humans, Male, fMRI, Language Development, Brain Mapping, Child, Preschool, Social Environment, Magnetic Resonance Imaging, open data, open materials, Broca Area, Interpersonal Relations, Social Class, socioeconomic status, turn taking},
	pages = {700--710},
	file = {Full Text:/Users/eec35/Zotero/storage/AYMA8CVP/Romeo et al. - 2018 - Beyond the 30-Million-Word Gap Children's Convers.pdf:application/pdf},
}

@article{roseberry2014,
	title = {Skype me! {Socially} contingent interactions help toddlers learn language},
	volume = {85},
	issn = {1467-8624},
	doi = {10.1111/cdev.12166},
	abstract = {Language learning takes place in the context of social interactions, yet the mechanisms that render social interactions useful for learning language remain unclear. This study focuses on whether social contingency might support word learning. Toddlers aged 24-30 months (N = 36) were exposed to novel verbs in one of three conditions: live interaction training, socially contingent video training over video chat, and noncontingent video training (yoked video). Results suggest that children only learned novel verbs in socially contingent interactions (live interactions and video chat). This study highlights the importance of social contingency in interactions for language learning and informs the literature on learning through screen media as the first study to examine word learning through video chat technology.},
	language = {eng},
	number = {3},
	journal = {Child Development},
	author = {Roseberry, Sarah and Hirsh-Pasek, Kathy and Golinkoff, Roberta M.},
	year = {2014},
	pmid = {24112079},
	pmcid = {PMC3962808},
	keywords = {Child, Preschool, Female, Humans, Interpersonal Relations, Language Development, Learning, Male, Random Allocation, Video Recording, Videoconferencing},
	pages = {956--970},
	file = {Accepted Version:/Users/eec35/Zotero/storage/A6JQ4UGU/Roseberry et al. - 2014 - Skype me! Socially contingent interactions help to.pdf:application/pdf},
}

@article{bernsteinratner1984,
	title = {Patterns of vowel modification in mother–child speech},
	volume = {11},
	issn = {1469-7602},
	abstract = {Analyzed patterns of vowel articulation in conversational speech to an adult and to child listeners in the speech of 9 mothers. The sample contained 3 mothers with daughters who were preverbal but above 9 mo of age, 3 mothers with daughters who had holophrastic stage language, and 3 mothers with daughters having mean length of utterances between 2.0 and 3.5. Formant frequency analysis of vowels embedded in 2,406 words found in varying syntactic environments and uttered by Ss to preverbal, holophrastic, and more advanced child listeners revealed an emerging pattern of content word clarification, as measured by a wider dispersion and decreased overlap between vowel phoneme categories in formant characteristics. Additionally, function word clarification was noted in speech to the oldest children. It is suggested that vowel production is modulated by child-addressee language ability. Earlier studies suggesting a lack of phonetic clarification in mother–child speech may have investigated speech to children too mature to elicit maternal clarification behaviors. (26 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Child Language},
	author = {Bernstein Ratner, Nan},
	year = {1984},
	note = {Place: United Kingdom
Publisher: Cambridge University Press},
	keywords = {Conversation, Language Development, Vowels, Mothers, Mother Child Communication, Articulation (Speech), Developmental Stages},
	pages = {557--578},
	file = {Snapshot:/Users/eec35/Zotero/storage/QGXETMEF/1985-09153-001.html:text/html},
}

@article{chiesa2015,
	title = {Communicative interactions between visually impaired mothers and their sighted children: analysis of gaze, facial expressions, voice and physical contacts},
	volume = {41},
	issn = {1365-2214},
	shorttitle = {Communicative interactions between visually impaired mothers and their sighted children},
	doi = {10.1111/cch.12274},
	abstract = {BACKGROUND: Social and emotional development of infants and young children is largely based on the communicative interaction with their mother, or principal caretaker (Trevarthen ). The main modalities implied in this early communication are voice, facial expressions and gaze (Stern ). This study aims at analysing early mother-child interactions in the case of visually impaired mothers who do not have access to their children's gaze and facial expressions.
METHODS: Spontaneous play interactions between seven visually impaired mothers and their sighted children aged between 6 months and 3 years were filmed. These dyads were compared with a control group of sighted mothers and children analysing four modalities of communication and interaction regulation: gaze, physical contacts, verbal productions and facial expressions.
RESULTS: The visually impaired mothers' facial expressions differed from the ones of sighted mothers mainly with respect to forehead movements, leading to an impoverishment of conveyed meaning. Regarding the other communicative modalities, results suggest that visually impaired mothers and their children use compensatory strategies to guaranty harmonic interaction despite the mother's impairment: whereas gaze results the main factor of interaction regulation in sighted dyads, physical contacts and verbal productions assume a prevalent role in dyads with visually impaired mothers. Moreover, visually impaired mother's children seem to be able to differentiate between their mother and sighted interaction partners, adapting differential modes of communication.
CONCLUSIONS: The results of this study show that, in spite of the obvious differences in the modes of communication, visual impairment does not prevent a harmonious interaction with the child.},
	language = {eng},
	number = {6},
	journal = {Child: Care, Health and Development},
	author = {Chiesa, S. and Galati, D. and Schmidt, S.},
	month = nov,
	year = {2015},
	pmid = {26250608},
	keywords = {Child Development, Infant, Female, Humans, Male, communication skills, joint attention, social development, Child, Preschool, Communication, Visually Impaired Persons, Mother-Child Relations, Mothers, Facial Expression, mother-child interaction, visually impaired mothers},
	pages = {1040--1046},
	file = {Submitted Version:/Users/eec35/Zotero/storage/K289D46I/Chiesa et al. - 2015 - Communicative interactions between visually impair.pdf:application/pdf},
}

@article{senju2013,
	title = {The importance of the eyes: communication skills in infants of blind parents},
	volume = {280},
	issn = {1471-2954},
	shorttitle = {The importance of the eyes},
	doi = {10.1098/rspb.2013.0436},
	abstract = {The effects of selectively different experience of eye contact and gaze behaviour on the early development of five sighted infants of blind parents were investigated. Infants were assessed longitudinally at 6-10, 12-15 and 24-47 months. Face scanning and gaze following were assessed using eye tracking. In addition, established measures of autistic-like behaviours and standardized tests of cognitive, motor and linguistic development, as well as observations of naturalistic parent-child interaction were collected. These data were compared with those obtained from a larger group of sighted infants of sighted parents. Infants with blind parents did not show an overall decrease in eye contact or gaze following when they observed sighted adults on video or in live interactions, nor did they show any autistic-like behaviours. However, they directed their own eye gaze somewhat less frequently towards their blind mothers and also showed improved performance in visual memory and attention at younger ages. Being reared with significantly reduced experience of eye contact and gaze behaviour does not preclude sighted infants from developing typical gaze processing and other social-communication skills. Indeed, the need to switch between different types of communication strategy may actually enhance other skills during development.},
	language = {eng},
	number = {1760},
	journal = {Proceedings. Biological Sciences},
	author = {Senju, Atsushi and Tucker, Leslie and Pasco, Greg and Hudry, Kristelle and Elsabbagh, Mayada and Charman, Tony and Johnson, Mark H.},
	month = jun,
	year = {2013},
	pmid = {23576790},
	pmcid = {PMC3652463},
	keywords = {Child Development, Infant, Female, Humans, Male, Child, Preschool, Parents, Communication, Longitudinal Studies, Visually Impaired Persons, Parent-Child Relations, Eye Movements, Interpersonal Relations, Face},
	pages = {20130436},
	file = {Full Text:/Users/eec35/Zotero/storage/MDBNJE2V/Senju et al. - 2013 - The importance of the eyes communication skills i.pdf:application/pdf},
}

@article{ganea2018,
	title = {Development of adaptive communication skills in infants of blind parents},
	volume = {54},
	issn = {1939-0599},
	doi = {10.1037/dev0000564},
	abstract = {A fundamental question about the development of communication behavior in early life is how infants acquire adaptive communication behavior that is well-suited to their individual social environment, and how the experience of parent-child communication affects this development. The current study investigated how infants develop communication skills when their parents are visually impaired and cannot see their infants' eye gaze. We analyzed 6-min video recordings of naturalistic interaction between 14 sighted infants of blind parents (SIBP) with (a) their blind parent, and (b) a sighted experimenter. Data coded from these interactions were compared with those from 28 age-matched sighted infants of sighted parents (controls). Each infant completed two visits, at 6-10 months and 12-16 months of age. Within each interaction sample, we coded the function (initiation or response) and form (face gaze, vocalization, or action) of each infant communication behavior. When interacting with their parents, SIBP made relatively more communicative responses than initiations, and used more face gaze and fewer actions to communicate, than did controls. When interacting with a sighted experimenter, by contrast, SIBP made slightly (but significantly) more communicative initiations than controls, but otherwise used similar forms of communication. The differential communication behavior by infants of blind versus sighted parents was already apparent by 6-10 months of age, and was specific to communication with the parent. These results highlight the flexibility in the early development of human communication behavior, which enables infants to optimize their communicative bids and methods to their unique social environment. (PsycINFO Database Record (c) 2018 APA, all rights reserved).},
	language = {eng},
	number = {12},
	journal = {Developmental Psychology},
	author = {Ganea, Nataşa and Hudry, Kristelle and Vernetti, Angélina and Tucker, Leslie and Charman, Tony and Johnson, Mark H. and Senju, Atsushi},
	month = dec,
	year = {2018},
	pmid = {30335435},
	pmcid = {PMC6254470},
	keywords = {Child Development, Blindness, Infant, Female, Humans, Male, Follow-Up Studies, Verbal Behavior, Parent-Child Relations, Nonverbal Communication, Fixation, Ocular, Interpersonal Relations, Child of Impaired Parents},
	pages = {2265--2273},
	file = {Full Text:/Users/eec35/Zotero/storage/KWDN7XVK/Ganea et al. - 2018 - Development of adaptive communication skills in in.pdf:application/pdf},
}

@article{hirsh-pasek2015,
	title = {The {Contribution} of {Early} {Communication} {Quality} to {Low}-{Income} {Children}'s {Language} {Success}},
	volume = {26},
	issn = {1467-9280},
	doi = {10.1177/0956797615581493},
	abstract = {The disparity in the amount and quality of language that low-income children hear relative to their more-affluent peers is often referred to as the 30-million-word gap. Here, we expand the literature about this disparity by reporting the relative contributions of the quality of early parent-child communication and the quantity of language input in 60 low-income families. Including both successful and struggling language learners from the National Institute of Child Health and Human Development Study of Early Child Care and Youth Development, we noted wide variation in the quality of nonverbal and verbal interactions (symbol-infused joint engagement, routines and rituals, fluent and connected communication) at 24 months, which accounted for 27\% of the variance in expressive language 1 year later. These indicators of quality were considerably more potent predictors of later language ability than was the quantity of mothers' words during the interaction or sensitive parenting. Bridging the word gap requires attention to how caregivers and children establish a communication foundation within low-income families.},
	language = {eng},
	number = {7},
	journal = {Psychological Science},
	author = {Hirsh-Pasek, Kathy and Adamson, Lauren B. and Bakeman, Roger and Owen, Margaret Tresch and Golinkoff, Roberta Michnick and Pace, Amy and Yust, Paula K. S. and Suma, Katharine},
	month = jul,
	year = {2015},
	pmid = {26048887},
	keywords = {Vocabulary, language development, Child, Infant, Female, Humans, Male, social interaction, Adult, Child, Preschool, Communication, Child Language, Psycholinguistics, Parenting, Mother-Child Relations, Interpersonal Relations, Poverty, psycholinguistics, relationship quality},
	pages = {1071--1083},
}

@article{huttenlocher1991,
	title = {Early vocabulary growth: {Relation} to language input and gender},
	volume = {27},
	issn = {1939-0599},
	shorttitle = {Early vocabulary growth},
	doi = {10.1037/0012-1649.27.2.236},
	abstract = {Examines the role of exposure to speech in children's early vocabulary growth. It is generally assumed that individual differences in vocabulary depend, in large part, on variations in learning capacity. However, variations in exposure have not been systematically explored. In this study vocabulary growth rates are characterized for each of 22 children by using data obtained at several time points from 14 to 26 mo. A substantial relation between individual differences in vocabulary acquisition and variations in the amount that particular mothers speak to their children was found. It is argued that the relation between amount of parent speech and vocabulary growth reflects parent effects on the child, rather than child-ability effects on the parent or hereditary factors. It was also found that gender is an important factor in rate of vocabulary growth. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Developmental Psychology},
	author = {Huttenlocher, Janellen and Haight, Wendy and Bryk, Anthony and Seltzer, Michael and Lyons, Thomas},
	year = {1991},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Vocabulary, Language Development, Parents, Human Sex Differences, Interpersonal Communication},
	pages = {236--248},
	file = {Snapshot:/Users/eec35/Zotero/storage/A7QZV495/doiLanding.html:text/html},
}

@article{lucca2018,
	title = {Communicating to {Learn}: {Infants}' {Pointing} {Gestures} {Result} in {Optimal} {Learning}},
	volume = {89},
	issn = {1467-8624},
	shorttitle = {Communicating to {Learn}},
	doi = {10.1111/cdev.12707},
	abstract = {Infants' pointing gestures are a critical predictor of early vocabulary size. However, it remains unknown precisely how pointing relates to word learning. The current study addressed this question in a sample of 108 infants, testing one mechanism by which infants' pointing may influence their learning. In Study 1, 18-month-olds, but not 12-month-olds, more readily mapped labels to objects if they had first pointed toward those objects than if they had referenced those objects via other communicative behaviors, such as reaching or gaze alternations. In Study 2, when an experimenter labeled a not pointed-to-object, 18-month-olds' pointing was no longer related to enhanced fast mapping. These findings suggest that infants' pointing gestures reflect a readiness and, potentially, a desire to learn.},
	language = {eng},
	number = {3},
	journal = {Child Development},
	author = {Lucca, Kelsey and Wilbourn, Makeba Parramore},
	month = may,
	year = {2018},
	pmid = {28032638},
	keywords = {Learning, Child Development, Infant, Female, Humans, Male, Age Factors, Gestures, Infant Behavior},
	pages = {941--960},
	file = {Accepted Version:/Users/eec35/Zotero/storage/5NUAS5HN/Lucca and Wilbourn - 2018 - Communicating to Learn Infants' Pointing Gestures.pdf:application/pdf},
}

@article{tomasello1986,
	title = {Joint {Attention} and {Early} {Language}},
	volume = {57},
	issn = {00093920},
	url = {https://www.jstor.org/stable/1130423?origin=crossref},
	doi = {10.2307/1130423},
	language = {en},
	number = {6},
	urldate = {2021-04-16},
	journal = {Child Development},
	author = {Tomasello, Michael and Farrar, Michael Jeffrey},
	month = dec,
	year = {1986},
	pages = {1454},
	file = {Tomasello and Farrar - 1986 - Joint Attention and Early Language.pdf:/Users/eec35/Zotero/storage/4CD3BM7P/Tomasello and Farrar - 1986 - Joint Attention and Early Language.pdf:application/pdf},
}

@article{uccelli2019,
	title = {Children's {Early} {Decontextualized} {Talk} {Predicts} {Academic} {Language} {Proficiency} in {Midadolescence}},
	volume = {90},
	issn = {1467-8624},
	doi = {10.1111/cdev.13034},
	abstract = {This study examines whether children's decontextualized talk-talk about nonpresent events, explanations, or pretend-at 30 months predicts seventh-grade academic language proficiency (age 12). Academic language (AL) refers to the language of school texts. AL proficiency has been identified as an important predictor of adolescent text comprehension. Yet research on precursors to AL proficiency is scarce. Child decontextualized talk is known to be a predictor of early discourse development, but its relation to later language outcomes remains unclear. Forty-two children and their caregivers participated in this study. The proportion of child talk that was decontextualized emerged as a significant predictor of seventh-grade AL proficiency, even after controlling for socioeconomic status, parent decontextualized talk, child total words, child vocabulary, and child syntactic comprehension.},
	language = {eng},
	number = {5},
	journal = {Child Development},
	author = {Uccelli, Paola and Demir-Lira, Özlem Ece and Rowe, Meredith L. and Levine, Susan and Goldin-Meadow, Susan},
	month = sep,
	year = {2019},
	pmid = {29359315},
	pmcid = {PMC6785988},
	keywords = {Language, Child, Infant, Female, Humans, Male, Language Development, Child, Preschool, Parents, Comprehension, Social Class, Academic Performance},
	pages = {1650--1663},
	file = {Accepted Version:/Users/eec35/Zotero/storage/H7US86GX/Uccelli et al. - 2019 - Children's Early Decontextualized Talk Predicts Ac.pdf:application/pdf},
}

@article{yu2012,
	title = {Embodied attention and word learning by toddlers},
	volume = {125},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027712001369},
	doi = {10.1016/j.cognition.2012.06.016},
	abstract = {Many theories of early word learning begin with the uncertainty inherent to learning a word from its co-occurrence with a visual scene. However, the relevant visual scene for infant word learning is neither from the adult theorist’s view nor the mature partner’s view, but is rather from the learner’s personal view. Here we show that when 18-month old infants interacted with objects in play with their parents, they created moments in which a single object was visually dominant. If parents named the object during these moments of bottom-up selectivity, later forced-choice tests showed that infants learned the name, but did not when naming occurred during a less visually selective moment. The momentary visual input for parents and toddlers was captured via head cameras placed low on each participant’s forehead as parents played with and named objects for their infant. Frame-by-frame analyses of the head camera images at and around naming moments were conducted to determine the visual properties at input that were associated with learning. The analyses indicated that learning occurred when bottom-up visual information was clean and uncluttered. The sensory-motor behaviors of infants and parents were also analyzed to determine how their actions on the objects may have created these optimal visual moments for learning. The results are discussed with respect to early word learning, embodied attention, and the social role of parents in early word learning.},
	language = {en},
	number = {2},
	urldate = {2022-07-18},
	journal = {Cognition},
	author = {Yu, Chen and Smith, Linda B.},
	month = nov,
	year = {2012},
	keywords = {Embodied cognition, Language learning, Perception and action},
	pages = {244--262},
	file = {ScienceDirect Full Text PDF:/Users/eec35/Zotero/storage/JQFN96VP/Yu and Smith - 2012 - Embodied attention and word learning by toddlers.pdf:application/pdf;ScienceDirect Snapshot:/Users/eec35/Zotero/storage/9H8BQ7EH/S0010027712001369.html:text/html},
}

@article{demir2015,
	title = {Vocabulary, syntax, and narrative development in typically developing children and children with early unilateral brain injury: early parental talk about the "there-and-then" matters},
	volume = {51},
	issn = {1939-0599},
	shorttitle = {Vocabulary, syntax, and narrative development in typically developing children and children with early unilateral brain injury},
	doi = {10.1037/a0038476},
	abstract = {This study examines the role of a particular kind of linguistic input--talk about the past and future, pretend, and explanations, that is, talk that is decontextualized--in the development of vocabulary, syntax, and narrative skill in typically developing (TD) children and children with pre- or perinatal brain injury (BI). Decontextualized talk has been shown to be particularly effective in predicting children's language skills, but it is not clear why. We first explored the nature of parent decontextualized talk and found it to be linguistically richer than contextualized talk in parents of both TD and BI children. We then found, again for both groups, that parent decontextualized talk at child age 30 months was a significant predictor of child vocabulary, syntax, and narrative performance at kindergarten, above and beyond the child's own early language skills, parent contextualized talk and demographic factors. Decontextualized talk played a larger role in predicting kindergarten syntax and narrative outcomes for children with lower syntax and narrative skill at age 30 months, and also a larger role in predicting kindergarten narrative outcomes for children with BI than for TD children. The difference between the 2 groups stemmed primarily from the fact that children with BI had lower narrative (but not vocabulary or syntax) scores than TD children. When the 2 groups were matched in terms of narrative skill at kindergarten, the impact that decontextualized talk had on narrative skill did not differ for children with BI and for TD children. Decontextualized talk is thus a strong predictor of later language skill for all children, but may be particularly potent for children at the lower-end of the distribution for language skill. The findings also suggest that variability in the language development of children with BI is influenced not only by the biological characteristics of their lesions, but also by the language input they receive.},
	language = {eng},
	number = {2},
	journal = {Developmental Psychology},
	author = {Demir, Özlem Ece and Rowe, Meredith L. and Heller, Gabriella and Goldin-Meadow, Susan and Levine, Susan C.},
	month = feb,
	year = {2015},
	pmid = {25621756},
	pmcid = {PMC4307606},
	keywords = {Vocabulary, Child Development, Female, Humans, Male, Language Development, Child, Preschool, Longitudinal Studies, Case-Control Studies, Linguistics, Parent-Child Relations, Brain Injuries},
	pages = {161--175},
	file = {Accepted Version:/Users/eec35/Zotero/storage/QCRCEKN4/Demir et al. - 2015 - Vocabulary, syntax, and narrative development in t.pdf:application/pdf},
}

@article{hsu2017,
	title = {Diversity matters: parent input predicts toddler verb production},
	volume = {44},
	issn = {1469-7602},
	shorttitle = {Diversity matters},
	doi = {10.1017/S0305000915000690},
	abstract = {The contribution of parent input to children's subsequent expressive verb diversity was explored in twenty typically developing toddlers with small verb lexicons. Child developmental factors and parent input measures (i.e. verb quantity, verb diversity, and verb-related structural cues) at age 1;9 were examined as potential predictors of children's verb production in spontaneous language samples at age 2;3. Parent verb input diversity, rather than input quantity, was the primary input factor contributing to children's subsequent verb diversity. Regression analysis showed that verb diversity in parent input at age 1;9 accounted for 30\% of the variance in children's verb production six months later, with children's total vocabulary size at age 1;9 accounting for an additional 16\% of the variance. These findings demonstrate the relative contributions of developmental and input factors to individual differences in toddlers' language development and establish the importance of input diversity to verb acquisition.},
	language = {eng},
	number = {1},
	journal = {Journal of Child Language},
	author = {Hsu, Ning and Hadley, Pamela A. and Rispoli, Matthew},
	month = jan,
	year = {2017},
	pmid = {26638832},
	keywords = {Language, Vocabulary, Child Development, Infant, Female, Humans, Male, Language Development, Child, Preschool, Parents, Cues, Individuality},
	pages = {63--86},
}

@article{weizman2001,
	title = {Lexical input as related to children's vocabulary acquisition: effects of sophisticated exposure and support for meaning},
	volume = {37},
	issn = {0012-1649},
	shorttitle = {Lexical input as related to children's vocabulary acquisition},
	doi = {10.1037/0012-1649.37.2.265},
	abstract = {A corpus of nearly 150,000 maternal word-tokens used by 53 low-income mothers in 263 mother-child conversations in 5 settings (e.g., play, mealtime, and book readings) was studied. Ninety-nine percent of maternal lexical input consisted of the 3,000 most frequent words. Children's vocabulary performance in kindergarten and later in 2nd grade related more to the occurrence of sophisticated lexical items than to quantity of lexical input overall. Density of sophisticated words heard and the density with which such words were embedded in helpful or instructive interactions, at age 5 at home, independently predicted over a third of the variance in children's vocabulary performance in both kindergarten and 2nd grade. These two variables, with controls for maternal education, child nonverbal IQ, and amount of child's talk produced during the interactive settings, at age 5, predicted 50\% of the variance in children's 2nd-grade vocabulary.},
	language = {eng},
	number = {2},
	journal = {Developmental Psychology},
	author = {Weizman, Z. O. and Snow, C. E.},
	month = mar,
	year = {2001},
	pmid = {11269394},
	keywords = {Vocabulary, Female, Humans, Male, Language Development, Adult, Child, Preschool, Follow-Up Studies, Mother-Child Relations, Poverty, Forecasting},
	pages = {265--279},
}

@article{naigles1998,
	title = {Why are some verbs learned before other verbs? {Effects} of input frequency and structure on children's early verb use},
	volume = {25},
	issn = {1469-7602, 0305-0009},
	shorttitle = {Why are some verbs learned before other verbs?},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/abs/why-are-some-verbs-learned-before-other-verbs-effects-of-input-frequency-and-structure-on-childrens-early-verb-use/AD0CD2EA85B15B064306AC09EE887EAF},
	doi = {10.1017/S0305000997003358},
	abstract = {This study investigated the extent to which the nature of verb
 input 
accounts for the order in which children acquire verbs. We assessed the
 
nature of verb input using a combined sample of the speech of 57 
mothers addressing their Stage I children. We assessed the order of verb
 
acquisition using as our database a combined sample of those children's
 
speech 10 weeks later and using as our measure of order of acquisition
 
the frequency of verb occurrence. The first set of analyses established
 
the validity of this measure of acquisition order by comparing it with
 
order of acquisition data obtained from checklist and diary data. The 
second set of analyses revealed that three properties of the input were
 
significant predictors of the order of acquisition of the 25 verbs that
 were 
the focus of this study. The predictive properties of input were the total
 
frequency, final position frequency, and diversity of syntactic environments
 
in which the verbs appeared. These findings suggest that the way 
verbs appear in input influences their ease of acquisition. More specifically,
 
the effect of syntactic diversity in input provides support for the 
syntactic bootstrapping account of how children use structural information
 
to learn the meaning of new verbs.},
	language = {en},
	number = {1},
	urldate = {2022-09-04},
	journal = {Journal of Child Language},
	author = {Naigles, Letitia R. and Hoff-Ginsberg, Erika},
	month = feb,
	year = {1998},
	note = {Publisher: Cambridge University Press},
	pages = {95--120},
	file = {Snapshot:/Users/eec35/Zotero/storage/9IW4BCI5/AD0CD2EA85B15B064306AC09EE887EAF.html:text/html},
}

@book{perez-pereira1999,
	address = {London},
	title = {Language {Development} and {Social} {Interaction} in {Blind} {Children}},
	isbn = {978-0-203-77608-7},
	abstract = {This book provides an up-to-date account of blind children's developing communicative abilities with particular emphasis on social cognition and language acquisition from infancy to early school age. It purports to foster dialogue between those interested in the study of typically developing children and those interested in the development of children who are blind and to provide insights and new explanations of why the development of blind children may differ from that of sighted children. The book also aims to identify and examine current theoretical issues which are likely to be at the centre of developments in the fields of child language and developmental psychology.Language Development and Social Interaction in Blind Children is also a timely book. The study of blind children's development constitutes a unique opportunity to study the effect of vision on development, and more specifically on the development of language and certain aspects of social cognition. Current interest in the development of "theory of mind" and perspective taking in language learning, make the case of blind children crucial to our understanding of certain aspects of psychological functioning. The book explores these issues, challenges some widely-held beliefs about the development of communication in blind children, and provides a cohesive picture of our knowledge to date.},
	publisher = {Psychology Press},
	author = {Perez-Pereira, Miguel and Conti-Ramsden, Gina},
	month = sep,
	year = {1999},
	doi = {10.4324/9780203776087},
}

@article{newman2016,
	title = {Input and uptake at 7 months predicts toddler vocabulary: the role of child-directed speech and infant processing skills in language development},
	volume = {43},
	issn = {1469-7602},
	shorttitle = {Input and uptake at 7 months predicts toddler vocabulary},
	doi = {10.1017/S0305000915000446},
	abstract = {Both the input directed to the child, and the child's ability to process that input, are likely to impact the child's language acquisition. We explore how these factors inter-relate by tracking the relationships among: (a) lexical properties of maternal child-directed speech to prelinguistic (7-month-old) infants (N = 121); (b) these infants' abilities to segment lexical targets from conversational child-directed utterances in an experimental paradigm; and (c) the children's vocabulary outcomes at age 2;0. Both repetitiveness in maternal input and the child's speech segmentation skills at age 0;7 predicted language outcomes at 2;0; moreover, while these factors were somewhat inter-related, they each had independent effects on toddler vocabulary skill, and there was no interaction between the two.},
	language = {eng},
	number = {5},
	journal = {Journal of Child Language},
	author = {Newman, Rochelle S. and Rowe, Meredith L. and Bernstein Ratner, Nan},
	month = sep,
	year = {2016},
	pmid = {26300377},
	note = {tex.ids= newman2016a, newman2016b
publisher: Cambridge University Press},
	keywords = {Vocabulary, Child, Infant, Female, Humans, Male, Language Development, Child, Preschool, Speech Perception, Communication, Child Language, Comprehension, Verbal Behavior, Mother-Child Relations},
	pages = {1158--1173},
	file = {Full Text:/Users/eec35/Zotero/storage/7MVQPC6D/Newman et al. - 2016 - Input and uptake at 7 months predicts toddler voca.pdf:application/pdf},
}

@article{hoff2003,
	title = {The specificity of environmental influence: socioeconomic status affects early vocabulary development via maternal speech},
	volume = {74},
	issn = {0009-3920},
	shorttitle = {The specificity of environmental influence},
	doi = {10.1111/1467-8624.00612},
	abstract = {The hypothesis was tested that children whose families differ in socioeconomic status (SES) differ in their rates of productive vocabulary development because they have different language-learning experiences. Naturalistic interaction between 33 high-SES and 30 mid-SES mothers and their 2-year-old children was recorded at 2 time points 10 weeks apart. Transcripts of these interactions provided the basis for estimating the growth in children's productive vocabularies between the first and second visits and properties of maternal speech at the first visit. The high-SES children grew more than the mid-SES children in the size of their productive vocabularies. Properties of maternal speech that differed as a function of SES fully accounted for this difference. Implications of these findings for mechanisms of environmental influence on child development are discussed.},
	language = {eng},
	number = {5},
	journal = {Child Development},
	author = {Hoff, Erika},
	month = oct,
	year = {2003},
	pmid = {14552403},
	keywords = {Vocabulary, Female, Humans, Male, Language Development, Child, Preschool, Socioeconomic Factors, Social Environment, Follow-Up Studies, Verbal Behavior, Mother-Child Relations},
	pages = {1368--1378},
	file = {Full Text:/Users/eec35/Zotero/storage/UMSXULUR/Hoff - 2003 - The specificity of environmental influence socioe.pdf:application/pdf},
}

@article{hadley2017,
	title = {Input {Subject} {Diversity} {Enhances} {Early} {Grammatical} {Growth}: {Evidence} from a {Parent}-{Implemented} {Intervention}},
	volume = {13},
	issn = {1547-5441},
	shorttitle = {Input {Subject} {Diversity} {Enhances} {Early} {Grammatical} {Growth}},
	doi = {10.1080/15475441.2016.1193020},
	abstract = {PURPOSE: The current study used an intervention design to test the hypothesis that parent input sentences with diverse lexical noun phrase (NP) subjects would accelerate growth in children's sentence diversity.
METHOD: Child growth in third person sentence diversity was modeled from 21 to 30 months (n = 38) in conversational language samples obtained at 21, 24, 27, and 30 months. Treatment parents (n = 19) received instruction on strategies designed to increase lexical NP subjects (e.g., The baby is sleeping.). Instruction consisted of one group education session and two individual coaching sessions which took place when children were approximately 22 to 23 months of age.
RESULTS: Treatment substantially increased parents' lexical NP subject tokens and types (ηp2 ≥ .45) compared to controls. Children's number of different words was a significant predictor of sentence diversity in the analyses of group treatment effects and individual input effects. Treatment condition was not a significant predictor of treatment effects on children's sentence diversity, but parents' lexical NP subject types was a significant predictor of children's sentence diversity growth, even after controlling for children's number of different words over time.
CONCLUSIONS: These findings establish a link between subject diversity in parent input and children's early grammatical growth, and the feasibility of using relatively simple strategies to alter this specific grammatical property of parent language input.},
	language = {eng},
	number = {1},
	journal = {Language Learning and Development: The Official Journal of the Society for Language Development},
	author = {Hadley, Pamela A. and Rispoli, Matthew and Holt, Janet K. and Papastratakos, Theodora and Hsu, Ning and Kubalanza, Mary and McKenna, Megan M.},
	year = {2017},
	pmcid = {PMC5343515},
	pmid = {28286431},
	note = {tex.ids= hadley2017a},
	keywords = {child-directed speech, syntax, language intervention, parent input, toddlers},
	pages = {54--79},
}

@article{devilliers1985,
	title = {Learning how to use verbs: lexical coding and the influence of the input*},
	volume = {12},
	issn = {1469-7602, 0305-0009},
	shorttitle = {Learning how to use verbs},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/abs/learning-how-to-use-verbs-lexical-coding-and-the-influence-of-the-input/86C31542277D235C161A0A0C87F62772},
	doi = {10.1017/S0305000900006668},
	abstract = {Samples of spontaneous speech from two young children and their mothers were analysed to examine how children learn some of the inflectional/syntactic possibilities for individual verbs. Multiple regression analyses were performed to establish predictors of the children's range of grammatical use of particular verbs. Maternal variety of use proved to be a highly significant predictor of the children's use of the same verbs, but maternal frequency was not a significant predictor of children's use. Step-wise regression analyses revealed that each child's own mother's use was a significantly better predictor of the child's use than that of the unacquainted mother. It is argued that the children were monitoring the grammatical patterns of use of individual verbs in the input they received. The extent of novel use of verbs by the child cannot be assessed from these data, and awaits further experimental investigation.},
	language = {en},
	number = {3},
	urldate = {2022-09-15},
	journal = {Journal of Child Language},
	author = {De Villiers, Jill},
	month = oct,
	year = {1985},
	note = {Publisher: Cambridge University Press},
	pages = {587--595},
	file = {Snapshot:/Users/eec35/Zotero/storage/Y2Y95S7P/86C31542277D235C161A0A0C87F62772.html:text/html},
}

@article{huttenlocher2002,
	title = {Language input and child syntax},
	volume = {45},
	issn = {0010-0285},
	doi = {10.1016/s0010-0285(02)00500-5},
	abstract = {Existing work on the acquisition of syntax has been concerned mainly with the early stages of syntactic development. In the present study we examine later syntactic development in children. Also, existing work has focused on commonalities in the emergence of syntax. Here we explore individual differences among children and their relation to variations in language input. In Study 1 we find substantial individual differences in children's mastery of multiclause sentences and a significant relation between those differences and the proportion of multiclause sentences in parent speech. We also find individual differences in the number of noun phrases in children's utterances and a significant relation between those differences and the number of noun phrases in parent speech. In Study 2 we find greater syntactic growth over a year of preschool in classes where teachers' speech is more syntactically complex. The implications of our findings for the understanding of the sources of syntactic development are discussed.},
	language = {eng},
	number = {3},
	journal = {Cognitive Psychology},
	author = {Huttenlocher, Janellen and Vasilyeva, Marina and Cymerman, Elina and Levine, Susan},
	month = nov,
	year = {2002},
	pmid = {12480478},
	keywords = {Female, Humans, Male, Child, Preschool, Socioeconomic Factors, Child Language, Regression Analysis, Social Environment, Interpersonal Relations, Multivariate Analysis, Observation},
	pages = {337--374},
}

@article{campbell2022,
	title = {Making sense of sensory language: {Acquisition} of sensory knowledge by individuals with congenital sensory impairments},
	volume = {174},
	issn = {0028-3932},
	shorttitle = {Making sense of sensory language},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393222001798},
	doi = {10.1016/j.neuropsychologia.2022.108320},
	abstract = {The present article provides a narrative review on how language communicates sensory information and how knowledge of sight and sound develops in individuals born deaf or blind. Studying knowledge of the perceptually inaccessible sensory domain for these populations offers a lens into how humans learn about that which they cannot perceive. We first review the linguistic strategies within language that communicate sensory information. Highlighting the power of language to shape knowledge, we next review the detailed knowledge of sensory information by individuals with congenital sensory impairments, limitations therein, and neural representations of imperceptible phenomena. We suggest that the acquisition of sensory knowledge is supported by language, experience with multiple perceptual domains, and cognitive and social abilities which mature over the first years of life, both in individuals with and without sensory impairment. We conclude by proposing a developmental trajectory for acquiring sensory knowledge in the absence of sensory perception.},
	language = {en},
	urldate = {2022-09-05},
	journal = {Neuropsychologia},
	author = {Campbell, Erin E. and Bergelson, Elika},
	month = sep,
	year = {2022},
	pages = {108320},
	file = {ScienceDirect Full Text PDF:/Users/eec35/Zotero/storage/MBKB98QN/Campbell and Bergelson - 2022 - Making sense of sensory language Acquisition of s.pdf:application/pdf;ScienceDirect Snapshot:/Users/eec35/Zotero/storage/VHMXDD9P/S0028393222001798.html:text/html},
}

@article{bergelson2013,
	title = {The acquisition of abstract words by young infants},
	volume = {127},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027713000395},
	doi = {10.1016/j.cognition.2013.02.011},
	abstract = {Young infants’ learning of words for abstract concepts like ‘all gone’ and ‘eat,’ in contrast to their learning of more concrete words like ‘apple’ and ‘shoe,’ may follow a relatively protracted developmental course. We examined whether infants know such abstract words. Parents named one of two events shown in side-by-side videos while their 6–16-month-old infants (n=98) watched. On average, infants successfully looked at the named video by 10months, but not earlier, and infants’ looking at the named referent increased robustly at around 14months. Six-month-olds already understand concrete words in this task (Bergelson \& Swingley, 2012). A video-corpus analysis of unscripted mother-infant interaction showed that mothers used the tested abstract words less often in the presence of their referent events than they used concrete words in the presence of their referent objects. We suggest that referential uncertainty in abstract words’ teaching conditions may explain the later acquisition of abstract than concrete words, and we discuss the possible role of changes in social-cognitive abilities over the 6–14month period.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {Cognition},
	author = {Bergelson, Elika and Swingley, Daniel},
	month = jun,
	year = {2013},
	keywords = {Cognitive development, Infancy, Language acquisition, Psycholinguistics, Word learning},
	pages = {391--397},
	file = {ScienceDirect Full Text PDF:/Users/eec35/Zotero/storage/PZ5ZDNNB/Bergelson and Swingley - 2013 - The acquisition of abstract words by young infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/eec35/Zotero/storage/XWEW7EG2/S0010027713000395.html:text/html},
}

@article{snow1972,
	title = {Mothers' {Speech} to {Children} {Learning} {Language} on {JSTOR}},
	volume = {43},
	url = {https://www-jstor-org.proxy.lib.duke.edu/stable/1127555?origin=crossref#metadata_info_tab_contents},
	urldate = {2022-09-15},
	journal = {Child Development},
	author = {Snow, Catherine E.},
	year = {1972},
	pages = {549--565},
	file = {Mothers' Speech to Children Learning Language on JSTOR:/Users/eec35/Zotero/storage/424EKZX5/1127555.html:text/html},
}

@book{vygotsky1978,
	title = {Mind in {Society}: {Development} of {Higher} {Psychological} {Processes}},
	isbn = {978-0-674-57629-2},
	shorttitle = {Mind in {Society}},
	abstract = {The great Russian psychologist L. S. Vygotsky has long been recognized as a pioneer in developmental psychology. But his theory of development has never been well understood in the West. Mind in Society corrects much of this misunderstanding. Carefully edited by a group of outstanding Vygotsky scholars, the book presents a unique selection of Vygotsky's important essays.},
	language = {en},
	publisher = {Harvard University Press},
	author = {Vygotsky, L. S. and Cole, Michael},
	year = {1978},
	note = {Google-Books-ID: RxjjUefze\_oC},
	keywords = {Psychology / General},
}

@article{fernald1989,
	title = {Intonation and communicative intent in mothers' speech to infants: is the melody the message?},
	volume = {60},
	issn = {0009-3920},
	shorttitle = {Intonation and communicative intent in mothers' speech to infants},
	abstract = {This study explores the power of intonation to convey meaningful information about the communicative intent of the speaker in speech addressed to preverbal infants and in speech addressed to adults. Natural samples of infant- and adult-directed speech were recorded from 5 mothers of 12-month-old infants, in 5 standardized interactional contexts: Attention-bid, Approval, Prohibition, Comfort, and Game/Telephone. 25 infant-directed and 25 adult-directed vocalizations were electronically filtered to eliminate linguistic content. The content-filtered speech stimuli were presented to 80 adult subjects: 40 experienced parents and 40 students inexperienced with infants. The subjects' task was to identify the communicative intent of the speaker using only prosodic information, given a 5-alternative forced choice. Listeners were able to use intonation to identify the speaker's intent with significantly higher accuracy in infant-directed speech than in adult-directed speech. These findings suggest that the prosodic patterns of speech to infants are more informative than those of adult-adult speech, and may provide the infant with reliable cues to the communicative intent of the speaker. The interpretation of these results proposed here is that the relation of prosodic form to communicative function is made uniquely salient in the melodies of mothers' speech, and that these characteristic prosodic patterns are potentially meaningful to the preverbal infant.},
	language = {eng},
	number = {6},
	journal = {Child Development},
	author = {Fernald, A.},
	month = dec,
	year = {1989},
	pmid = {2612255},
	keywords = {Infant, Female, Humans, Male, Language Development, Adult, Communication, Attention, Verbal Behavior, Maternal Behavior, Affect, Pitch Perception},
	pages = {1497--1510},
}

@article{preisler1991,
	title = {Early patterns of interaction between blind infants and their sighted mothers},
	volume = {17},
	issn = {1365-2214},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2214.1991.tb00680.x},
	doi = {10.1111/j.1365-2214.1991.tb00680.x},
	abstract = {In a longitudinal, descriptive study of blind infant—sighted mother interaction during the age period 3 to 12 months, 10 infants, seven blind and three severely visually impaired, were video-recorded in natural interactional settings with their parents. The objective was to describe which communicative expressions the infants, as well as their mothers use in interaction and how they respond to each others’communications. Detailed analyses of the infants’and mothers’communicative behaviours were carried out. The blind infants exhibited a variety of communicative expressions in interaction with their mothers; they took an active part in proto-conversations and dialogues with their mothers. The blind infants had difficulties in sharing their opinions about objects with their mothers during the age period studied. Comparisons between the blind and the severely visually impaired infants showed that even very low vision improves the infant's opportunities to take part in interpersonal communication and to share meanings. The results are discussed in relation to Trevarthen's view of the infant having an innate motive for intersubjectivity — for communication — and Stern's theory of the development of the self.},
	language = {en},
	number = {2},
	urldate = {2022-09-15},
	journal = {Child: Care, Health and Development},
	author = {Preisler, Gunilla M.},
	year = {1991},
	note = {tex.ids= preisler1991a
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2214.1991.tb00680.x},
	pages = {65--90},
	file = {Snapshot:/Users/eec35/Zotero/storage/9ZGT7WMH/j.1365-2214.1991.tb00680.html:text/html},
}

@article{thiessen2005,
	title = {Infant-{Directed} {Speech} {Facilitates} {Word} {Segmentation}},
	volume = {7},
	issn = {1532-7078},
	doi = {10.1207/s15327078in0701_5},
	abstract = {There are reasons to believe that infant-directed (ID) speech may make language acquisition easier for infants. However, the effects of ID speech on infants' learning remain poorly understood. The experiments reported here assess whether ID speech facilitates word segmentation from fluent speech. One group of infants heard a set of nonsense sentences spoken with intonation contours characteristic of adult-directed (AD) speech, and the other group heard the same sentences spoken with intonation contours characteristic of ID speech. In both cases, the only cue to word boundaries was the statistical structure of the speech. Infants were able to distinguish words from syllable sequences spanning word boundaries after exposure to ID speech but not after hearing AD speech. These results suggest that ID speech facilitates word segmentation and may be useful for other aspects of language acquisition as well. Issues of direction of preference in preferential listening paradigms are also considered.},
	language = {eng},
	number = {1},
	journal = {Infancy: The Official Journal of the International Society on Infant Studies},
	author = {Thiessen, Erik D. and Hill, Emily A. and Saffran, Jenny R.},
	month = jan,
	year = {2005},
	pmid = {33430544},
	pages = {53--71},
}

@article{campbell2003,
	title = {Maternal {Directives} to {Young} {Children} who are {Blind}},
	volume = {97},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X0309700604},
	doi = {10.1177/0145482X0309700604},
	abstract = {The results of a detailed analysis of how mothers direct attention and play with their blind and sighted 18-month-old children found that the mothers of the blind children were no more directive than were the mothers of the sighted children, but that they made some use of directives that were particular to the needs of young blind children.},
	language = {en},
	number = {6},
	urldate = {2022-09-15},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Campbell, Julie},
	month = jun,
	year = {2003},
	note = {Publisher: SAGE Publications Inc},
	pages = {355--365},
	file = {SAGE PDF Full Text:/Users/eec35/Zotero/storage/XI5S3MP7/Campbell - 2003 - Maternal Directives to Young Children who are Blin.pdf:application/pdf},
}

@article{urwin1983,
	title = {Dialogue and cognitive functioning in the early language development of three blind children: {Normal} and deficient},
	url = {https://scholar.google.com/scholar_lookup?title=Dialogue%20and%20Cognitive%20Functioning%20in%20the%20Early%20Language%20Development%20of%20Three%20Blind%20Children&publication_year=1983&author=C.%20Urwin},
	urldate = {2022-09-15},
	author = {Urwin, Cathy},
	year = {1983},
	pages = {142--161},
	file = {Urwin\: Dialogue and cognitive functioning in the... - Google Scholar:/Users/eec35/Zotero/storage/ILIWTI95/scholar_lookup.html:text/html},
}

@article{preisler1995,
	title = {The development of communication in blind and in deaf infants--similarities and differences},
	volume = {21},
	issn = {0305-1862},
	doi = {10.1111/j.1365-2214.1995.tb00412.x},
	abstract = {Results from two longitudinal studies of blind infant--sighted mother and of deaf infant-hearing mother/deaf mother interaction, are summarized in this paper. The aim is to shed light on the role of visual and auditory stimulation in the development of communication. Video-recorded interactions taken during infancy were transcribed in a systematic, objective and detailed way. The development of communication is described with a focus on pre-verbal abilities, exploration of toys, social and symbolic play, communicative intent and sharing of experiences. The results show a delay in the development of communication in the blind infants compared with the deaf infants, indicating a more critical role of visual stimulation compared with auditory stimulation during the infancy period to this development.},
	language = {eng},
	number = {2},
	journal = {Child: Care, Health and Development},
	author = {Preisler, G. M.},
	month = mar,
	year = {1995},
	pmid = {7781155},
	keywords = {Deafness, Child, Blindness, Infant, Female, Humans, Male, Language Development, Child, Preschool, Communication, Early Intervention, Educational, Sign Language, Social Environment, Longitudinal Studies, Psychomotor Performance, Mother-Child Relations, Play and Playthings, Exploratory Behavior, Motor Skills, Personality Development},
	pages = {79--110},
}

@article{rowland1984,
	title = {Preverbal {Communication} of {Blind} {Infants} and {Their} {Mothers}},
	volume = {78},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X8407800701},
	doi = {10.1177/0145482X8407800701},
	abstract = {Films of interactions between five mothers and their blind infants, aged 11 months to 2 years, 8 months, made at regular intervals over six months, were analyzed to determine the development of communicative skills in each mother-infant dyad. It was found that, although the frequency of the infants? vocalizations was within normal limits, the vocalizations did not follow normal patterns of responsiveness, and the mothers? responses to them were weak and inconsistent. Suggestions are made for a highly structured program to enhance the communicative skills of parents and their blind infants.},
	language = {en},
	number = {7},
	urldate = {2022-09-15},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Rowland, Charity},
	month = sep,
	year = {1984},
	note = {Publisher: SAGE Publications Inc},
	pages = {297--302},
}

@article{watkins1998,
	title = {The {Deaf} {Mentor} {Experimental} {Project} for young children who are deaf and their families},
	volume = {143},
	issn = {0002-726X},
	doi = {10.1353/aad.2012.0098},
	abstract = {The Deaf Mentor Experimental Project investigated the efficacy of deaf mentor services to young deaf children and their families. These services focused on deaf adults (mentors), who made regular home visits to the children and their families; shared their language (American Sign Language), culture, and personal knowledge of deafness with the families; and served as role models for the children. The children also received regular home visits from a hearing parent adviser who helped the family promote the child's early listening, English, and literacy skills. The result was a bilingual-bicultural home environment for these children. The children who received deaf mentor services were compared to matched children who did not receive these services but who received parent adviser services. Children receiving this early bilingual-bicultural programming made greater language gains during treatment time, had considerably larger vocabularies, and scored higher on measures of communication, language, and English syntax than the matched children.},
	language = {eng},
	number = {1},
	journal = {American Annals of the Deaf},
	author = {Watkins, S. and Pittman, P. and Walden, B.},
	month = mar,
	year = {1998},
	pmid = {9557330},
	keywords = {Deafness, Infant, Female, Humans, Male, Language Development, Adult, Child, Preschool, Child Language, Infant, Newborn, Family, Mentors, Multilingualism},
	pages = {29--34},
}

@article{bigelow1987,
	title = {Early words of blind children},
	volume = {14},
	issn = {0305-0009, 1469-7602},
	url = {https://www.cambridge.org/core/product/identifier/S0305000900012721/type/journal_article},
	doi = {10.1017/S0305000900012721},
	abstract = {ABSTRACT 
            The first 50 words of three blind children were collected and analysed using procedures used by Nelson (1973) on 18 sighted children. The early vocabulary of the blind children paralleled that of the sighted children in the age and speed of acquisition, and in the underlying characteristics of what the children chose to label. These reflect a sensorimotor organization in which self-action and perceptual change are the salient variables. The early words of the blind children differed from those of sighted children in the percentage of words in each of Nelson's grammatical categories. This suggests differences in how the children use language. These differences are discussed as a function of the children's lack of vision and their particular language learning context.},
	language = {en},
	number = {1},
	urldate = {2022-09-20},
	journal = {Journal of Child Language},
	author = {Bigelow, Ann},
	month = feb,
	year = {1987},
	pages = {47--56},
}

@article{roder2000,
	title = {Event-related potentials during auditory language processing in congenitally blind and sighted people},
	volume = {38},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393200000579},
	doi = {10.1016/S0028-3932(00)00057-9},
	abstract = {While behavioral studies have documented delayed language acquisition in blind children, other studies have revealed better speech discrimination abilities for blind than sighted adults. Several brain imaging studies have provided evidence for cortical reorganization due to visual deprivation but the cerebral organization of language in blind humans is not known yet. We hypothesized that the increasing specialization of language systems normally observed during development may not take place to the same degree in blind individuals since posterior visual areas do not receive their adequate input. On the other hand, we hypothesized that blind people, due to their greater reliance upon the auditory language signal, may process speech faster than sighted people. To test these assumptions, event-related potentials were recorded while 11 congenitally blind and 11 sighted adults matched in age, gender, handedness and education were engaged in a language task. Participants listened to sentences in order to decide after each sentence if it was meaningful or not. Incongruous sentence-final words elicited an N400 effect in both groups. The N400 effect had a left-lateralized fronto-central scalp distribution in the sighted but a symmetric and broad topography in the blind. Furthermore, the N400 effect started earlier in the blind than in the sighted. Closed class compared to open class sentence middle words elicited a more pronounced late negativity in the blind than in the sighted. These results suggest that blind people process auditory language stimuli faster than sighted people and that some language functions may be reorganized in the blind.},
	language = {en},
	number = {11},
	urldate = {2022-09-20},
	journal = {Neuropsychologia},
	author = {Röder, Brigitte and Rösler, Frank and Neville, Helen J},
	month = oct,
	year = {2000},
	keywords = {Blindness, Neural plasticity, Cross-modal compensation, Language perception},
	pages = {1482--1502},
}

@article{roder2003,
	title = {Semantic and morpho-syntactic priming in auditory word recognition in congenitally blind adults},
	volume = {18},
	issn = {0169-0965},
	url = {https://doi.org/10.1080/01690960143000407},
	doi = {10.1080/01690960143000407},
	abstract = {While several studies have reported a deviation from the normal time course of language acquisition in blind children others have provided evidence for a more efficient processing of the language input in blind than sighted adults. The present study used a semantic and morpho-syntactic priming paradigm to address the question at which processing stage the advantage of blind adults may arise. Congenitally blind adults and sighted controls matched for age, gender and education, first heard an adjective followed by a noun or a pseudo-word. The adjective was or was not semantically associated with the target and it was either correctly or incorrectly inflected for gender with respect to the following noun. Participants decided whether or not the target noun was a legal German word. Nouns primed semantically and morpho-syntactically had shorter lexical decision times than those primed only semantically or only morpho-syntactically and decision times for the latter two conditions were shorter than in a condition without a semantically or morpho-syntactically congruent context. This response pattern did not differ between groups. However, blind participants had shorter reaction times than sighted for pseudo-words, and overall decision times for words tended to be shorter in the blind as well. It is concluded that the faster speech comprehension skills of blind adults most likely originate from a more efficient perceptual analysis rather than from a more extended use of semantic or morpho-syntactic context information.},
	number = {1},
	urldate = {2022-09-20},
	journal = {Language and Cognitive Processes},
	author = {Röder, Brigitte and Demuth, Lisa and Streb, Judith and Rösler, Frank},
	month = feb,
	year = {2003},
	pages = {1--20},
}

@article{hazan2011,
	title = {Acoustic-phonetic characteristics of speech produced with communicative intent to counter adverse listening conditions},
	volume = {130},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.3623753},
	doi = {10.1121/1.3623753},
	number = {4},
	urldate = {2022-09-20},
	journal = {The Journal of the Acoustical Society of America},
	author = {Hazan, Valerie and Baker, Rachel},
	month = oct,
	year = {2011},
	pages = {2139--2152},
}

@article{rowe2013,
	title = {Decontextualized {Language} {Input} and {Preschoolers}' {Vocabulary} {Development}},
	volume = {34},
	copyright = {Thieme Medical Publishers 333 Seventh Avenue, New York, NY 10001, USA.},
	issn = {0734-0478, 1098-9056},
	url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0033-1353444},
	doi = {10.1055/s-0033-1353444},
	abstract = {This article discusses the importance of using decontextualized language, or language that is removed from the here and now including pretend, narrative, and explanatory talk, with preschool children. The literature on parents' use of decontextualized language is reviewed and results of a longitudinal study of parent decontextualized language input in relation to child vocabulary development are explained. The main findings are that parents who provide their preschool children with more explanations and narrative utterances about past or future events in the input have children with larger vocabularies 1 year later, even with quantity of parent input and child prior vocabulary skill controlled. Recommendations for how to engage children in decontextualized language conversations are provided.},
	language = {en},
	number = {4},
	urldate = {2022-09-20},
	journal = {Seminars in Speech and Language},
	author = {Rowe, Meredith L.},
	month = nov,
	year = {2013},
	keywords = {vocabulary, extended discourse, Decontextualized language, input, narrative},
	pages = {260--266},
}

@misc{lavechin2021,
	title = {An open-source voice type classifier for child-centered daylong recordings},
	url = {http://arxiv.org/abs/2005.12656},
	doi = {10.48550/arXiv.2005.12656},
	abstract = {Spontaneous conversations in real-world settings such as those found in child-centered recordings have been shown to be amongst the most challenging audio files to process. Nevertheless, building speech processing models handling such a wide variety of conditions would be particularly useful for language acquisition studies in which researchers are interested in the quantity and quality of the speech that children hear and produce, as well as for early diagnosis and measuring effects of remediation. In this paper, we present our approach to designing an open-source neural network to classify audio segments into vocalizations produced by the child wearing the recording device, vocalizations produced by other children, adult male speech, and adult female speech. To this end, we gathered diverse child-centered corpora which sums up to a total of 260 hours of recordings and covers 10 languages. Our model can be used as input for downstream tasks such as estimating the number of words produced by adult speakers, or the number of linguistic units produced by children. Our architecture combines SincNet filters with a stack of recurrent layers and outperforms by a large margin the state-of-the-art system, the Language ENvironment Analysis (LENA) that has been used in numerous child language studies.},
	urldate = {2023-01-02},
	publisher = {arXiv},
	author = {Lavechin, Marvin and Bousbib, Ruben and Bredin, Hervé and Dupoux, Emmanuel and Cristia, Alejandrina},
	month = jan,
	year = {2021},
	note = {arXiv:2005.12656 [eess]},
	keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing, I.2.7},
	annote = {Comment: accepted to Interspeech 2020},
	file = {arXiv Fulltext PDF:/Users/eec35/Zotero/storage/IVBY8CAF/Lavechin et al. - 2021 - An open-source voice type classifier for child-cen.pdf:application/pdf;arXiv.org Snapshot:/Users/eec35/Zotero/storage/IXTBIKCH/2005.html:text/html},
}

@article{howe2006,
	title = {Disabled children, parent-child interaction and attachment},
	volume = {11},
	issn = {1356-7500, 1365-2206},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1365-2206.2006.00397.x},
	doi = {10.1111/j.1365-2206.2006.00397.x},
	language = {en},
	number = {2},
	urldate = {2023-01-25},
	journal = {Child {\textless}html\_ent glyph="@amp;" ascii="\&amp;"/{\textgreater} Family Social Work},
	author = {Howe, David},
	month = may,
	year = {2006},
	pages = {95--106},
}

@article{loots2003,
	title = {The {Interaction} between {Mothers} and their {Visually} {Impaired} {Infants}: {An} {Intersubjective} {Developmental} {Perspective}},
	volume = {97},
	issn = {0145-482X, 1559-1476},
	shorttitle = {The {Interaction} between {Mothers} and their {Visually} {Impaired} {Infants}},
	url = {http://journals.sagepub.com/doi/10.1177/0145482X0309700703},
	doi = {10.1177/0145482X0309700703},
	abstract = {In this article, an intersubjective developmental theory that focuses primarily on the development of the interworld between the caregiver and the infant is used to integrate and interpret the seemingly incoherent and contradictory research findings on the interactions between mothers and their infants with visual impairments. The implications for further research and early intervention practices are presented.},
	language = {en},
	number = {7},
	urldate = {2023-01-25},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Loots, Gerrit and Devise, Isabel and Sermijn, Jasmina},
	month = jul,
	year = {2003},
	pages = {403--417},
}

@article{baird1997,
	title = {Mothers’ {Interpretations} of the {Behavior} of {Their} {Infants} with {Visual} and {Other} {Impairments} during {Interactions}},
	volume = {91},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X9709100507},
	doi = {10.1177/0145482X9709100507},
	abstract = {In this study, seven mothers of infants with visual and other impairments identified behaviors that they considered meaningful and interpreted these behaviors. The mothers identified 14 of 22 subcategories of behaviors that a previous study of mothers with sighted infants had identified. Not only was the range of behaviors they interpreted limited, but over 65 percent of their interpretations fell into only two of the 16 subcategories previously identified (attention preference and intentional behavior: desire). The implications for early intervention and future research are discussed.},
	language = {en},
	number = {5},
	urldate = {2023-01-25},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Baird, S.M. and Mayfield, P. and Baker, P.},
	month = sep,
	year = {1997},
	note = {Publisher: SAGE Publications Inc},
	pages = {467--483},
}

@article{grumi2021,
	title = {Togetherness, beyond the eyes: {A} systematic review on the interaction between visually impaired children and their parents},
	volume = {64},
	issn = {0163-6383},
	shorttitle = {Togetherness, beyond the eyes},
	url = {https://www.sciencedirect.com/science/article/pii/S0163638321000655},
	doi = {10.1016/j.infbeh.2021.101590},
	abstract = {Background
Parent-child interaction is essential to promote adaptive emotional, cognitive, and social development. The majority of previous research on parent-child interaction is largely dependent on face-to-face exchanges that require the interactive partners to visually recognize reciprocal communicative bids. Therefore, previous findings in the field can only partially apply to the early interactive patterns occurring between visually impaired infants and their parents. The present study was aimed to systematically review the available evidence on parent-child interaction in the context of developmental visual impairment.
Methods
Fourteen papers were finally selected after literature search on PubMed and Scopus. Data synthesis was focused on three core topics: visually impaired children’s contribution to the interaction, parental caregiving behaviors with visually impaired children, and the association between parents’ behaviors and the developmental outcomes of children with visual impairment.
Results
Visually impaired children may exhibit reduced reactivity to maternal stimuli and less-than-optimal levels of interactive initiations in social exchanges. Parents of children with visual impairment may use more descriptive communicative acts and greater directiveness compared to mothers of sighted counterparts. Specific caregiving behaviors (e.g., responsiveness and goal setting) of parents of children with visual impairment may significantly support language and socio-emotional development as well as sensorimotor integration.
Discussion
Children with visual impairment may be less responsive and they may produce less clear communicative bids while interacting with their parents. Their parents may face specific challenges while engaging with them and they may become increasingly directive and intrusive. Nonetheless, even in the presence of visual impairment, the quality of parental caregiving behaviors appears to play a potential preventive role in the face of children’s socio-emotional and cognitive outcomes. These results suggest that early interventions focused on parent-child interactions are especially needed in this population.},
	language = {en},
	urldate = {2023-02-14},
	journal = {Infant Behavior and Development},
	author = {Grumi, Serena and Cappagli, Giulia and Aprile, Giorgia and Mascherpa, Eleonora and Gori, Monica and Provenzi, Livio and Signorini, Sabrina},
	month = aug,
	year = {2021},
	keywords = {Children, Visual impairment, Dyadic regulation, Parent-child interaction, Sensitivity},
	pages = {101590},
	file = {ScienceDirect Snapshot:/Users/eec35/Zotero/storage/THGCJC8R/S0163638321000655.html:text/html},
}

@inproceedings{terragni2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Word {Embedding}-{Based} {Topic} {Similarity} {Measures}},
	isbn = {978-3-030-80599-9},
	doi = {10.1007/978-3-030-80599-9_4},
	abstract = {Topic models aim at discovering a set of hidden themes in a text corpus. A user might be interested in identifying the most similar topics of a given theme of interest. To accomplish this task, several similarity and distance metrics can be adopted. In this paper, we provide a comparison of the state-of-the-art topic similarity measures and propose novel metrics based on word embeddings. The proposed measures can overcome some limitations of the existing approaches, highlighting good capabilities in terms of several topic performance measures on benchmark datasets.},
	language = {en},
	booktitle = {Natural {Language} {Processing} and {Information} {Systems}},
	publisher = {Springer International Publishing},
	author = {Terragni, Silvia and Fersini, Elisabetta and Messina, Enza},
	editor = {Métais, Elisabeth and Meziane, Farid and Horacek, Helmut and Kapetanios, Epaminondas},
	year = {2021},
	keywords = {Topic modeling, Topic similarity, Word embeddings},
	pages = {33--45},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/VRVBWPVM/Terragni et al. - 2021 - Word Embedding-Based Topic Similarity Measures.pdf:application/pdf},
}

@inproceedings{hashemikamangar2020,
	title = {Children {Semantic} {Network} {Growth}: {A} {Graph} {Theory} {Analysis}},
	shorttitle = {Children {Semantic} {Network} {Growth}},
	doi = {10.1109/ICBME51989.2020.9319438},
	abstract = {In this study, we aim to investigate how children's language develops. To do so, we apply the network model of language and examine the graph-theoretic properties of Word2Vec semantic networks of children through development. The networks are made of words children learn prior to the age of 30 months as the nodes. The links in the word-embedding networks are built from the cosine vector similarity of words normatively acquired by children prior to 2½ years of age. By exploiting some graph measures such as the clustering coefficient and path length, the growth pattern of these semantic networks will be revealed. The small-world property allows for high amounts of local structure combined with global access. Within these semantic networks, there is a considerable local structure in the form of clusters of words. For global structure, some nodes act like bridges. They are actually the hubs of the network and connect the clusters which are semantically far-away. We explore the small-world property of these semantic networks and their changes through language development. The results demonstrate that the Word2Vec semantic networks of children show the small-world property from the early age of several months.},
	booktitle = {2020 27th {National} and 5th {International} {Iranian} {Conference} on {Biomedical} {Engineering} ({ICBME})},
	author = {Hashemikamangar, Somayeh Sadat and Bakouie, Fatemeh and Gharibzadeh, Shahriar},
	month = nov,
	year = {2020},
	keywords = {Semantics, Vocabulary, Language Development, Biomedical engineering, Biomedical measurement, Context modeling, Level measurement, Network Analysis, Pediatrics, Semantic Networks, Small-world Networks, Word embedding},
	pages = {318--321},
	file = {IEEE Xplore Abstract Record:/Users/eec35/Zotero/storage/PF6P4FSB/9319438.html:text/html;IEEE Xplore Full Text PDF:/Users/eec35/Zotero/storage/JNW7KP9Y/Hashemikamangar et al. - 2020 - Children Semantic Network Growth A Graph Theory A.pdf:application/pdf},
}

@article{macleod2023,
	title = {Transmitting white monolingual {Anglo}-{American} norms: {A} concept analysis of “quality of language” in parent-child interactions},
	issn = {0142-7164, 1469-1817},
	shorttitle = {Transmitting white monolingual {Anglo}-{American} norms},
	url = {https://www.cambridge.org/core/product/identifier/S014271642300005X/type/journal_article},
	doi = {10.1017/S014271642300005X},
	abstract = {White monolingual Anglo-American values permeate language acquisition research, which extends into public health and educational policies. “Quality of language” in parent-child interactions is often called upon to explain weaknesses in the language development of children who are racialized, experiencing poverty, or bilingual. Indeed, many early intervention approaches build on this premise by aiming to improve the “quality of language” used by parents. We aimed to understand the conceptualizations of “quality of language” in studies of parent-child interaction through the critical lens of Community Cultural Wealth Theory and perspectives from development research across cultures. We completed a Systematic Concept Analysis of articles published from 2010 to 2022 and focused on parent-child interactions in the home environment. Our search identified 972 articles and 78 met the inclusion criteria, but only 45 papers provided a definition. These definitions covered eight conceptualizations but only three were previously described. We also found inequity in the use of this terminology, which focused on children who were bilingual, had disability, or experiencing poverty. Informed by a critical lens, we recommend the use of four new terms to encompass “quality of language.” We also recommend refraining from using this term as it is value-laden, poorly defined, and diminishes culturally sustaining language transmission practices.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Applied Psycholinguistics},
	author = {MacLeod, Andrea A.N. and Demers, Catrine},
	month = mar,
	year = {2023},
	pages = {1--29},
	file = {MacLeod and Demers - 2023 - Transmitting white monolingual Anglo-American norm.pdf:/Users/eec35/Zotero/storage/VSR8RJ89/MacLeod and Demers - 2023 - Transmitting white monolingual Anglo-American norm.pdf:application/pdf},
}

@article{oller2010,
	title = {Automated vocal analysis of naturalistic recordings from children with autism, language delay, and typical development},
	volume = {107},
	issn = {1091-6490},
	doi = {10.1073/pnas.1003882107},
	abstract = {For generations the study of vocal development and its role in language has been conducted laboriously, with human transcribers and analysts coding and taking measurements from small recorded samples. Our research illustrates a method to obtain measures of early speech development through automated analysis of massive quantities of day-long audio recordings collected naturalistically in children's homes. A primary goal is to provide insights into the development of infant control over infrastructural characteristics of speech through large-scale statistical analysis of strategically selected acoustic parameters. In pursuit of this goal we have discovered that the first automated approach we implemented is not only able to track children's development on acoustic parameters known to play key roles in speech, but also is able to differentiate vocalizations from typically developing children and children with autism or language delay. The method is totally automated, with no human intervention, allowing efficient sampling and analysis at unprecedented scales. The work shows the potential to fundamentally enhance research in vocal development and to add a fully objective measure to the battery used to detect speech-related disorders in early childhood. Thus, automated analysis should soon be able to contribute to screening and diagnosis procedures for early disorders, and more generally, the findings suggest fundamental methods for the study of language in natural environments.},
	language = {eng},
	number = {30},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Oller, D. K. and Niyogi, P. and Gray, S. and Richards, J. A. and Gilkerson, J. and Xu, D. and Yapanel, U. and Warren, S. F.},
	month = jul,
	year = {2010},
	pmcid = {PMC2922144},
	pmid = {20643944},
	note = {tex.ids= oller2010a},
	keywords = {Infant, Female, Humans, Language Development Disorders, Male, Language Development, Linear Models, Child, Preschool, Speech Production Measurement, Autistic Disorder, Speech Disorders, Multivariate Analysis},
	pages = {13354--13359},
}

@misc{zotero-3547,
	title = {What {Automated} {Vocal} {Analysis} {Reveals} {About} the {Vocal} {Production} and {Language} {Learning} {Environment} of {Young} {Children} with {Autism} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s10803-009-0902-5},
	urldate = {2023-04-04},
	file = {What Automated Vocal Analysis Reveals About the Vocal Production and Language Learning Environment of Young Children with Autism | SpringerLink:/Users/eec35/Zotero/storage/J462WWX6/s10803-009-0902-5.html:text/html},
}

@article{vandam2015,
	title = {Automated {Vocal} {Analysis} of {Children} with {Hearing} {Loss} and {Their} {Typical} and {Atypical} {Peers}},
	volume = {36},
	issn = {0196-0202},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4478108/},
	doi = {10.1097/AUD.0000000000000138},
	abstract = {Objectives
This study investigated automatic assessment of vocal development in children with hearing loss as compared with children who are typically developing, have language delays, and autism spectrum disorder. Statistical models are examined for performance in a classification model and to predict age within the four groups of children.

Design
The vocal analysis system analyzed over 1900 whole-day, naturalistic acoustic recordings from 273 toddlers and preschoolers comprising children who were typically developing, hard of hearing, language delayed, or autistic.

Results
Samples from children who were hard-of-hearing patterned more similarly to those of typically-developing children than to the language-delayed or autistic samples. The statistical models were able to classify children from the four groups examined and estimate developmental age based on automated vocal analysis.

Conclusions
This work shows a broad similarity between children with hearing loss and typically developing children, although children with hearing loss show some delay in their production of speech. Automatic acoustic analysis can now be used to quantitatively compare vocal development in children with and without speech-related disorders. The work may serve to better distinguish among various developmental disorders and ultimately contribute to improved intervention.},
	number = {4},
	urldate = {2023-04-04},
	journal = {Ear and hearing},
	author = {VanDam, Mark and Oller, D. Kimbrough and Ambrose, Sophie E. and Gray, Sharmistha and Richards, Jeffrey A. and Xu, Dongxin and Gilkerson, Jill and Silbert, Noah H. and Moeller, Mary Pat},
	year = {2015},
	pmid = {25587667},
	pmcid = {PMC4478108},
	pages = {e146--e152},
	file = {PubMed Central Full Text PDF:/Users/eec35/Zotero/storage/2YB8YYDR/VanDam et al. - 2015 - Automated Vocal Analysis of Children with Hearing .pdf:application/pdf},
}

@book{frank2021,
	address = {Cambridge},
	title = {Variability and {Consistency} in {Early} {Language} {Learning}: {The} {Wordbank} {Project}},
	isbn = {978-0-262-04510-0},
	shorttitle = {Variability and {Consistency} in {Early} {Language} {Learning}},
	abstract = {A data-driven exploration of how children's language learning varies across different languages, providing both a theoretical framework and reference.The Wordbank Project examines variability and consistency in children's language learning across different languages and cultures, drawing on Wordbank, an open database with data from more than 75,000 children and twenty-nine languages or dialects. This big data approach makes the book the most comprehensive cross-linguistic analysis to date of early language learning. Moreover, its data-driven picture of which aspects of language learning are consistent across languages suggests constraints on the nature of children's language learning mechanisms. The book provides both a theoretical framework for scholars of language learning, language, and human cognition, and a resource for future research.},
	language = {English},
	publisher = {The MIT Press},
	author = {Frank, Michael C. and Braginsky, Mika and Yurovsky, Daniel and Marchman, Virginia A.},
	month = mar,
	year = {2021},
}

@techreport{richards2009,
	address = {Boulder, CO},
	title = {The {LENA} {Automatic} {Vocalization} {Assessment}},
	url = {https://www.lena.org/wp-content/uploads/2016/07/LTR-08-1_Automatic_Vocalization_Assessment.pdf},
	abstract = {This report describes the development of the LENA Foundation’s automatic vocalization
assessment (AVATM) software. AVA software is designed to provide both parents and
professionals with automatically generated information about the expressive language
development of children ages 2 months to 48 months. Expressive language estimates
are produced based on 12- to 16-hour audio recordings collected in the natural home
environment using the LENA language environment analysis system. AVA software uses
automatic speech recognition technology to categorize and quantify the sounds in child
vocalizations (e.g., protophones and phonemes). These quantitative acoustic information
data (expressed as “phone” and “biphone” frequencies) are reduced to principal
components which are applied as input for age-based multiple linear regression models.
The AVA software utilizes these regression models to generate information about expressive
language development as standard scores, developmental age estimates, and estimated
mean length of utterance (EMLU). AVA expressive language estimates demonstrate
statistical reliability and validity comparable to standard expressive language assessments
commonly administered by speech language pathologists.},
	language = {English},
	urldate = {2023-04-04},
	institution = {The LENA Foundation},
	author = {Richards, Jeffrey A. and Gilkerson, Jill and Paul, Terrance and Xu, Dongxin},
	year = {2009},
	pages = {1--20},
	file = {LTR-08-1_Automatic_Vocalization_Assessment.pdf:/Users/eec35/Zotero/storage/8Y2RR6IA/LTR-08-1_Automatic_Vocalization_Assessment.pdf:application/pdf},
}

@article{richards2017a,
	title = {Automated {Assessment} of {Child} {Vocalization} {Development} {Using} {LENA}},
	volume = {60},
	url = {https://pubs.asha.org/doi/10.1044/2017_JSLHR-L-16-0157},
	doi = {10.1044/2017_JSLHR-L-16-0157},
	abstract = {Purpose 

To produce a novel, efficient measure of children's expressive vocal development on the basis of automatic vocalization assessment (AVA), child vocalizations were automatically identified and extracted from audio recordings using Language Environment Analysis (LENA) System technology.

Method 

Assessment was based on full-day audio recordings collected in a child's unrestricted, natural language environment. AVA estimates were derived using automatic speech recognition modeling techniques to categorize and quantify the sounds in child vocalizations (e.g., protophones and phonemes). These were expressed as phone and biphone frequencies, reduced to principal components, and inputted to age-based multiple linear regression models to predict independently collected criterion-expressive language scores. From these models, we generated vocal development AVA estimates as age-standardized scores and development age estimates.

Result 

AVA estimates demonstrated strong statistical reliability and validity when compared with standard criterion expressive language assessments.

Conclusions 

Automated analysis of child vocalizations extracted from full-day recordings in natural settings offers a novel and efficient means to assess children's expressive vocal development. More research remains to identify specific mechanisms of operation.},
	number = {7},
	urldate = {2023-04-04},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Richards, Jeffrey A. and Xu, Dongxin and Gilkerson, Jill and Yapanel, Umit and Gray, Sharmistha and Paul, Terrance},
	month = jul,
	year = {2017},
	note = {tex.ids= richards2017
publisher: American Speech-Language-Hearing Association},
	pages = {2047--2063},
}

@article{tadic2013a,
	title = {Story discourse and use of mental state language between mothers and school-aged children with and without visual impairment},
	volume = {48},
	issn = {1368-2822},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4229064/},
	doi = {10.1111/1460-6984.12040},
	abstract = {Background
Lack of sight compromises insight into other people’s mental states. Little is known about the role of maternal language in assisting the development of mental state language in children with visual impairment (VI).

Aims
To investigate mental state language strategies of mothers of school-aged children with VI and to compare these with mothers of comparable children with typically developing vision. To investigate whether the characteristics of mother–child discourse were associated with the child’s socio-communicative competence.

Methods \& Procedures
Mother–child discourse with twelve 6–12-year-old children with VI was coded during a shared book-reading narrative and compared with 14 typically sighted children matched in age and verbal ability.

Outcomes \& Results
Mothers of children with VI elaborated more and made significantly more references to story characters’ mental states and descriptive elaborations than mothers of sighted children. Mental state elaborations of mothers in the VI group related positively with the level produced by their children, with the association remaining after mothers’ overall verbosity and children’s developmental levels were controlled for. Frequency of maternal elaborations, including their mental state language, was related to socio-communicative competence of children with VI.

Conclusions \& Implications
The findings offer insights into the potential contribution of maternal verbal scaffolding to mentalistic language and social–communicative competences of children with VI.},
	number = {6},
	urldate = {2023-04-11},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Tadić, Valerija and Pring, Linda and Dale, Naomi},
	year = {2013},
	pmcid = {PMC4229064},
	pmid = {24165364},
	note = {tex.ids= tadic2013},
	keywords = {Blind, Child, Child Behavior, Child Development, Child Language, Communication, Female, Humans, Language Development, Male, mental state language, mother-child discourse, Mother-Child Relations, Mothers, Narration, Reading, Social Behavior, Vision Disorders, visual impairment},
	pages = {679--688},
	file = {PubMed Central Full Text PDF:/Users/eec35/Zotero/storage/45DIVQI9/Tadić et al. - 2013 - Story discourse and use of mental state language b.pdf:application/pdf},
}

@article{bergelson2019,
	title = {Day by day, hour by hour: {Naturalistic} language input to infants},
	volume = {22},
	issn = {1363-755X, 1467-7687},
	shorttitle = {Day by day, hour by hour},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/desc.12715},
	doi = {10.1111/desc.12715},
	language = {en},
	number = {1},
	urldate = {2023-04-13},
	journal = {Developmental Science},
	author = {Bergelson, Elika and Amatuni, Andrei and Dailey, Shannon and Koorathota, Sharath and Tor, Shaelise},
	month = jan,
	year = {2019},
	pmcid = {PMC6294661},
	pmid = {30094888},
	note = {tex.ids= bergelson2019b},
	keywords = {Language, Infant, Female, Humans, Male, Language Development, Video Recording, Time Factors},
	pages = {e12715},
	file = {Accepted Version:/Users/eec35/Zotero/storage/W65KHHUF/Bergelson et al. - 2019 - Day by day, hour by hour Naturalistic language in.pdf:application/pdf},
}

@article{dote-kwan1995,
	title = {Impact of {Mothers}’ {Interactions} on the {Development} of {Their} {Young} {Visually} {Impaired} {Children}},
	volume = {89},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X9508900109},
	doi = {10.1177/0145482X9508900109},
	abstract = {This article reports on a study of the relationship between mother-child interactions and children's development for 18 children, aged 20–36 months with severe visual impairments and no other known handicapping condition. The study found that mother-responsive behaviors were positively related to the children's development, whereas mother-initiated behaviors were either negatively related or not related.},
	language = {en},
	number = {1},
	urldate = {2021-06-21},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Dote-Kwan, J.},
	month = jan,
	year = {1995},
	note = {Publisher: SAGE Publications Inc},
	keywords = {early blindness},
	pages = {46--58},
}

@phdthesis{mcrae2002,
	address = {Toronto, Canada},
	title = {Attachment in blind infants : a systematic investigation using {Ainsworth}'s {Strange} {Situation}.},
	url = {https://library-archives.canada.ca/eng/services/services-libraries/theses/Pages/item.aspx?idNumber=55682060},
	abstract = {The purpose of this study was to examine the quality of attachment that exists between blind infants and their mothers. The sample included 16 mothers and blind infants who were videotaped in the Ainsworth Strange Situation, a standardized measure of infant-mother attachment. The mothers also participated in a semi-structured interview designed to provide information regarding the infants' behaviour at home and in the community, amidst both familiar and unfamiliar people. The data were analyzed by comparing the results of the Strange Situation Procedure to normative data and also by using a Muhiple-Case Analysis of other descriptive information. This study showed that the infants who were partially sighted (yet still legally blind) generally behaved in a similar manner to sighted children with respect to their attachment behaviour at home, in the community and during the Ainsworth Strange Situation. The attachment behaviour of infants who were totally blind, however, generally differed from that of sighted children in the Ainsworth Strange Situation, as well in home and community contexts. Infants who were totally blind from birth were more often classified as insecurely attached, Category A, (80\%), as compared to normative samples (22\%). A rationale based on Culture theory, is developed to explain why the totally blind infants react differently from children with some sight. Lastly, limitations on the applicability of the Attachment Theory and Ainsworth's Strange Situation procedure when used on totally blind children were identified.},
	language = {eng},
	urldate = {2023-04-19},
	school = {University of Toronto},
	author = {McRae, Kelly Anne},
	year = {2002},
	note = {Last Modified: 2022-09-01},
	file = {Snapshot:/Users/eec35/Zotero/storage/DX23GC8K/item.html:text/html},
}

@article{yamashita2007a,
	title = {A {Stepwise} {AIC} {Method} for {Variable} {Selection} in {Linear} {Regression}},
	volume = {36},
	issn = {0361-0926},
	url = {https://doi.org/10.1080/03610920701215639},
	doi = {10.1080/03610920701215639},
	abstract = {In this article, we study stepwise AIC method for variable selection comparing with other stepwise method for variable selection, such as, Partial F, Partial Correlation, and Semi-Partial Correlation in linear regression modeling. Then we show mathematically that the stepwise AIC method and other stepwise methods lead to the same method as Partial F. Hence, there are more reasons to use the stepwise AIC method than the other stepwise methods for variable selection, since the stepwise AIC method is a model selection method that can be easily managed and can be widely extended to more generalized models and applied to non normally distributed data. We also treat problems that always appear in applications, that are validation of selected variables and problem of collinearity.},
	number = {13},
	urldate = {2023-04-19},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Yamashita, Toshie and Yamashita, Keizo and Kamimura, Ryotaro},
	month = oct,
	year = {2007},
	note = {tex.ids= yamashita2007
\_eprint: https://doi.org/10.1080/03610920701215639
publisher: Taylor \& Francis},
	keywords = {AIC, Collinearity, Linear regression, Partial correlation, Partial F, Primary 62J05, Secondary 62J99, Semi-partial correlation, Stepwise variable selection, Validation},
	pages = {2395--2403},
}

@misc{familyconnect,
	title = {Understanding the {Stages} of {Language} {Development} for {Babies} {Who} {Are} {Blind}},
	url = {https://familyconnect.org/browse-by-age/infants-and-toddlers/growth-and-development-iandt/language-development/},
	abstract = {Repeating or echoing what other people say is a stage all children go through. It’s a way of practicing speech and learning about language and communication. For blind and visually impaired children, this stage sometimes seems to last a long time. Language is abstract. Words stand for real people, concepts, or things. Until your child … Continued},
	language = {en-US},
	urldate = {2023-04-21},
	journal = {FamilyConnect},
	author = {FamilyConnect},
	file = {Snapshot:/Users/eec35/Zotero/storage/Q3XX3QM4/language-development.html:text/html},
}

@misc{chernyak,
	title = {3 {Ways} to {Teach} {Your} {Blind} or {Visually} {Impaired} {Child} to {Talk}},
	url = {https://www.wikihow.life/Teach-Your-Blind-or-Visually-Impaired-Child-to-Talk},
	urldate = {2023-04-21},
	journal = {WikiHow},
	author = {Chernyak, Paul},
	file = {3 Ways to Teach Your Blind or Visually Impaired Child to Talk:/Users/eec35/Zotero/storage/8NLNP82U/Teach-Your-Blind-or-Visually-Impaired-Child-to-Talk.html:text/html},
}

@article{bergelson2022a,
	title = {Everyday language input and production in 1001 children from 6 continents},
	author = {Bergelson, Elika and Soderstrom, Melanie and Schwarz, Iris-Corinna and Rowland, Caroline and Ramirez-Esparza, Nairan and Hamrick, Lisa and Marklund, Ellen and Kalashnikova, Marina and Guez, Ava and Casillas, Marisa},
	year = {2022},
	note = {Publisher: PsyArXiv},
}

@article{bergelson2019c,
	title = {What {Do} {North} {American} {Babies} {Hear}? {A} large-scale cross-corpus analysis},
	volume = {22},
	issn = {1467-7687},
	shorttitle = {What {Do} {North} {American} {Babies} {Hear}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12724},
	doi = {10.1111/desc.12724},
	abstract = {A range of demographic variables influences how much speech young children hear. However, because studies have used vastly different sampling methods, quantitative comparison of interlocking demographic effects has been nearly impossible, across or within studies. We harnessed a unique collection of existing naturalistic, day-long recordings from 61 homes across four North American cities to examine language input as a function of age, gender, and maternal education. We analyzed adult speech heard by 3- to 20-month-olds who wore audio recorders for an entire day. We annotated speaker gender and speech register (child-directed or adult-directed) for 10,861 utterances from female and male adults in these recordings. Examining age, gender, and maternal education collectively in this ecologically valid dataset, we find several key results. First, the speaker gender imbalance in the input is striking: children heard 2–3× more speech from females than males. Second, children in higher-maternal education homes heard more child-directed speech than those in lower-maternal education homes. Finally, our analyses revealed a previously unreported effect: the proportion of child-directed speech in the input increases with age, due to a decrease in adult-directed speech with age. This large-scale analysis is an important step forward in collectively examining demographic variables that influence early development, made possible by pooled, comparable, day-long recordings of children's language environments. The audio recordings, annotations, and annotation software are readily available for reuse and reanalysis by other researchers.},
	language = {en},
	number = {1},
	urldate = {2023-04-21},
	journal = {Developmental Science},
	author = {Bergelson, Elika and Casillas, Marisa and Soderstrom, Melanie and Seidl, Amanda and Warlaumont, Anne S. and Amatuni, Andrei},
	year = {2019},
	pmcid = {PMC6294666},
	pmid = {30369005},
	note = {tex.ids= bergelson2018, bergelson2019a
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12724},
	keywords = {language development, Infant, Female, Humans, Male, Language Development, Adult, Child, Preschool, Speech Perception, Educational Status, United States, Sex Factors, linguistic input, addressee, child directed speech, Demography, gender, maternal education, Tape Recording},
	pages = {e12724},
	file = {Attachment:/Users/eec35/Zotero/storage/F4WGTGNG/Bergelson et al. - 2018 - What Do North American Babies Hear A large-scale cross-corpus analysis.pdf:application/pdf;Full Text PDF:/Users/eec35/Zotero/storage/JL95LH6S/Bergelson et al. - 2019 - What Do North American Babies Hear A large-scale .pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/Q835ZRA6/desc.html:text/html},
}

@article{brugman2009,
	title = {Annotating {Multimedia} / {Multi}-modal resources with {ELAN}},
	abstract = {This paper shows the actual state of development of the manual annotation tool ELAN. It presents usage requirements from three different groups of users and how one annotation model and a number of generic design principles guided the choices made during the development process of ELAN.},
	journal = {Proceedings of the Fourth International Conference on Language Resources and Evaluation},
	author = {Brugman, Hennie and Russel, Albert},
	month = mar,
	year = {2009},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/PVQV9GWE/Brugman and Russel - 2009 - Annotating Multimedia  Multi-modal resources with.pdf:application/pdf},
}

@article{babineau2022,
	title = {Learning to predict and predicting to learn: {Before} and beyond the syntactic bootstrapper},
	volume = {0},
	issn = {1048-9223},
	shorttitle = {Learning to predict and predicting to learn},
	url = {https://doi.org/10.1080/10489223.2022.2078211},
	doi = {10.1080/10489223.2022.2078211},
	abstract = {Young children can exploit the syntactic context of a novel word to narrow down its probable meaning. This is syntactic bootstrapping. A learner that uses syntactic bootstrapping to foster lexical acquisition must first have identified the semantic information that a syntactic context provides. Based on the semantic seed hypothesis, children discover the semantic predictiveness of syntactic contexts by tracking the distribution of familiar words. We propose that these learning mechanisms relate to a larger cognitive model: the predictive processing framework. According to this model, we perceive and make sense of the world by constantly predicting what will happen next in a probabilistic fashion. We outline evidence that prediction operates within language acquisition and show how this framework helps us understand the way lexical knowledge refines syntactic predictions and how syntactic knowledge refines predictions about novel words’ meanings. The predictive processing framework entails that learners can adapt to recent information and update their linguistic model. Here we review some of the recent experimental work showing that the type of prediction preschool children make from a syntactic context can change when they are presented with contrary evidence from recent input. We end by discussing some challenges of applying the predictive processing framework to syntactic bootstrapping and propose new avenues to investigate in future work.},
	number = {0},
	urldate = {2023-01-23},
	journal = {Language Acquisition},
	author = {Babineau, Mireille and Havron, Naomi and Dautriche, Isabelle and de Carvalho, Alex and Christophe, Anne},
	month = jun,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10489223.2022.2078211},
	pages = {1--24},
	file = {Submitted Version:/Users/eec35/Zotero/storage/44TXWRPZ/Babineau et al. - 2022 - Learning to predict and predicting to learn Befor.pdf:application/pdf},
}

@article{babineau2021,
	title = {Familiar words can serve as a semantic seed for syntactic bootstrapping},
	volume = {24},
	issn = {1467-7687},
	doi = {10.1111/desc.13010},
	abstract = {Young children can exploit the syntactic context of a novel word to narrow down its probable meaning. But how do they learn which contexts are linked to which semantic features in the first place? We investigate if 3- to 4-year-old children (n = 60) can learn about a syntactic context from tracking its use with only a few familiar words. After watching a 5-min training video in which a novel function word (i.e., 'ko') replaced either personal pronouns or articles, children were able to infer semantic properties for novel words co-occurring with the newly learned function word (i.e., objects vs. actions). These findings implicate a mechanism by which a distributional analysis, associated with a small vocabulary of known words, could be sufficient to identify some properties associated with specific syntactic contexts.},
	language = {eng},
	number = {1},
	journal = {Developmental Science},
	author = {Babineau, Mireille and de Carvalho, Alex and Trueswell, John and Christophe, Anne},
	month = jan,
	year = {2021},
	pmid = {32589813},
	pmcid = {PMC7750202},
	pages = {e13010},
}

@misc{campbellsubmitted,
	title = {The {Role} of {Vision} in the {Acquisition} of {Words}: {Vocabulary} {Development} in {Blind} {Toddlers}},
	url = {https://osf.io/uw6zm/},
	doi = {10.17605/OSF.IO/UW6ZM},
	author = {Campbell, Erin E. and Casillas, Robyn and Bergelson, Elika},
}

@article{gleitman1990,
	title = {The {Structural} {Sources} of {Verb} {Meanings}},
	volume = {1},
	issn = {1048-9223},
	url = {https://www.jstor.org/stable/20011341},
	number = {1},
	urldate = {2021-04-16},
	journal = {Language Acquisition},
	author = {Gleitman, Lila},
	year = {1990},
	note = {Publisher: Taylor \& Francis, Ltd.},
	pages = {3--55},
}

@article{lynott2020,
	title = {The {Lancaster} {Sensorimotor} {Norms}: multidimensional measures of perceptual and action strength for 40,000 {English} words},
	volume = {52},
	issn = {1554-3528},
	shorttitle = {The {Lancaster} {Sensorimotor} {Norms}},
	doi = {10.3758/s13428-019-01316-z},
	abstract = {Sensorimotor information plays a fundamental role in cognition. However, the existing materials that measure the sensorimotor basis of word meanings and concepts have been restricted in terms of their sample size and breadth of sensorimotor experience. Here we present norms of sensorimotor strength for 39,707 concepts across six perceptual modalities (touch, hearing, smell, taste, vision, and interoception) and five action effectors (mouth/throat, hand/arm, foot/leg, head excluding mouth/throat, and torso), gathered from a total of 3,500 individual participants using Amazon's Mechanical Turk platform. The Lancaster Sensorimotor Norms are unique and innovative in a number of respects: They represent the largest-ever set of semantic norms for English, at 40,000 words × 11 dimensions (plus several informative cross-dimensional variables), they extend perceptual strength norming to the new modality of interoception, and they include the first norming of action strength across separate bodily effectors. In the first study, we describe the data collection procedures, provide summary descriptives of the dataset, and interpret the relations observed between sensorimotor dimensions. We then report two further studies, in which we (1) extracted an optimal single-variable composite of the 11-dimension sensorimotor profile (Minkowski 3 strength) and (2) demonstrated the utility of both perceptual and action strength in facilitating lexical decision times and accuracy in two separate datasets. These norms provide a valuable resource to researchers in diverse areas, including psycholinguistics, grounded cognition, cognitive semantics, knowledge representation, machine learning, and big-data approaches to the analysis of language and conceptual representations. The data are accessible via the Open Science Framework (http://osf.io/7emr6/) and an interactive web application (https://www.lancaster.ac.uk/psychology/lsnorms/).},
	language = {eng},
	number = {3},
	journal = {Behavior Research Methods},
	author = {Lynott, Dermot and Connell, Louise and Brysbaert, Marc and Brand, James and Carney, James},
	month = jun,
	year = {2020},
	pmid = {31832879},
	pmcid = {PMC7280349},
	pages = {1271--1291},
	file = {Full Text:/Users/eec35/Zotero/storage/DH522T4K/Lynott et al. - 2020 - The Lancaster Sensorimotor Norms multidimensional.pdf:application/pdf},
}

@article{muraki2022,
	title = {Quantifying children's sensorimotor experience: {Child} body-object interaction ratings for 3359 {English} words},
	volume = {54},
	issn = {1554-3528},
	shorttitle = {Quantifying children's sensorimotor experience},
	doi = {10.3758/s13428-022-01798-4},
	abstract = {Body-object interaction (BOI) ratings measure how easily the human body can physically interact with a word's referent. Previous research has found that words higher in BOI tend to be processed more quickly and accurately in tasks such as lexical decision, semantic decision, and syntactic classification, suggesting that sensorimotor information is an important aspect of lexical knowledge. However, limited research has examined the importance of sensorimotor information from a developmental perspective. One barrier to addressing such theoretical questions has been a lack of semantic dimension ratings that take into account child sensorimotor experience. The goal of the current study was to collect Child BOI rating norms. Parents of children aged 5 to 9 years old were asked to rate words according to how easily an average 6-year-old child can interact with each word's referent. The relationships of Child and Adult BOI ratings with other lexical semantic dimensions were assessed, as well as the relationships of Child and Adult BOI ratings with age of acquisition. Child BOI ratings were more strongly related to valence and sensory experience ratings than Adult BOI ratings and were a better predictor of three different measures of age of acquisition. The results suggest that child-centric ratings such as those reported here provide a more sensitive measure of children's experience that can be used to address theoretical questions in embodied cognition from a developmental perspective.},
	language = {eng},
	number = {6},
	journal = {Behavior Research Methods},
	author = {Muraki, Emiko J. and Siddiqui, Israa A. and Pexman, Penny M.},
	month = dec,
	year = {2022},
	pmid = {35112287},
	pages = {2864--2877},
	file = {Submitted Version:/Users/eec35/Zotero/storage/2B2HT92C/Muraki et al. - 2022 - Quantifying children's sensorimotor experience Ch.pdf:application/pdf},
}

@article{perez-pereira2001,
	title = {The use of {Directives} in {Verbal} {Interactions} between {Blind} {Children} and their {Mothers}},
	volume = {95},
	doi = {10.1177/0145482x0109500302},
	abstract = {Verbal interactions between three mothers and their young blind children, with special attention to the use of maternal directives, were examined. It was found that a simple analysis of maternal di...},
	number = {3},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Pérez-Pereira, Miguel and Conti-Ramsden, Gina},
	month = mar,
	year = {2001},
	doi = {10.1177/0145482x0109500302},
	note = {MAG ID: 68408239},
	pages = {133--149},
}

@article{fraiberg1975,
	title = {The development of human attachments in infants blind from birth},
	volume = {21},
	issn = {1535-0266},
	abstract = {Normative data on the development of social and motor responses of blind infants was provided by home observations of 5 male and 5 female children 1-24 mo old. The social behaviors studied were (a) tactile discrimination of familiar and unfamiliar faces, (b) smiling to a familiar voice, (c) separation protest, (d) stranger avoidance, and (e) person permanence. Methods for studying these behaviors in blind children are explained, with discussion of their equivalents in sighted children. Norms for 10 gross motor behaviors are presented and compared with the identical behaviors in sighted children. Examples from observational protocols illustrate the methods and criteria employed. (36 ref) (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
	journal = {Merrill-Palmer Quarterly},
	author = {Fraiberg, Selma},
	year = {1975},
	note = {Place: US
Publisher: Wayne State University Press},
	keywords = {Blindness, Infant Development, Motor Development, Psychosocial Development},
	pages = {315--334},
	file = {Snapshot:/Users/eec35/Zotero/storage/FDLIGTX6/1976-12554-001.html:text/html},
}

@article{sandbank2016,
	title = {The {Association} {Between} {Parental} {Mean} {Length} of {Utterance} and {Language} {Outcomes} in {Children} {With} {Disabilities}: {A} {Correlational} {Meta}-{Analysis}},
	volume = {25},
	issn = {1558-9110},
	shorttitle = {The {Association} {Between} {Parental} {Mean} {Length} of {Utterance} and {Language} {Outcomes} in {Children} {With} {Disabilities}},
	doi = {10.1044/2015_AJSLP-15-0003},
	abstract = {PURPOSE: The purpose of this correlational meta-analysis was to examine the association between parental utterance length and language outcomes in children with disabilities and whether this association varies according to other child characteristics, such as age and disability type. This association can serve as a starting point for language intervention practices for children with disabilities.
METHOD: We conducted a systematic search of 42 electronic databases to identify relevant studies. Twelve studies reporting on a total of 13 populations (including 257 participants) were identified. A random-effects model was used to estimate a combined effect size across all studies as well as separate effect sizes across studies in each disability category.
RESULTS: The combined effect size across all studies suggests a weak positive association between parental input length and child language outcomes. However, subgroup analyses within disability categories suggest that this association may differ for children with autism. Results of 4 studies including 47 children with autism show that parental input length is strongly associated with positive language outcomes in this population.
CONCLUSIONS: Present evidence suggests that clinicians should reconsider intervention practices that prescribe shorter, grammatically incomplete utterances, particularly when working with children with autism.},
	language = {eng},
	number = {2},
	journal = {American Journal of Speech-Language Pathology},
	author = {Sandbank, Micheal and Yoder, Paul},
	month = may,
	year = {2016},
	pmid = {27088766},
	keywords = {Language, Child, Humans, Adult, Parents, Autistic Disorder, Parent-Child Relations, Disabled Children},
	pages = {240--251},
}

@article{nagayoshi2017,
	title = {Related visual impairment to mother-infant interaction and development in infants with bilateral retinoblastoma},
	volume = {28},
	issn = {1532-2122},
	doi = {10.1016/j.ejon.2017.02.002},
	abstract = {PURPOSE: This study was conducted with infants diagnosed with bilateral retinoblastoma (RB) and their mothers. It explored characteristics of the mother-infant interaction, the infants' developmental characteristics and related risk factors.
METHOD: Cross-sectional statistical analysis was performed with 18 dyads of one-year-old infants with bilateral RB and their mothers.
RESULTS: Using the Japanese Nursing Child Assessment Teaching Scale (JNCATS) results showed that infants with RB had significantly lower scores compared to normative Japanese scores on all of the infants' subscales and "Child's contingency" (p {\textless} 0.01). Five infants with visual impairment at high risk of developmental problems had a pass rate of 0\% on six JNCATS items. There were positive correlations between Developmental quotients (DQ) and JNCATS score of "Responsiveness to caregiver" (ρ = 0.50, p {\textless} 0.05) and DQ and "Child's contingency" (ρ = 0.47, p {\textless} 0.05).
CONCLUSIONS: Infants with visual impairment were characterized by high likelihood of developmental delays and problematic behaviors; they tended not to turn their face or eyes toward their mothers, smile in response to their mothers' talking to them or the latter's changing body language or facial expressions, or react in a contingent manner in their interactions. These infant behaviors noted by their mothers shared similarities with developmental characteristics of children with visual impairments. These findings indicated a need to provide support promoting mother-infant interactions consistent with the developmental characteristics of RB infants with visual impairment.},
	language = {eng},
	journal = {European Journal of Oncology Nursing: The Official Journal of European Oncology Nursing Society},
	author = {Nagayoshi, Michie and Hirose, Taiko and Toju, Kyoko and Suzuki, Shigenobu and Okamitsu, Motoko and Teramoto, Taeko and Omori, Takahide and Kawamura, Aki and Takeo, Naoko},
	month = jun,
	year = {2017},
	pmid = {28478852},
	keywords = {Child, Child Development, Infant, Female, Humans, Male, Adult, Child, Preschool, Vision Disorders, Mother-Child Relations, Mothers, Infant Behavior, Adolescent, Asian People, Cross-Sectional Studies, Japan, Middle Aged, Retinoblastoma, Risk Factors},
	pages = {28--34},
}

@article{troster1992,
	title = {Early social-emotional development in blind infants},
	volume = {18},
	issn = {0305-1862},
	doi = {10.1111/j.1365-2214.1992.tb00355.x},
	abstract = {In order to study the impact of blindness on social and emotional development during the first year of life, the level of social-emotional development was compared in blind and sighted 9- and 12-month-old infants. The five 9-month-old and the 17 12-month-old blind infants were completely blind from birth and exhibited no further serious disabilities. Social-emotional development was assessed with a scale from the Bielefeld Developmental Test for Blind Infants and Preschoolers containing three subscales on emotions, social interaction and impulse control. Compared to non-disabled infants, blind infants exhibited a more limited repertoire of facial expressions and less responsiveness. They less frequently attempted to initiate contact with their mothers (self-initiated interactions) or comply with simple requests and prohibitions than sighted infants. These differences in the social-emotional development of blind and sighted infants are traced back to the effects of blindness on the mother-child interaction. The lack of visual perception appears to impede particularly the acquisition of a dialogue concept.},
	language = {eng},
	number = {4},
	journal = {Child: Care, Health and Development},
	author = {Tröster, H. and Brambring, M.},
	year = {1992},
	pmid = {1386004},
	keywords = {Child, Child Development, Blindness, Infant, Female, Humans, Male, Communication, Infant, Newborn, Mother-Child Relations, Interpersonal Relations, Facial Expression, Disabled Persons, Emotions, Visual Perception},
	pages = {207--227},
}

@article{rogers1984,
	title = {Social {Characteristics} of {Visually} {Impaired} {Infants}' {Play}},
	volume = {3},
	issn = {0271-1214},
	url = {https://doi.org/10.1177/027112148400300409},
	doi = {10.1177/027112148400300409},
	abstract = {This cross-sectional study explores the extent to which the visually impaired infant and mother are able to use play to facilitate rewarding social interactions. Mother-child interactions were observed in 21 visually impaired infants and 16 nonhandicapped infants. From videotape ratings of five child behaviors and five maternal behaviors, significant differences were found in several variables. Visually impaired infants demonstrated fewer periods of positive vocalization and positive responses to the mother, fewer social initiations to the mother, more negative vocalizations, more periods of negative affect, and more ignoring of the mother than did the controls. Mothers of visually impaired infants demonstrated less en-facing positioning, fewer positive vocalizations, and more periods of neutral vocalizations than did the mothers of nonhandicapped children.},
	language = {en},
	number = {4},
	urldate = {2023-04-21},
	journal = {Topics in Early Childhood Special Education},
	author = {Rogers, Sally J. and Puchalski, Carol B.},
	month = jan,
	year = {1984},
	note = {Publisher: SAGE Publications Inc},
	pages = {52--56},
	file = {SAGE PDF Full Text:/Users/eec35/Zotero/storage/E6AQ72I4/Rogers and Puchalski - 1984 - Social Characteristics of Visually Impaired Infant.pdf:application/pdf},
}

@incollection{grice1975,
	address = {New York San Francisco London},
	title = {Logic and {Conversation}},
	isbn = {978-0-12-785423-6},
	language = {xxx},
	booktitle = {Syntax and semantics},
	publisher = {Academic press, Harcourt Brace Jovanovich},
	author = {Grice, Herbert Paul},
	year = {1975},
	note = {tex.ids= kimball1975a},
}

@misc{bratt2022,
	title = {morphemepiece: {Morpheme} {Tokenization}},
	copyright = {Apache License (≥ 2)},
	shorttitle = {morphemepiece},
	url = {https://CRAN.R-project.org/package=morphemepiece},
	abstract = {Tokenize text into morphemes. The morphemepiece algorithm uses a lookup table to determine the morpheme breakdown of words, and falls back on a modified wordpiece tokenization algorithm for words not found in the lookup table.},
	urldate = {2023-04-21},
	author = {Bratt, Jonathan and Harmon, Jon and Learning, Bedford Freeman \& Worth Pub Grp LLC DBA Macmillan},
	month = apr,
	year = {2022},
}

@misc{wijffels2023,
	title = {{UDPipe}},
	url = {https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html#annotate-your-text},
	abstract = {The data preparation part of any Natural Language Processing flow consists of a number of important steps: Tokenization (1), Parts of Speech tagging (2), Lemmatization (3) and Dependency Parsing (4). This package allows you to do out-of-the-box annotation of these 4 steps and also allows you to train your own annotator models directly from R.},
	urldate = {2023-04-21},
	author = {Wijffels, Jan},
	month = jan,
	year = {2023},
}

@techreport{xu2009,
	address = {Boulder, CO},
	title = {Reliability of the {LENA} {Language} {Environment} {Analysis} {System} in {Young} {Children}’s {Natural} {Home} {Environment}},
	url = {https://www.lena.org/wp-content/uploads/2016/07/LTR-05-2_Reliability.pdf},
	abstract = {The LENA language environment analysis system was designed to provide information about the language environment of infants and toddlers. In this technical report, we describe the reliability of the LENA System in terms of segmentation, adult word counts, and child vocalizations. We also describe unique sources of variability associated with data collection in the natural home environment.},
	language = {English},
	urldate = {2023-04-22},
	institution = {The LENA Foundation},
	author = {Xu, Dongxin and Yapanel, Umit and Gray, Sharmistha},
	month = feb,
	year = {2009},
	pages = {1--16},
	file = {LTR-05-2_Reliability.pdf:/Users/eec35/Zotero/storage/QY52AAWW/LTR-05-2_Reliability.pdf:application/pdf},
}

@article{cristia2021b,
	title = {A thorough evaluation of the {Language} {Environment} {Analysis} ({LENA}) system},
	volume = {53},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-020-01393-5},
	doi = {10.3758/s13428-020-01393-5},
	abstract = {In the previous decade, dozens of studies involving thousands of children across several research disciplines have made use of a combined daylong audio-recorder and automated algorithmic analysis called the LENAⓇ system, which aims to assess children’s language environment. While the system’s prevalence in the language acquisition domain is steadily growing, there are only scattered validation efforts on only some of its key characteristics. Here, we assess the LENAⓇ system’s accuracy across all of its key measures: speaker classification, Child Vocalization Counts (CVC), Conversational Turn Counts (CTC), and Adult Word Counts (AWC). Our assessment is based on manual annotation of clips that have been randomly or periodically sampled out of daylong recordings, collected from (a) populations similar to the system’s original training data (North American English-learning children aged 3-36 months), (b) children learning another dialect of English (UK), and (c) slightly older children growing up in a different linguistic and socio-cultural setting (Tsimane’ learners in rural Bolivia). We find reasonably high accuracy in some measures (AWC, CVC), with more problematic levels of performance in others (CTC, precision of male adults and other children). Statistical analyses do not support the view that performance is worse for children who are dissimilar from the LENAⓇ original training set. Whether LENAⓇ results are accurate enough for a given research, educational, or clinical application depends largely on the specifics at hand. We therefore conclude with a set of recommendations to help researchers make this determination for their goals.},
	language = {en},
	number = {2},
	urldate = {2023-04-22},
	journal = {Behavior Research Methods},
	author = {Cristia, Alejandrina and Lavechin, Marvin and Scaff, Camila and Soderstrom, Melanie and Rowland, Caroline and Räsänen, Okko and Bunce, John and Bergelson, Elika},
	month = apr,
	year = {2021},
	note = {tex.ids= cristia2021, cristia2021a},
	keywords = {LENA, English, Adult Word Count, Agreement, Child Vocalization Count, Conversational Turn Count, Human transcription, Measurement error, Method comparison, Reliability, Speech technology, Tsimane’},
	pages = {467--486},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/NTI57AKQ/Cristia et al. - 2021 - A thorough evaluation of the Language Environment .pdf:application/pdf},
}

@techreport{gilkerson2008,
	address = {Boulder, CO},
	title = {The {LENA} {Natural} {Language} {Study}},
	url = {https://www.lena.org/wp-content/uploads/2016/07/LTR-02-2_Natural_Language_Study.pdf},
	abstract = {This paper describes the multiphase LENA Natural Language Study, an ongoing data
collection effort designed to investigate the language environment of infants and
toddlers. Data collected contributes to product development and normative information
for use with the LENA System and child development research. Phase I study participants
were representative of the US Census with respect to mothers’ attained education and
consisted of 329 normally developing infants and toddlers from monolingual Englishspeaking households living in the Denver-metro area. Participants provided day-long
audio recordings of their natural language environment once a month, and certified
speech language pathologists assessed participant language ability independently
through standardized assessments. A subset of 80 Phase I participants has continued to
provide monthly recordings in Phase II of the study. The normative database described
herein contains over 32,000 hours of spontaneous speech data. This paper describes how
normative information was derived for the Adult Word Count estimates (AWC; adult words
spoken per day), Conversational Turns estimates (CT; adult-child alternations per day), and
Child Vocalization frequency estimates (CV; words, babbles, and “protophones” or prespeech communicative sounds) that are reported in the LENA System.},
	institution = {LENA Foundation},
	author = {Gilkerson, Jill and Richards, Jeffrey A.},
	year = {2008},
}

@article{richards1987,
	title = {Type/{Token} {Ratios}: what do they really tell us?},
	volume = {14},
	doi = {doi:10.1017/s0305000900012885},
	abstract = {Type/Token Ratios have been extensively used in child language
research as an index of lexical diversity. This paper shows that the
measure has frequently failed to discriminate between children at widely
different stages of language development, and that the ratio may in fact
fall as children get older. It is suggested here that such effects are caused
by a negative, though non-linear, relationship between sample size (i.e.
number of tokens) and Type/Token Ratio. Effects of open and closed
class items are considered and an alternative Verbal Diversity measure
is examined. Standardization of the number of tokens before computing
Type/Token Ratios is recommended.},
	number = {2},
	journal = {Journal of Child Language},
	author = {Richards, B.},
	year = {1987},
	pages = {201},
}

@article{choi2020,
	title = {Reciprocal {Influences} {Between} {Parent} {Input} and {Child} {Language} {Skills} in {Dyads} {Involving} {High}‐ and {Low}‐{Risk} {Infants} for {Autism} {Spectrum} {Disorder}},
	volume = {13},
	issn = {1939-3792, 1939-3806},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/aur.2270},
	doi = {10.1002/aur.2270},
	language = {en},
	number = {7},
	urldate = {2023-05-03},
	journal = {Autism Research},
	author = {Choi, Boin and Nelson, Charles A. and Rowe, Meredith L. and Tager‐Flusberg, Helen},
	month = jul,
	year = {2020},
	pages = {1168--1183},
}

@misc{zotero-3781,
	title = {Circumspection in using automated measures: {Talker} gender and addressee affect error rates for adult speech detection in the {Language} {ENvironment} {Analysis} ({LENA}) system {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.3758/s13428-020-01419-y},
	urldate = {2023-05-03},
	file = {Circumspection in using automated measures\: Talker gender and addressee affect error rates for adult speech detection in the Language ENvironment Analysis (LENA) system | SpringerLink:/Users/eec35/Zotero/storage/G87726FK/s13428-020-01419-y.html:text/html},
}

@article{lehet2021,
	title = {Circumspection in using automated measures: {Talker} gender and addressee affect error rates for adult speech detection in the {Language} {ENvironment} {Analysis} ({LENA}) system},
	volume = {53},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-020-01419-y},
	doi = {10.3758/s13428-020-01419-y},
	abstract = {Automatic speech processing devices have become popular for quantifying amounts of ambient language input to children in their home environments. We assessed error rates for language input estimates for the Language ENvironment Analysis (LENA) audio processing system, asking whether error rates differed as a function of adult talkers’ gender and whether they were speaking to children or adults. Audio was sampled from within LENA recordings from 23 families with children aged 4–34 months. Human coders identified vocalizations by adults and children, counted intelligible words, and determined whether adults’ speech was addressed to children or adults. LENA’s classification accuracy was assessed by parceling audio into 100-ms frames and comparing, for each frame, human and LENA classifications. LENA correctly classified adult speech 67\% of the time across families (average false negative rate: 33\%). LENA’s adult word count showed a mean +47\% error relative to human counts. Classification and Adult Word Count error rates were significantly affected by talkers’ gender and whether speech was addressed to a child or an adult. The largest systematic errors occurred when adult females addressed children. Results show LENA’s classifications and Adult Word Count entailed random – and sometimes large – errors across recordings, as well as systematic errors as a function of talker gender and addressee. Due to systematic and sometimes high error in estimates of amount of adult language input, relying on this metric alone may lead to invalid clinical and/or research conclusions. Further validation studies and circumspect usage of LENA are warranted.},
	number = {1},
	journal = {Behavior Research Methods},
	author = {Lehet, Matthew and Arjmandi, Meisam K. and Houston, Derek and Dilley, Laura},
	month = feb,
	year = {2021},
	pages = {113--138},
}

@book{pisani2021,
	title = {Long-form recordings: {From} {A} to {Z}},
	shorttitle = {Long-form recordings},
	url = {https://bookdown.org/alecristia/exelang-book/},
	abstract = {This bookdown contains the scripts of instructional videos created in the context of the ExELang Project (exelang.fr).},
	urldate = {2023-05-03},
	author = {Pisani, Sara and Gautheron, Lucas and Cristia, Alejandrina},
	year = {2021},
	file = {Snapshot:/Users/eec35/Zotero/storage/IC2J2X2F/exelang-book.html:text/html},
}

@techreport{luchkina2020,
	type = {preprint},
	title = {Sixteen-month-olds comprehend unanchored absent reference},
	url = {https://osf.io/5tc6d},
	abstract = {A nascent understanding of absent reference emerges around 12 months: provided with rich contextual support, infants look and point to the location of a displaced object. When can infants understand absent reference without contextual support? Using a procedure modified from Hendrickson and Sundara (2017), 13- and 16-montholds first listened to utterances containing familiar target words, while viewing a checkerboard. Then, two objects – a referent and a distractor (e.g., a cup and a shoe) – appeared on the screen. Only 16-month-olds demonstrated a reliable looking preference for the referents, suggesting that listening to the utterances activated their mental images of the referents. These results establish that at 16 months, infants comprehend reference to absent entities without any contextual support.},
	language = {en},
	urldate = {2023-05-04},
	institution = {Open Science Framework},
	author = {Luchkina, Elena and Xu, Fei and Sobel, David and Morgan, James},
	month = feb,
	year = {2020},
	doi = {10.31219/osf.io/5tc6d},
	file = {Luchkina et al. - 2020 - Sixteen-month-olds comprehend unanchored absent re.pdf:/Users/eec35/Zotero/storage/FYVUE644/Luchkina et al. - 2020 - Sixteen-month-olds comprehend unanchored absent re.pdf:application/pdf},
}

@article{grimminger2020,
	title = {Decontextualized talk in caregivers’ input to 12-month-old children during structured interaction},
	volume = {47},
	issn = {0305-0009, 1469-7602},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/decontextualized-talk-in-caregivers-input-to-12monthold-children-during-structured-interaction/A4E52BB699522B33F5E64164FF75E31D},
	doi = {10.1017/S0305000919000710},
	abstract = {Decontextualized talk is assumed to be used only rarely when children are younger than 30 months. Motivated by Bühler's (1934/1999) linguistic theory that describes different dimensions of (de-)contextualization, we provide evidence that this kind of input can already be found in caregivers’ talking to their 12-month-old children. Such early input is characterized by being decontextualized on some dimensions while being grounded in the immediate context on others. In this way, parents may scaffold understanding of talk about the there-and-then. We also examined whether caregivers adapt decontextualized verbal input to individual trajectories in language development. We observed 59 parent–child interactions within a decorated room when children were 12 months old, and assessed the children's linguistic development at 12 and 24 months of age. However, we did not find differences in the input directed toward children with different trajectories in language development.},
	language = {en},
	number = {2},
	urldate = {2023-05-04},
	journal = {Journal of Child Language},
	author = {Grimminger, Angela and Rohlfing, Katharina J. and Lüke, Carina and Liszkowski, Ulf and Ritterfeld, Ute},
	month = mar,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	keywords = {12-month-olds, decontextualized talk, delayed language development, individual differences},
	pages = {418--434},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/V9UZJ274/Grimminger et al. - 2020 - Decontextualized talk in caregivers’ input to 12-m.pdf:application/pdf},
}

@article{lucariello1987,
	title = {Remembering and planning talk between mothers and children},
	volume = {10},
	issn = {0163-853X},
	url = {https://doi.org/10.1080/01638538709544673},
	doi = {10.1080/01638538709544673},
	abstract = {Three aspects of temporally displaced (TD) talk between mothers and children were explored: the role of the knowledge base in such talk, the effect of mother talk on child talk, and the impact of such talk on the child's knowledge base. Mother‐child (2‐year‐old) speech was observed in three contexts: (a) routine or scripted; (b) free play; and (c) novel play. Such talk occurred almost exclusively in the scripted context and its topics were predominantly based on other routine activities in which the dyad was not presently engaged. These results point to the strong influence of the knowledge base in terms of event schemas (representations of routine activities) in supporting TD talk. Maternal talk was characterized by the use of adverbial temporal markers, hypothetical and conditional expressions, conversational routines, and Wh‐ questions. These aspects of maternal speech indicate “scaffolding” and may facilitate the child's acquisition of the appropriate form, content, and organization of TD talk. Analyses of the relation between TD talk and child knowledge indicated that for past events, maternal speech can mediate information and experience and thereby contribute to and transform the child's world knowledge.},
	number = {3},
	urldate = {2023-05-04},
	journal = {Discourse Processes},
	author = {Lucariello, Joan and Nelson, Katherine},
	month = jul,
	year = {1987},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01638538709544673},
	pages = {219--235},
}

@article{hudson2002,
	title = {"{Do} {You} {Know} {What} {We}'re {Going} to {Do} {This} {Summer}?": {Mothers}' {Talk} to {Preschool} {Children} {About} {Future} {Events}},
	volume = {3},
	issn = {1524-8372},
	shorttitle = {"{Do} {You} {Know} {What} {We}'re {Going} to {Do} {This} {Summer}?},
	url = {https://doi.org/10.1207/S15327647JCD0301_4},
	doi = {10.1207/S15327647JCD0301_4},
	abstract = {Mothers engaged their 21/2- and 4-year-old children in conversations about novel and familiar past and future events. Analyses focused on (a) evidence for style differences in mothers' elicitation of future event talk, (b) the temporal frames of references (past, future, general, and hypothetical) mothers used across conversations, and (c) mothers' use of conventional time terms (e.g., last week, on Sunday). Mothers showed little consistency in style of elicitation over past and future conversations. In conversations about future events, mothers produced more references to future time, more hypothetical references, and more conventional time references. In talking about the past, mothers referred to the past more often and used more sequence terms. Mothers also varied their temporal references when talking about novel and familiar events. Results are discussed in terms of how conversations about future events can contribute to the development of children's concepts of time.},
	number = {1},
	urldate = {2023-05-04},
	journal = {Journal of Cognition and Development},
	author = {Hudson, Judith A.},
	month = feb,
	year = {2002},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/S15327647JCD0301\_4},
	pages = {49--71},
}

@article{rogers1988,
	title = {Development of {Object} {Permanence} in {Visually} {Impaired} {Infants}},
	volume = {82},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X8808200407},
	doi = {10.1177/0145482X8808200407},
	abstract = {The development of object permanence skills in 20 visually impaired infants between the ages of 4 and 25 months was examined longitudinally. Other areas of development which were examined in relationship to object permanence included motor skills, various aspects of language and social adaptation, symbolic play, and stranger and separation distress. Parallels to object permanence development in sighted infants that were found included order of skill acquisition and the span of time across which the skills were mastered. The visually impaired subjects as a group were 8 to 12 months older than the sighted infants at the time of similar object permanence skills, but the greater maturity of the visually impaired subjects seemed to be demonstrated in the lack of A?B error and the ability of visually impaired infants to perform the tasks on the basis of discontinuous sensory information. No relationships between object permanence levels and either symbolic play abilities and separation or stranger distress were found.},
	language = {en},
	number = {4},
	urldate = {2023-05-04},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Rogers, S. J. and Puchalski, C.B.},
	month = apr,
	year = {1988},
	note = {Publisher: SAGE Publications Inc},
	pages = {137--142},
}

@article{kramer1975,
	title = {Infants' {Development} of {Object} {Permanence}: {A} {Refined} {Methodology} and {New} {Evidence} for {Piaget}'s {Hypothesized} {Ordinality}},
	volume = {46},
	issn = {0009-3920},
	shorttitle = {Infants' {Development} of {Object} {Permanence}},
	url = {https://www.jstor.org/stable/1128843},
	doi = {10.2307/1128843},
	abstract = {To investigate Piaget's theory of object concept development, a series of 6 tasks was administered in a combined longitudinal/cross-sectional design incorporating a number of methodological controls. The tasks spanned the entire sensorimotor period and included single versus sequential displacements combined with visible or invisible hidings. 36 infants from 5 to 32 months of age at initial testing were drawn equally from day-care and home settings. All infants received the 6 tasks during each of 3 testing sessions over a 6-month period. Clear evidence was obtained for task ordinality as proposed by Piaget, with ordinality coefficients ranging from .71 to .82 for the 3 testing sessions. Performance changes across the 3 sessions were also ordinal in 80\% of the cases. Expected age, task, and session effects and accompanying interactions were also obtained.},
	number = {1},
	urldate = {2023-05-04},
	journal = {Child Development},
	author = {Kramer, Judith A. and Hill, Kennedy T. and Cohen, Leslie B.},
	year = {1975},
	note = {Publisher: [Wiley, Society for Research in Child Development]},
	pages = {149--155},
	file = {JSTOR Full Text PDF:/Users/eec35/Zotero/storage/X4WSRMMM/Kramer et al. - 1975 - Infants' Development of Object Permanence A Refin.pdf:application/pdf},
}

@article{ganek2018,
	title = {Language {ENvironment} analysis ({LENA}) system investigation of day long recordings in children: {A} literature review},
	volume = {72},
	issn = {0021-9924},
	shorttitle = {Language {ENvironment} analysis ({LENA}) system investigation of day long recordings in children},
	url = {https://www.sciencedirect.com/science/article/pii/S0021992416301861},
	doi = {10.1016/j.jcomdis.2017.12.005},
	abstract = {The Language ENvironment Analysis (LENA) System is a relatively new recording technology that can be used to investigate typical child language acquisition and populations with language disorders. The purpose of this paper is to familiarize language acquisition researchers and speech-language pathologists with how the LENA System is currently being used in research. The authors outline issues in peer-reviewed research based on the device. Considerations when using the LENA System are discussed.},
	language = {en},
	urldate = {2023-05-04},
	journal = {Journal of Communication Disorders},
	author = {Ganek, Hillary and Eriks-Brophy, Alice},
	month = mar,
	year = {2018},
	keywords = {Automated vocal analysis, Language acquisition, LENA System},
	pages = {77--85},
	file = {ScienceDirect Snapshot:/Users/eec35/Zotero/storage/ADAIW9NY/S0021992416301861.html:text/html},
}

@article{magimairaj2022,
	title = {A {Systematic} {Review} of the {Effects} of {LENA}-based {Feedback} on {Parent}-{Child} {Language} {Interactions} in {Families} with {Young} {Children}},
	volume = {7},
	issn = {2381-2362},
	url = {https://digitalcommons.usu.edu/jehdi/vol7/iss3/6},
	doi = {https://doi.org/10.26077/6c72-973b},
	number = {3},
	journal = {Journal of Early Hearing Detection and Intervention},
	author = {Magimairaj, Beula and Nagaraj, Naveen and Caballero, Ana and Munoz, Karen and White, Karl},
	month = nov,
	year = {2022},
	pages = {47--60},
	file = {"Efficacy of LENA-based feedback to families of young children" by Beula M. Magimairaj, Naveen K. Nagaraj et al.:/Users/eec35/Zotero/storage/A5SPST8H/6.html:text/html},
}

@article{ferjanramirez2021,
	title = {Comparing {Automatic} and {Manual} {Measures} of {Parent}–{Infant} {Conversational} {Turns}: {A} {Word} of {Caution}},
	volume = {92},
	issn = {1467-8624},
	shorttitle = {Comparing {Automatic} and {Manual} {Measures} of {Parent}–{Infant} {Conversational} {Turns}},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13495},
	doi = {10.1111/cdev.13495},
	abstract = {The Language ENvironment Analysis system (LENA) records children’s language environment and provides an automatic estimate of adult–child conversational turn count (CTC). The present study compares LENA’s CTC estimate to manually coded CTC on a sample of 70 English-speaking infants recorded longitudinally at 6, 10, 14, 18, and 24 months of age. At each age, LENA’s CTC was significantly higher than manually coded CTC (all ps {\textless} .001, Cohen’s ds: 0.9–2.05), with the largest discrepancies between the two methods observed at younger ages. The Limits of Agreement Analyses confirm wide disagreements between the two methods, highlighting potential problems with automatic measurement of parent–infant verbal interaction. These findings suggest that future studies should validate LENA’s CTC estimates with manual coding.},
	language = {en},
	number = {2},
	urldate = {2022-11-28},
	journal = {Child Development},
	author = {Ferjan Ramírez, Naja and Hippe, Daniel S. and Kuhl, Patricia K.},
	year = {2021},
	note = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.13495},
	keywords = {LENA},
	pages = {672--681},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/3YKH59ER/Ferjan Ramírez et al. - 2021 - Comparing Automatic and Manual Measures of Parent–.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/R4XKC6KE/cdev.html:text/html},
}

@article{yurovsky2013,
	title = {Statistical word learning at scale: the baby's view is better},
	volume = {16},
	issn = {1467-7687},
	shorttitle = {Statistical word learning at scale},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12036},
	doi = {10.1111/desc.12036},
	abstract = {A key question in early word learning is how children cope with the uncertainty in natural naming events. One potential mechanism for uncertainty reduction is cross-situational word learning – tracking word/object co-occurrence statistics across naming events. But empirical and computational analyses of cross-situational learning have made strong assumptions about the nature of naming event ambiguity, assumptions that have been challenged by recent analyses of natural naming events. This paper shows that learning from ambiguous natural naming events depends on perspective. Natural naming events from parent–child interactions were recorded from both a third-person tripod-mounted camera and from a head-mounted camera that produced a ‘child's-eye’ view. Following the human simulation paradigm, adults were asked to learn artificial language labels by integrating across the most ambiguous of these naming events. Significant learning was found only from the child's perspective, pointing to the importance of considering statistical learning from an embodied perspective.},
	language = {en},
	number = {6},
	urldate = {2023-05-04},
	journal = {Developmental Science},
	author = {Yurovsky, Daniel and Smith, Linda B. and Yu, Chen},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12036},
	pages = {959--966},
	file = {Accepted Version:/Users/eec35/Zotero/storage/28SE2EB8/Yurovsky et al. - 2013 - Statistical word learning at scale the baby's vie.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/FXJ5K4AY/desc.html:text/html},
}

@article{busch2018,
	title = {Correlation and agreement between {Language} {ENvironment} {Analysis} ({LENA}™) and manual transcription for {Dutch} natural language recordings},
	volume = {50},
	issn = {1554-3528},
	doi = {10.3758/s13428-017-0960-0},
	abstract = {The Language ENvironment Analysis system (LENA™) automatically analyzes the natural sound environments of children. Among other things, it estimates the amounts of adult words (AWC), child vocalizations (CV), conversational turns (CT), and electronic media (TV) that a child is exposed to. To assess LENA's reliability, we compared it to manual transcription. Specifically, we calculated the correlation and agreement between the LENA estimates and manual counts for 48 five-min audio samples. These samples were selected from eight day-long recordings of six Dutch-speaking children (ages 2-5). The correlations were strong for AWC, r =  . 87, and CV, r =  . 77, and comparatively low for CT, r =  . 52, and TV, r =  . 50. However, the agreement analysis revealed a constant bias in AWC counts, and proportional biases for CV and CT (i.e., the bias varied with the values for CV and CT). Agreement for detecting electronic media was poor. Moreover, the limits of agreement were wide for all four metrics. That is, the differences between LENA and the manual transcriptions for individual audio samples varied widely around the mean difference. This variation could indicate that LENA was affected by differences between the samples that did not equally affect the human transcribers. The disagreements and biases cast doubt on the comparability of LENA measurements across families and time, which is crucial for using LENA in research. Our sample is too small to conclude within which limits LENA's measurements are comparable, but it seems advisable to be cautious of factors that could systematically bias LENA's performance and thereby create confounds.},
	language = {eng},
	number = {5},
	journal = {Behavior Research Methods},
	author = {Busch, Tobias and Sangen, Anouk and Vanpoucke, Filiep and van Wieringen, Astrid},
	month = oct,
	year = {2018},
	pmid = {28936690},
	keywords = {Adult, Adult word count, Agreement, Automatic speech recognition, Bias, Child vocalization count, Child, Preschool, Conversational turn count, Dutch, Electronic media, Environment, Female, Human transcription, Humans, Language, Male, Measurement error, Method comparison, Netherlands, Reliability, Reproducibility of Results, Speech Recognition Software},
	pages = {1921--1932},
	file = {Full Text:/Users/eec35/Zotero/storage/LKHGYFYQ/Busch et al. - 2018 - Correlation and agreement between Language ENviron.pdf:application/pdf},
}

@article{pancsofar2006,
	title = {Mother and father language input to young children: {Contributions} to later language development},
	volume = {27},
	issn = {0193-3973},
	shorttitle = {Mother and father language input to young children},
	url = {https://www.sciencedirect.com/science/article/pii/S0193397306000980},
	doi = {10.1016/j.appdev.2006.08.003},
	abstract = {There has been little research comparing the nature and contributions of language input of mothers and fathers to their young children. This study examined differences in mother and father talk to their 24 month-old children. This study also considered contributions of parent education, child care quality and mother and father language (output, vocabulary, complexity, questions, and pragmatics) to children's expressive language development at 36 months. It was found that fathers' language input was less than mothers' language input on the following: verbal output, turn length, different word roots, and wh-questions. Mothers and fathers did not differ on type-token ratio, mean length of utterance, or the proportion of questions. At age 36 months, parent level of education, the total quality of child care and paternal different words were significant predictors of child language. Mothers' language was not a significant predictor of child language.},
	language = {en},
	number = {6},
	urldate = {2023-05-04},
	journal = {Journal of Applied Developmental Psychology},
	author = {Pancsofar, Nadya and Vernon-Feagans, Lynne},
	month = nov,
	year = {2006},
	keywords = {Child care, Child language development, Father language input, Mother language input},
	pages = {571--587},
	file = {ScienceDirect Full Text PDF:/Users/eec35/Zotero/storage/A2ETFB46/Pancsofar and Vernon-Feagans - 2006 - Mother and father language input to young children.pdf:application/pdf;ScienceDirect Snapshot:/Users/eec35/Zotero/storage/LXKUD5X8/S0193397306000980.html:text/html},
}

@article{montag2018,
	title = {Quantity and {Diversity}: {Simulating} {Early} {Word} {Learning} {Environments}},
	volume = {42 Suppl 2},
	issn = {1551-6709},
	shorttitle = {Quantity and {Diversity}},
	doi = {10.1111/cogs.12592},
	abstract = {The words in children's language learning environments are strongly predictive of cognitive development and school achievement. But how do we measure language environments and do so at the scale of the many words that children hear day in, day out? The quantity and quality of words in a child's input are typically measured in terms of total amount of talk and the lexical diversity in that talk. There are disagreements in the literature whether amount or diversity is the more critical measure of the input. Here we analyze the properties of a large corpus (6.5 million words) of speech to children and simulate learning environments that differ in amount of talk per unit time, lexical diversity, and the contexts of talk. The central conclusion is that what researchers need to theoretically understand, measure, and change is not the total amount of words, or the diversity of words, but the function that relates total words to the diversity of words, and how that function changes across different contexts of talk.},
	language = {eng},
	number = {Suppl 2},
	journal = {Cognitive Science},
	author = {Montag, Jessica L. and Jones, Michael N. and Smith, Linda B.},
	month = may,
	year = {2018},
	pmid = {29411899},
	pmcid = {PMC5980672},
	keywords = {Child Language, Child-directed speech, Child, Preschool, Computer simulation, Computer Simulation, Female, Humans, Individual differences, Individuality, Language development, Language Development, Linguistic quantity and quality, Male, Speech, Verbal Learning, Vocabulary},
	pages = {375--412},
	file = {Accepted Version:/Users/eec35/Zotero/storage/XDZ2DUTC/Montag et al. - 2018 - Quantity and Diversity Simulating Early Word Lear.pdf:application/pdf},
}

@book{templin1957,
	address = {Minneapolis, MN, US},
	series = {Certain language skills in children; their development and interrelationships},
	title = {Certain language skills in children; their development and interrelationships},
	abstract = {Normative data were secured on 480 children between the ages of 3 and 8 divided into 8 subsamples by age, and stratified for SES. Measures obtained were: articulation of speech sounds, sound discrimination, vocabulary, and verbalizations. Using the terminal status concept and the significance of differences between consecutively tested age groups, age trends were determined. The often-assumed superiority of girls over boys is not entirely substantiated. SES differences are significant. In comparison with previous studies, children today show greater loquacity, possibly reflecting the effect of mass media or other cultural changes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {University of Minnesota Press},
	author = {Templin, Mildred C.},
	year = {1957},
	note = {Pages: xviii, 183},
	file = {Snapshot:/Users/eec35/Zotero/storage/MAZW5YI2/1957-07556-000.html:text/html},
}

@article{osina2013,
	title = {When familiar is not better: 12-month-old infants respond to talk about absent objects},
	volume = {49},
	issn = {1939-0599},
	shorttitle = {When familiar is not better},
	doi = {10.1037/a0027903},
	abstract = {Three experiments that demonstrate a novel constraint on infants' language skills are described. Across the experiments it is shown that as babies near their 1st birthday, their ability to respond to talk about an absent object is influenced by a referent's spatiotemporal history: familiarizing infants with an object in 1 or several nontest locations before the study interferes with their ability to respond to talk about the object when it is out of view. Familiarity with an object may not always strengthen infants' object representations and therefore facilitate their ability to appropriately react to the mention of absent objects. On the contrary, early in development, irrelevant information about prior location may be bound to representations of familiar objects and thus interfere with infants' ability to respond to talk about absent things. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Developmental Psychology},
	author = {Osina, Maria A. and Saylor, Megan M. and Ganea, Patricia A.},
	year = {2013},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Contextual Associations, Conversation, Familiarity, Infant Development, Language Development, Memory},
	pages = {138--145},
	file = {Snapshot:/Users/eec35/Zotero/storage/WA3T2SWP/2012-07968-001.html:text/html},
}

@article{ganea2013,
	title = {Talking about the near and dear: {Infants}' comprehension of displaced speech},
	volume = {49},
	issn = {1939-0599},
	shorttitle = {Talking about the near and dear},
	doi = {10.1037/a0030086},
	abstract = {The present research investigated the role of familiarity and proximity in infants' comprehension of displaced speech. When 13- and 16-month-old infants heard a researcher talk about a familiar person immediately after she left the room, they showed comprehension of the name by looking, pointing, or searching for the person in question. The majority of 16-month-olds were also able to reveal comprehension of the reference to the absent person after a 16-min delay, and they were able to respond to the name of an unfamiliar person as well. The 13-month-olds had more difficulty responding after the delay and to the name of a less familiar person. Thus, in the early phases of absent reference comprehension, infants' ability to respond to displaced speech can vary as a function of the temporal gap between the verbal reference and the last appearance of the referent, and of how strong their representation of the referent is.},
	language = {eng},
	number = {7},
	journal = {Developmental Psychology},
	author = {Ganea, Patricia A. and Saylor, Megan M.},
	month = jul,
	year = {2013},
	pmid = {22985298},
	keywords = {Child Development, Comprehension, Female, Humans, Infant, Male, Models, Psychological, Speech},
	pages = {1299--1307},
}

@article{urwin1984,
	title = {Language for absent things: learning from visually handicapped children},
	volume = {4},
	issn = {0271-8294},
	shorttitle = {Language for absent things},
	url = {https://journals.lww.com/topicsinlanguagedisorders/Citation/1984/09000/Language_for_absent_things__learning_from_visually.6.aspx},
	abstract = {An abstract is unavailable. This article is available as a PDF only.},
	language = {en-US},
	number = {4},
	urldate = {2023-05-04},
	journal = {Topics in Language Disorders},
	author = {Urwin, Cathy},
	month = sep,
	year = {1984},
	pages = {24},
	file = {Snapshot:/Users/eec35/Zotero/storage/U7STU9QH/Language_for_absent_things__learning_from_visually.6.html:text/html},
}

@article{moore1994,
	title = {Communication between blind and severely visually impaired children and their parents},
	volume = {12},
	issn = {2044-835X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-835X.1994.tb00650.x},
	doi = {10.1111/j.2044-835X.1994.tb00650.x},
	abstract = {This study examines communications directed to young visually impaired children by their parents. Eight totally blind children and eight children whose vision was severely impaired were visited at home at around 18 months of age and video-recordings were made of each child interacting with a familiar caretaker. It was found that the parents of blind children were more likely to initiate interactions themselves and tended to use verbal comments unaccompanied by actions more frequently. They were less likely to talk about objects which were at the child's current focus of attention and were more likely to describe the properties of objects to the child using general terms such as pronouns or general nouns. In addition, they tended to request verbal information from their children in contrast to the parents of severely visually impaired children, who were more likely to describe objects for them. Children in both groups received more requests for action than any other utterance type and all parents made infrequent mention of the attributes of objects. The differences between the groups are discussed in terms of the difficulties faced particularly by parents of blind children in initiating and sustaining interactions.},
	language = {en},
	number = {4},
	urldate = {2023-05-04},
	journal = {British Journal of Developmental Psychology},
	author = {Moore, Vanessa and McConachie, Helen},
	year = {1994},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-835X.1994.tb00650.x},
	pages = {491--502},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/6J2I4YXN/Moore and McConachie - 1994 - Communication between blind and severely visually .pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/FPCASS9R/j.2044-835X.1994.tb00650.html:text/html},
}

@article{snow1972a,
	title = {Mothers' {Speech} to {Children} {Learning} {Language}},
	volume = {43},
	issn = {0009-3920},
	url = {https://www.jstor.org/stable/1127555},
	doi = {10.2307/1127555},
	abstract = {The assumption that language acquisition is relatively independent of the amount and kind of language input must be assessed in light of information about the speech actually heard by young children. The speech of middle-class mothers to 2-year-old children was found to be simpler and more redundant than their speech to 10-year-old children. The mothers modified their speech less when talking to children whose responses they could not observe, indicating that the children played some role in eliciting the speech modifications. Task difficulty did not contribute to the mothers' production of simplified, redundant speech. Experienced mothers were only slightly better than nonmothers in predicting the speech-style modifications required by young children. These findings indicate that children who are learning language have available a sample of speech which is simpler, more redundant, and less confusing than normal adult speech.},
	number = {2},
	urldate = {2023-05-05},
	journal = {Child Development},
	author = {Snow, Catherine E.},
	year = {1972},
	note = {Publisher: [Wiley, Society for Research in Child Development]},
	pages = {549--565},
	file = {JSTOR Full Text PDF:/Users/eec35/Zotero/storage/XIF8NZXG/Snow - 1972 - Mothers' Speech to Children Learning Language.pdf:application/pdf},
}

@article{wang2020,
	title = {A meta-analysis of the predictability of {LENA}™ automated measures for child language development},
	volume = {57},
	issn = {0273-2297},
	url = {https://www.sciencedirect.com/science/article/pii/S0273229720300277},
	doi = {10.1016/j.dr.2020.100921},
	abstract = {Early language environment plays a critical role in child language development. The Language ENvironment Analysis (LENA™) system allows researchers and clinicians to collect daylong recordings and obtain automated measures to characterize a child’s language environment. This meta-analysis evaluates the predictability of LENA’s automated measures for language skills in young children. We systematically searched reports for associations between LENA’s automated measures, specifically, adult word count (AWC), conversational turn count (CTC), and child vocalization count (CVC), and language skills in children younger than 48 months. Using robust variance estimation, we calculated weighted mean effect sizes and conducted moderator analyses exploring the factors that might affect this relationship. The results revealed an overall medium effect size for the correlation between LENA’s automated measures and language skills. This relationship was largely consistent regardless of child developmental status, publication status, language assessment modality and method, or the age at which the LENA recording was taken; however, the effect was moderated by the gap between LENA recordings and language measures taken. Among the three measures, there were medium associations between CTC and CVC and language, whereas there was a small-to-medium association between AWC and language. These findings extend beyond validation work conducted by the LENA Research Foundation and suggest certain predictive strength of LENA’s automated measures for child language. We discussed possible mechanisms underlying the observed associations, as well as the theoretical, methodological, and clinical implications of these findings.},
	language = {en},
	urldate = {2023-05-05},
	journal = {Developmental Review},
	author = {Wang, Yuanyuan and Williams, Rondeline and Dilley, Laura and Houston, Derek M.},
	month = sep,
	year = {2020},
	keywords = {AWC, Child language, CTC, CVC, LENA, Predictability},
	pages = {100921},
	file = {Accepted Version:/Users/eec35/Zotero/storage/ZHWIQQ3G/Wang et al. - 2020 - A meta-analysis of the predictability of LENA™ aut.pdf:application/pdf;ScienceDirect Snapshot:/Users/eec35/Zotero/storage/B5EXBFV8/S0273229720300277.html:text/html},
}

@article{harris1986,
	title = {Relations between the non-verbal context of maternal speech and rate of language development},
	volume = {4},
	issn = {2044-835X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-835X.1986.tb01017.x},
	doi = {10.1111/j.2044-835X.1986.tb01017.x},
	abstract = {This study compares maternal speech to two groups of children who showed a normal or slower rate of language development up to 24 months. Maternal speech to these children at 16 months was analysed in order to determine relations between speech and the contiguous non-verbal context. Several differences emerged between the two groups. Mothers of children with slower language development initiated more changes in conversational topic without providing an appropriate non-verbal context. They also made fewer references to objects which were at the child's current focus of attention and more references to objects to which the child was not attending. The children with slower language development were also presented with fewer specific object labels and more general terms such as pronouns and general nouns. Possible difficulties for the early stages of language development arising from these differences are discussed.},
	language = {en},
	number = {3},
	urldate = {2023-05-05},
	journal = {British Journal of Developmental Psychology},
	author = {Harris, Margaret and Jones, David and Brookes, Susan and Grant, Julia},
	year = {1986},
	note = {\_eprint: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-835X.1986.tb01017.x},
	pages = {261--268},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/ZQNNY5WX/Harris et al. - 1986 - Relations between the non-verbal context of matern.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/KCUUBWLL/j.2044-835X.1986.tb01017.html:text/html},
}

@article{bigelow1990,
	title = {Relationship between the {Development} of {Language} and {Thought} in {Young} {Blind} {Children}},
	volume = {84},
	issn = {0145-482X},
	url = {https://doi.org/10.1177/0145482X9008400805},
	doi = {10.1177/0145482X9008400805},
	abstract = {The relationship between the development of object permanence and early words was studied in three young boys, two totally blind from birth and one severely visually impaired. Auditory and tactile tasks analogous to traditional visual object-permanence tasks were presented to the children at monthly intervals, and their first 50 words and the context in which the words were said were recorded by their mothers and collected monthly. All three boys acquired early words within the age range for sighted children, but their usage of the words was different. The two blind boys but not the visually impaired boy were delayed in their development of object permanence. The relationship between the acquisition of early words and the development of object permanence suggests that the emergence of language is not dependent on a stable understanding of the existence and permanence of objects.},
	language = {en},
	number = {8},
	urldate = {2021-04-16},
	journal = {Journal of Visual Impairment \& Blindness},
	author = {Bigelow, Ann},
	month = oct,
	year = {1990},
	note = {Publisher: SAGE Publications Inc},
	pages = {414--419},
}

@article{segal2015,
	title = {Infant {Preferences} for {Structural} and {Prosodic} {Properties} of {Infant}-{Directed} {Speech} in the {Second} {Year} of {Life}},
	volume = {20},
	issn = {15250008},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/infa.12077},
	doi = {10.1111/infa.12077},
	language = {en},
	number = {3},
	urldate = {2023-05-05},
	journal = {Infancy},
	author = {Segal, Judith and Newman, Rochelle S.},
	month = may,
	year = {2015},
	pages = {339--351},
}

@article{stevenson1986,
	title = {Mothers' speech to their 1-year-old infants in home and laboratory settings},
	volume = {15},
	issn = {1573-6555},
	url = {https://doi.org/10.1007/BF01067725},
	doi = {10.1007/BF01067725},
	abstract = {The speech of mothers and their 1-year-old infants was compared in the home and in the laboratory playroom. The home and laboratory settings were similar for measuring the number of actual words that infants spoke and were similar for measuring the complexity of the mother's speech, including the number of different words, the type-token ratio, and the length of the utterances. Infants vocalized at similar rates in the two settings, but mothers spoke at a faster rate in the laboratory playroom. The usefulness of a preliminary warm-up period was supported by the finding that for the second half of the sessions, mothers slowed their rate of speech and increased the complexity of their speech.},
	language = {en},
	number = {5},
	urldate = {2023-05-05},
	journal = {Journal of Psycholinguistic Research},
	author = {Stevenson, Marguerite B. and Leavitt, Lewis A. and Roach, Mary A. and Chapman, Robin S. and Miller, Jon F.},
	month = sep,
	year = {1986},
	keywords = {Cognitive Psychology, Actual Word, Fast Rate, Laboratory Setting, Similar Rate},
	pages = {451--461},
}

@article{tadic2013,
	title = {Story discourse and use of mental state language between mothers and school-aged children with and without visual impairment},
	volume = {48},
	issn = {1460-6984},
	doi = {10.1111/1460-6984.12040},
	abstract = {BACKGROUND: Lack of sight compromises insight into other people's mental states. Little is known about the role of maternal language in assisting the development of mental state language in children with visual impairment (VI).
AIMS: To investigate mental state language strategies of mothers of school-aged children with VI and to compare these with mothers of comparable children with typically developing vision. To investigate whether the characteristics of mother-child discourse were associated with the child's socio-communicative competence.
METHODS \& PROCEDURES: Mother-child discourse with twelve 6-12-year-old children with VI was coded during a shared book-reading narrative and compared with 14 typically sighted children matched in age and verbal ability.
OUTCOMES \& RESULTS: Mothers of children with VI elaborated more and made significantly more references to story characters' mental states and descriptive elaborations than mothers of sighted children. Mental state elaborations of mothers in the VI group related positively with the level produced by their children, with the association remaining after mothers' overall verbosity and children's developmental levels were controlled for. Frequency of maternal elaborations, including their mental state language, was related to socio-communicative competence of children with VI.
CONCLUSIONS \& IMPLICATIONS: The findings offer insights into the potential contribution of maternal verbal scaffolding to mentalistic language and social-communicative competences of children with VI.},
	language = {eng},
	number = {6},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Tadić, Valerija and Pring, Linda and Dale, Naomi},
	year = {2013},
	pmid = {24165364},
	pmcid = {PMC4229064},
	keywords = {Blind},
	pages = {679--688},
	file = {Full Text:/Users/eec35/Zotero/storage/JMLZNRB7/Tadić et al. - 2013 - Story discourse and use of mental state language b.pdf:application/pdf},
}

@article{cychosz2021a,
	title = {Efficient {Estimation} of {Children}'s {Language} {Exposure} in {Two} {Bilingual} {Communities}},
	volume = {64},
	url = {https://pubs.asha.org/doi/full/10.1044/2021_JSLHR-20-00755},
	doi = {10.1044/2021_JSLHR-20-00755},
	abstract = {Purpose 

The language that children hear early in life is associated with their speech-language outcomes. This line of research relies on naturalistic observations of children's language input, often captured with daylong audio recordings. However, the large quantity of data that daylong recordings generate requires novel analytical tools to feasibly parse thousands of hours of naturalistic speech. This study outlines a new approach to efficiently process and sample from daylong audio recordings made in two bilingual communities, Spanish–English in the United States and Quechua–Spanish in Bolivia, to derive estimates of children's language exposure.

Method 

We employed a general sampling with replacement technique to efficiently estimate two key elements of children's early language environments: (a) proportion of child-directed speech (CDS) and (b) dual language exposure. Proportions estimated from random sampling of 30-s segments were compared to those from annotations over the entire daylong recording (every other segment), as well as parental report of dual language exposure.

Results 

Results showed that approximately 49 min from each recording or just 7\% of the overall recording was required to reach a stable proportion of CDS and bilingual exposure. In both speech communities, strong correlations were found between bilingual language estimates made using random sampling and all-day annotation techniques. A strong association was additionally found for CDS estimates in the United States, but this was weaker at the Bolivian site, where CDS was less frequent. Dual language estimates from the audio recordings did not correspond well to estimates derived from parental report collected months apart.

Conclusions 

Daylong recordings offer tremendous insight into children's daily language experiences, but they will not become widely used in developmental research until data processing and annotation time substantially decrease. We show that annotation based on random sampling is a promising approach to efficiently estimate ambient characteristics from daylong recordings that cannot currently be estimated via automated methods.},
	number = {10},
	urldate = {2023-05-08},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Cychosz, Margaret and Villanueva, Anele and Weisleder, Adriana},
	month = oct,
	year = {2021},
	note = {tex.ids= cychosz2021b
publisher: American Speech-Language-Hearing Association},
	pages = {3843--3866},
}

@article{weisleder2013,
	title = {Talking to {Children} {Matters}: {Early} {Language} {Experience} {Strengthens} {Processing} and {Builds} {Vocabulary}},
	volume = {24},
	issn = {0956-7976},
	shorttitle = {Talking to {Children} {Matters}},
	url = {https://doi.org/10.1177/0956797613488145},
	doi = {10.1177/0956797613488145},
	abstract = {Infants differ substantially in their rates of language growth, and slow growth predicts later academic difficulties. In this study, we explored how the amount of speech directed to infants in Spanish-speaking families low in socioeconomic status influenced the development of children?s skill in real-time language processing and vocabulary learning. All-day recordings of parent-infant interactions at home revealed striking variability among families in how much speech caregivers addressed to their child. Infants who experienced more child-directed speech became more efficient in processing familiar words in real time and had larger expressive vocabularies by the age of 24 months, although speech simply overheard by the child was unrelated to vocabulary outcomes. Mediation analyses showed that the effect of child-directed speech on expressive vocabulary was explained by infants? language-processing efficiency, which suggests that richer language experience strengthens processing skills that facilitate language growth.},
	number = {11},
	urldate = {2023-05-08},
	journal = {Psychological Science},
	author = {Weisleder, Adriana and Fernald, Anne},
	month = nov,
	year = {2013},
	note = {Publisher: SAGE Publications Inc},
	pages = {2143--2152},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/8QBIM5DS/Weisleder and Fernald - 2013 - Talking to Children Matters Early Language Experi.pdf:application/pdf},
}

@article{shneidman2013,
	title = {What counts as effective input for word learning?},
	volume = {40},
	issn = {1469-7602},
	doi = {10.1017/S0305000912000141},
	abstract = {The talk children hear from their primary caregivers predicts the size of their vocabularies. But children who spend time with multiple individuals also hear talk that others direct to them, as well as talk not directed to them at all. We investigated the effect of linguistic input on vocabulary acquisition in children who routinely spent time with one vs. multiple individuals. For all children, the number of words primary caregivers directed to them at age 2 ; 6 predicted vocabulary size at age 3 ; 6. For children who spent time with multiple individuals, child-directed words from all household members also predicted later vocabulary and accounted for more variance in vocabulary than words from primary caregivers alone. Interestingly, overheard words added no predictive value to the model. These findings suggest that speech directed to children is important for early word learning, even in households where a sizable proportion of input comes from overheard speech.},
	language = {eng},
	number = {3},
	journal = {Journal of Child Language},
	author = {Shneidman, Laura A. and Arroyo, Michelle E. and Levine, Susan C. and Goldin-Meadow, Susan},
	month = jun,
	year = {2013},
	pmid = {22575125},
	pmcid = {PMC3445663},
	keywords = {Age Factors, Child Language, Child, Preschool, Family, Family Characteristics, Female, Humans, Learning, Male, Speech, Vocabulary},
	pages = {672--686},
	file = {Accepted Version:/Users/eec35/Zotero/storage/FETZSLA7/Shneidman et al. - 2013 - What counts as effective input for word learning.pdf:application/pdf},
}

@article{casillas2020,
	title = {Early {Language} {Experience} in a {Tseltal} {Mayan} {Village}},
	volume = {91},
	issn = {1467-8624},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13349},
	doi = {10.1111/cdev.13349},
	abstract = {Daylong at-home audio recordings from 10 Tseltal Mayan children (0;2–3;0; Southern Mexico) were analyzed for how often children engaged in verbal interaction with others and whether their speech environment changed with age, time of day, household size, and number of speakers present. Children were infrequently directly spoken to, with most directed speech coming from adults, and no increase with age. Most directed speech came in the mornings, and interactional peaks contained nearly four times the baseline rate of directed speech. Coarse indicators of children’s language development (babbling, first words, first word combinations) suggest that Tseltal children manage to extract the linguistic information they need despite minimal directed speech. Multiple proposals for how they might do so are discussed.},
	language = {en},
	number = {5},
	urldate = {2023-05-08},
	journal = {Child Development},
	author = {Casillas, Marisa and Brown, Penelope and Levinson, Stephen C.},
	year = {2020},
	note = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.13349},
	pages = {1819--1835},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/BQLC4G9P/Casillas et al. - 2020 - Early Language Experience in a Tseltal Mayan Villa.pdf:application/pdf;Snapshot:/Users/eec35/Zotero/storage/VQB6NR8H/cdev.html:text/html},
}

@article{lorang2020,
	title = {An investigation into maternal use of telegraphic input to children with {Down} syndrome},
	volume = {47},
	issn = {0305-0009, 1469-7602},
	url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/an-investigation-into-maternal-use-of-telegraphic-input-to-children-with-down-syndrome/5432E8B1AD4E26DDA796ADAD1D774B4E},
	doi = {10.1017/S0305000919000503},
	abstract = {Maternal input influences language development in children with Down syndrome (DS) and typical development (TD). Telegraphic input, or simplified input violating English grammatical rules, is controversial in speech–language pathology, yet no research to date has investigated whether mothers of children with DS use telegraphic input. This study investigated the quality of linguistic input to children with DS compared to age-matched children with TD, and the relationship between maternal input and child language abilities. Mothers of children with DS simplified their input in multiple ways, by using a lower lexical diversity, shorter utterances, and more telegraphic input compared to mothers of children with TD. Telegraphic input was not significantly correlated with other aspects of maternal input or child language abilities. Since children with DS demonstrate specific deficits in grammatical compared to lexical abilities, future work should investigate the long-term influence of maternal telegraphic input on language development in children with DS.},
	language = {en},
	number = {1},
	urldate = {2023-05-09},
	journal = {Journal of Child Language},
	author = {Lorang, Emily and Venker, Courtney E. and Sterling, Audra},
	month = jan,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	keywords = {Down syndrome, maternal input, parent–child interactions},
	pages = {225--249},
	file = {Accepted Version:/Users/eec35/Zotero/storage/MFDVSA62/Lorang et al. - 2020 - An investigation into maternal use of telegraphic .pdf:application/pdf},
}

@article{ferjanramirez2023,
	title = {A comparison of automatic and manual measures of turn-taking in monolingual and bilingual contexts},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-023-02127-z},
	doi = {10.3758/s13428-023-02127-z},
	abstract = {The Language ENvironment Analysis system (LENA) records children’s language environment and provides an automatic estimate of adult–child conversational turn count (CTC) by automatically identifying adult and child speech in close temporal proximity. To assess the reliability of this measure, we examine correlation and agreement between LENA’s CTC estimates and manual measurement of adult–child turn-taking in two corpora collected in the USA: a bilingual corpus of Spanish–English-speaking families with infants between 4 and 22 months (n = 37), and a corpus of monolingual families with English-speaking 5-year-olds (n = 56). In each corpus for each child, 100 30-second segments were extracted from daylong recordings in two ways, yielding a total of 9300 minutes of manually annotated audio. LENA’s CTC estimate for the same segments was obtained through the LENA software. The two measures of CTC had low correlations for the segments from the monolingual 5-year-olds sampled in both ways, and somewhat higher correlations for the bilingual samples. LENA substantially overestimated CTC on average, relative to manual measurement, for three out of four analysis conditions, and limits of agreement were wide in all cases. Segment-level analyses demonstrated that accidental contiguity had the largest individual impact on LENA’s average CTC error, affecting 12–17\% of analyzed segments. Other factors significantly contributing to CTC error were speech from other children, presence of multiple adults, and presence of electronic media. These results indicate wide discrepancies between LENA’s CTC estimates and manual CTCs, and call into question the comparability of LENA’s CTC measure across participants, conditions, and developmental time points.},
	language = {en},
	urldate = {2023-05-10},
	journal = {Behavior Research Methods},
	author = {Ferjan Ramirez, Naja and Hippe, Daniel S. and Braverman, Adeline and Weiss, Yael and Kuhl, Patricia K.},
	month = may,
	year = {2023},
	keywords = {Conversational turns, Daylong recordings, Language input, LENA},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/3ZRKSXI8/Ferjan Ramirez et al. - 2023 - A comparison of automatic and manual measures of t.pdf:application/pdf},
}

@article{cesana-arlotti2020,
	title = {Infants recruit logic to learn about the social world},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-19734-5},
	doi = {10.1038/s41467-020-19734-5},
	abstract = {When perceptually available information is scant, we can leverage logical connections among hypotheses to draw reliable conclusions that guide our reasoning and learning. We investigate whether this function of logical reasoning is present in infancy and aid understanding and learning about the social environment. In our task, infants watch reaching actions directed toward a hidden object whose identity is ambiguous between two alternatives and has to be inferred by elimination. Here we show that infants apply a disjunctive inference to identify the hidden object and use this logical conclusion to assess the consistency of the actions with a preference previously demonstrated by the agent and, importantly, also to acquire new knowledge regarding the preferences of the observed actor. These findings suggest that, early in life, preverbal logical reasoning functions as a reliable source of evidence that can support learning by offering a logical route for knowledge acquisition.},
	language = {en},
	number = {1},
	urldate = {2023-05-20},
	journal = {Nature Communications},
	author = {Cesana-Arlotti, Nicolò and Kovács, Ágnes Melinda and Téglás, Ernő},
	month = nov,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Human behaviour, Psychology},
	pages = {5999},
	file = {Full Text PDF:/Users/eec35/Zotero/storage/5PELS4TQ/Cesana-Arlotti et al. - 2020 - Infants recruit logic to learn about the social wo.pdf:application/pdf},
}

@incollection{borghi2014,
	address = {New York, NY},
	series = {{SpringerBriefs} in {Psychology}},
	title = {Word {Learning} and {Word} {Acquisition}},
	isbn = {978-1-4614-9539-0},
	url = {https://doi.org/10.1007/978-1-4614-9539-0_4},
	abstract = {The chapter illustrates evidence on word learning and word acquisition which supports the WAT proposal. First, we outline approaches that emphasize the importance of social aspects; then, we turn to embodied approaches highlighting the role of perception and action in word acquisition. We then describe hybrid approaches, according to which the role of perception and action cues might have more weight in the early phases of word learning, while the role of social and linguistic cues might be prominent later, once children master some social abilities and possess a consistent vocabulary. We then describe studies on modality of acquisition, showing that concrete and abstract words are learned through different strategies, based on perception versus based on language. Finally, we report some acquisition studies with adults realized in our laboratory. Based on the reported theories and evidence, we argue that the acquisition of both concrete and abstract words rests on associative mechanisms. Perceptive salience, embodied attention, and bodily actions contribute to learning of concrete words associating words to their referents. However, for acquiring abstract words, a mechanism based on words to referents associations is more difficult to apply, given the sparse variety of referents abstract words have. This makes the social and the linguistic input very relevant for abstract word learning. Thus, abstract words are learned both associating words and referents and words to other words. These different associative mechanisms influence not only the conceptual representation but also the body, leading to the activation of different effectors, hand, and mouth.},
	language = {en},
	urldate = {2023-05-20},
	booktitle = {Words as {Social} {Tools}: {An} {Embodied} {View} on {Abstract} {Concepts}},
	publisher = {Springer},
	author = {Borghi, Anna M. and Binkofski, Ferdinand},
	editor = {Borghi, Anna M. and Binkofski, Ferdinand},
	year = {2014},
	doi = {10.1007/978-1-4614-9539-0_4},
	keywords = {Abstract concepts, Abstract words, Acquisition modality, Associative learning, Development, Embodied cognition, Language acquisition, Language learning, Social cognition},
	pages = {71--93},
}

@article{yu2012a,
	title = {Embodied attention and word learning by toddlers},
	volume = {125},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027712001369},
	doi = {10.1016/j.cognition.2012.06.016},
	abstract = {Many theories of early word learning begin with the uncertainty inherent to learning a word from its co-occurrence with a visual scene. However, the relevant visual scene for infant word learning is neither from the adult theorist’s view nor the mature partner’s view, but is rather from the learner’s personal view. Here we show that when 18-month old infants interacted with objects in play with their parents, they created moments in which a single object was visually dominant. If parents named the object during these moments of bottom-up selectivity, later forced-choice tests showed that infants learned the name, but did not when naming occurred during a less visually selective moment. The momentary visual input for parents and toddlers was captured via head cameras placed low on each participant’s forehead as parents played with and named objects for their infant. Frame-by-frame analyses of the head camera images at and around naming moments were conducted to determine the visual properties at input that were associated with learning. The analyses indicated that learning occurred when bottom-up visual information was clean and uncluttered. The sensory-motor behaviors of infants and parents were also analyzed to determine how their actions on the objects may have created these optimal visual moments for learning. The results are discussed with respect to early word learning, embodied attention, and the social role of parents in early word learning.},
	language = {en},
	number = {2},
	urldate = {2023-05-20},
	journal = {Cognition},
	author = {Yu, Chen and Smith, Linda B.},
	month = nov,
	year = {2012},
	keywords = {Embodied cognition, Language learning, Perception and action},
	pages = {244--262},
	file = {ScienceDirect Snapshot:/Users/eec35/Zotero/storage/LDG4KZFS/S0010027712001369.html:text/html},
}

@article{benjamini1995,
	title = {Controlling the {False} {Discovery} {Rate}: {A} {Practical} and {Powerful} {Approach} to {Multiple} {Testing}},
	volume = {57},
	issn = {0035-9246},
	shorttitle = {Controlling the {False} {Discovery} {Rate}},
	url = {https://www.jstor.org/stable/2346101},
	abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	number = {1},
	urldate = {2023-05-20},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Benjamini, Yoav and Hochberg, Yosef},
	year = {1995},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {289--300},
	file = {JSTOR Full Text PDF:/Users/eec35/Zotero/storage/6XL24LDU/Benjamini and Hochberg - 1995 - Controlling the False Discovery Rate A Practical .pdf:application/pdf},
}

@article{loiotile2020,
	title = {Enhanced performance on a sentence comprehension task in congenitally blind adults},
	volume = {35},
	issn = {2327-3798},
	url = {https://doi.org/10.1080/23273798.2019.1706753},
	doi = {10.1080/23273798.2019.1706753},
	abstract = {People born blind habitually experience linguistic utterances in the absence of visual cues. Neuroimaging evidence suggests that congenitally blind individuals also activate “visual” cortices during sentence comprehension. Do blind individuals show superior performance on sentence processing tasks? Congenitally blind (n = 25) and age and education matched sighted (n = 52) participants answered yes/no who-did-what-to-whom questions for auditorily presented sentences, some of which contained a grammatical complexity manipulation (long-distance movement dependency or garden path). Short-term memory was measured with a forward and backward letter-span task. A battery of control tasks included two speeded math tasks and vocabulary and reading tasks from Woodcock Johnson III. The blind group outperformed the sighted group on the sentence comprehension task, particularly for garden-path sentences, and on short-term memory span tasks, but performed similar to the sighted group on control tasks. Sentence comprehension performance was not correlated with working memory span performance, suggesting independent enhancements.},
	number = {8},
	urldate = {2022-08-26},
	journal = {Language, Cognition and Neuroscience},
	author = {Loiotile, Rita and Lane, Connor and Omaki, Akira and Bedny, Marina},
	month = oct,
	year = {2020},
	pmid = {33043067},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/23273798.2019.1706753},
	pages = {1010--1023},
	file = {Accepted Version:/Users/eec35/Zotero/storage/BIE2K5RZ/Loiotile et al. - 2020 - Enhanced performance on a sentence comprehension t.pdf:application/pdf},
}
