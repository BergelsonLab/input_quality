{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica-Bold;
\f3\fnil\fcharset0 LucidaGrande;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww10980\viewh7840\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 general, well written and easy to follow\
* word count, target journal\
* what about devsci? currently in jslhr type format\
* 
\f1 \cf2 \expnd0\expndtw0\kerning0
i\'92d reread whole thing with tense streamlining in mind.
\f0 \cf0 \kerning1\expnd0\expndtw0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\fs32 \cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 Table 1:\
* we really have 44% unknown race for the sighted sample? ec2eb: unfortunately yes
\f1\fs32 \cf2 \expnd0\expndtw0\kerning0
\
\

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 Table 2: \
* blind mean, median, range: if you\'92re gonna do at least 2 lines per cell then can it always be \
mean, median\
range\
unit\
ec2eb: I would really love to, but I cannot figure out how to get a line break in there without weird other issues popping up\
\
Figures: \
 * for comparisons where values ARE significantly different can we do something visual to show that like e.g. red error bars instead of black or something that pops out?\
ec2eb: I tried this but didn\'92t like how it looked, so I added two (redundant) other visual bits. 1) For all the violins, I added a significance marker with ggpubr. 2) I added an optional argument to the plotting function so that if there\'92s a significant difference, the plot\'92s background color changes to the color of the higher group. I don\'92t think this is easily explained in a caption though, so my vote is just the **s/ns option.\
\
*
\f2\b\fs23\fsmilli11623 \cb3 \expnd0\expndtw0\kerning0
Type-Token Ratio.: 
\f0\b0 hm i\'92m confused about the standardization you\'92re doing. i agree that TTR changes with sample length, but these are literally coming from the same number of minutes of language. scaling it by how many words are in those minutes seems like a bizarre transformation. i\'92m happy to be convinced otherwise, but my current view is that given that it\'92s over 30min for each recording, it should be just straight up Types/tokens. \
- The reason I started doing this in the first place is that when I was looking for comparison values in the literature, I struggled to find recent papers that calculated it just as types/tokens. Nearly all were normalizing the  denominator in some way: either by subsampling (e.g., took the first 100 words in a play session) or by doing something like we do here. \
- Additionally, 30 of our 40 minute samples are selected randomly throughout the day, which I do think is a good way to estimate quantity differences across groups, but I\'92m not sure that leaves us with a meaningful denominator for TTR, since there\'92s some noise generated in whose random segments fall during naps, etc. Since we compare quantity elsewhere in the paper, I think it makes sense to reduce noise that isn\'92t related to lexical diversity.\
I\'92ve continued measuring it as standardized TTR, but I\'92ve edited the paragraph in the Methods to try to explain things more clearly.\
\
* glad to see that manual vs. udpipe MLU is so highly correlated! did udpipe under or overshoot significantly relative to manual in that 10? (not sure we need to add it to paper but i am curious)\

\fs24 \cb1 \kerning1\expnd0\expndtw0 ec2eb: it\'92s really close to 50-50. To give two examples from the extreme ends: it underestimated by 4 morphemes on \'93
\f3\fs22 \cb3 \expnd0\expndtw0\kerning0
your\'a0seasoning\'a0is\'a0probably\'a0giving\'a0you\'a0I\'a0like\'a0the\'a0seasoning
\f0\fs24 \cb1 \kerning1\expnd0\expndtw0 \'94 and it overestimated by 3 on \'93
\f3\fs22 \cb3 \expnd0\expndtw0\kerning0
take\'a0your\'a0laptop\'a0and\'a0watch\'a0something\'a0from\'a0Amazon\'a0Prime
\f0\fs24 \cb1 \kerning1\expnd0\expndtw0 \'94\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs23\fsmilli11623 \cf0 \cb3 \expnd0\expndtw0\kerning0
* can you just confirm with Zhenya that the way you\'92re characterizing the high vol selection process is right? i thought there was some kind of consideration of who the talker was in the ranking but maybe i\'92m misremembering \'97 ec2eb: confirmed with Zhenya!\
\

\f2\b *
\f0\b0 we had some back and forth over slack about some things that seemed weird with the word count numbers, please have a look. \
ec2eb: ok, I looked over the code for these values (and I also had Lilli and Max each step through the code with me as logic-checkers / rubber ducks). Code-wise, everything seems to be doing what it\'92s supposed to be. Moreover, the AWC and MWC word count values correlate strongly, with LENA fairly consistently underestimating for our sample. Looking through this paper of yours (https://pubs.asha.org/doi/full/10.1044/2020_JSLHR-19-00017), it seems like LENA sometimes overestimates and sometimes underestimates. In our sample, there are a few things that could contribute to underestimation: our MWC count includes several things that AWC does not: speech from other children, speech from segments that LENA might tag as overlap, and speech from segments that LENA might tag as Far (but were still intelligible to our annotators). 
\fs24 \cb1 \kerning1\expnd0\expndtw0 \
}