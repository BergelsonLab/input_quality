@article{ambrose2014,
  title = {Linguistic {{Input}}, {{Electronic Media}}, and {{Communication Outcomes}} of {{Toddlers With Hearing Loss}}},
  author = {Ambrose, Sophie E. and VanDam, Mark and Moeller, Mary Pat},
  year = {March/April 2014},
  journal = {Ear and Hearing},
  volume = {35},
  number = {2},
  pages = {139--147},
  issn = {1538-4667},
  doi = {10.1097/AUD.0b013e3182a76768},
  urldate = {2022-08-24},
  abstract = {Objectives:~         The objectives of this study were to examine the quantity of adult words, adult\textendash child conversational turns, and electronic media in the auditory environments of toddlers who are hard of hearing (HH) and to examine whether these factors contributed to variability in children's communication outcomes.         Design:~         Participants were 28 children with mild to severe hearing loss. Full-day recordings of children's auditory environments were collected within 6 months of their second birthdays by using Language ENvironment Analysis technology. The system analyzes full-day acoustic recordings, yielding estimates of the quantity of adult words, conversational turns, and electronic media exposure in the recordings. Children's communication outcomes were assessed via the receptive and expressive scales of the Mullen Scales of Early Learning at 2 years of age and the Comprehensive Assessment of Spoken Language at 3 years of age.         Results:~         On average, the HH toddlers were exposed to approximately 1400 adult words per hour and participated in approximately 60 conversational turns per hour. An average of 8\% of each recording was classified as electronic media. However, there was considerable within-group variability on all three measures. Frequency of conversational turns, but not adult words, was positively associated with children's communication outcomes at 2 and 3 years of age. Amount of electronic media exposure was negatively associated with 2-year-old receptive language abilities; however, regression results indicate that the relationship was fully mediated by the quantity of conversational turns.         Conclusions:~         HH toddlers who were engaged in more conversational turns demonstrated stronger linguistic outcomes than HH toddlers who were engaged in fewer conversational turns. The frequency of these interactions was found to be decreased in households with high rates of electronic media exposure. Optimal language-learning environments for HH toddlers include frequent linguistic interactions between parents and children. To support this goal, parents should be encouraged to reduce their children's exposure to electronic media.},
  langid = {american},
  file = {/Users/eec35/Zotero/storage/IUCXTFFD/Ambrose et al. - 2014 - Linguistic Input, Electronic Media, and Communicat.pdf;/Users/eec35/Zotero/storage/MDPP4Z24/Linguistic_Input,_Electronic_Media,_and.1.html}
}

@article{andersen1993,
  ids = {andersen1993a},
  title = {The Impact of Input: Language Acquisition in the Visually Impaired},
  shorttitle = {The Impact of Input},
  author = {Andersen, Elaine S. and Dunlea, Anne and Kekelis, Linda},
  year = {1993},
  month = feb,
  journal = {First Language},
  volume = {13},
  number = {37},
  pages = {23--49},
  publisher = {{SAGE Publications Ltd}},
  issn = {0142-7237},
  doi = {10.1177/014272379301303703},
  urldate = {2021-04-16},
  abstract = {Variation in language development between blind and sighted children may result from a diminution of experience or differences in linguistic input, or it may be a product of other factors. Researchers argue about the relative weighting of these. We examine this argument by reviewing data and findings from our studies of blind children's language and we evaluate the possible impact of input, both environmental and linguistic. We show that variation cannot be uniquely attributed to either of these, but find evidence that experiential input may influence some areas while linguistic input more strongly affects others. Moreover, there is a complex interaction between these. We also find independent adaptive strategies by the children, pointing to a plasticity in the acquisition process itself.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/BVKJDFN2/Andersen et al. - 1993 - The impact of input language acquisition in the v.pdf}
}

@article{anderson2021,
  title = {Linking {{Quality}} and {{Quantity}} of {{Parental Linguistic Input}} to {{Child Language Skills}}: {{A Meta-Analysis}}},
  shorttitle = {Linking {{Quality}} and {{Quantity}} of {{Parental Linguistic Input}} to {{Child Language Skills}}},
  author = {Anderson, Nina J. and Graham, Susan A. and Prime, Heather and Jenkins, Jennifer M. and Madigan, Sheri},
  year = {2021},
  journal = {Child Development},
  volume = {92},
  number = {2},
  pages = {484--501},
  issn = {1467-8624},
  doi = {10.1111/cdev.13508},
  urldate = {2022-09-07},
  abstract = {This meta-analysis examined associations between the quantity and quality of parental linguistic input and children's language. Pooled effect size for quality (i.e., vocabulary diversity and syntactic complexity; k = 35; N = 1,958; r = .33) was more robust than for quantity (i.e., number of words/tokens/utterances; k = 33; N = 1,411; r = .20) of linguistic input. For quality and quantity of parental linguistic input, effect sizes were stronger when input was observed in naturalistic contexts compared to free play tasks. For quality of parental linguistic input, effect sizes also increased as child age and observation length increased. Effect sizes were not moderated by socioeconomic status or child gender. Findings highlight parental linguistic input as a key environmental factor in children's language skills.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/G6J5766S/Anderson et al. - 2021 - Linking Quality and Quantity of Parental Linguisti.pdf;/Users/eec35/Zotero/storage/BBEESTS4/cdev.html}
}

@article{babineau2021,
  title = {Familiar Words Can Serve as a Semantic Seed for Syntactic Bootstrapping},
  author = {Babineau, Mireille and {de Carvalho}, Alex and Trueswell, John and Christophe, Anne},
  year = {2021},
  month = jan,
  journal = {Developmental Science},
  volume = {24},
  number = {1},
  pages = {e13010},
  issn = {1467-7687},
  doi = {10.1111/desc.13010},
  abstract = {Young children can exploit the syntactic context of a novel word to narrow down its probable meaning. But how do they learn which contexts are linked to which semantic features in the first place? We investigate if 3- to 4-year-old children (n~=~60) can learn about a syntactic context from tracking its use with only a few familiar words. After watching a 5-min training video in which a novel function word (i.e., 'ko') replaced either personal pronouns or articles, children were able to infer semantic properties for novel words co-occurring with the newly learned function word (i.e., objects vs. actions). These findings implicate a mechanism by which a distributional analysis, associated with a small vocabulary of known words, could be sufficient to identify some properties associated with specific syntactic contexts.},
  langid = {english},
  pmcid = {PMC7750202},
  pmid = {32589813}
}

@article{babineau2022,
  title = {Learning to Predict and Predicting to Learn: {{Before}} and beyond the Syntactic Bootstrapper},
  shorttitle = {Learning to Predict and Predicting to Learn},
  author = {Babineau, Mireille and Havron, Naomi and Dautriche, Isabelle and {de Carvalho}, Alex and Christophe, Anne},
  year = {2022},
  month = jun,
  journal = {Language Acquisition},
  volume = {0},
  number = {0},
  pages = {1--24},
  publisher = {{Routledge}},
  issn = {1048-9223},
  doi = {10.1080/10489223.2022.2078211},
  urldate = {2023-01-23},
  abstract = {Young children can exploit the syntactic context of a novel word to narrow down its probable meaning. This is syntactic bootstrapping. A learner that uses syntactic bootstrapping to foster lexical acquisition must first have identified the semantic information that a syntactic context provides. Based on the semantic seed hypothesis, children discover the semantic predictiveness of syntactic contexts by tracking the distribution of familiar words. We propose that these learning mechanisms relate to a larger cognitive model: the predictive processing framework. According to this model, we perceive and make sense of the world by constantly predicting what will happen next in a probabilistic fashion. We outline evidence that prediction operates within language acquisition and show how this framework helps us understand the way lexical knowledge refines syntactic predictions and how syntactic knowledge refines predictions about novel words' meanings. The predictive processing framework entails that learners can adapt to recent information and update their linguistic model. Here we review some of the recent experimental work showing that the type of prediction preschool children make from a syntactic context can change when they are presented with contrary evidence from recent input. We end by discussing some challenges of applying the predictive processing framework to syntactic bootstrapping and propose new avenues to investigate in future work.},
  file = {/Users/eec35/Zotero/storage/44TXWRPZ/Babineau et al. - 2022 - Learning to predict and predicting to learn Befor.pdf}
}

@article{baird1997,
  title = {Mothers' {{Interpretations}} of the {{Behavior}} of {{Their Infants}} with {{Visual}} and {{Other Impairments}} during {{Interactions}}},
  author = {Baird, S.M. and Mayfield, P. and Baker, P.},
  year = {1997},
  month = sep,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {91},
  number = {5},
  pages = {467--483},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X9709100507},
  urldate = {2023-01-25},
  abstract = {In this study, seven mothers of infants with visual and other impairments identified behaviors that they considered meaningful and interpreted these behaviors. The mothers identified 14 of 22 subcategories of behaviors that a previous study of mothers with sighted infants had identified. Not only was the range of behaviors they interpreted limited, but over 65 percent of their interpretations fell into only two of the 16 subcategories previously identified (attention preference and intentional behavior: desire). The implications for early intervention and future research are discussed.},
  langid = {english}
}

@article{bergelson2013,
  title = {The Acquisition of Abstract Words by Young Infants},
  author = {Bergelson, Elika and Swingley, Daniel},
  year = {2013},
  month = jun,
  journal = {Cognition},
  volume = {127},
  number = {3},
  pages = {391--397},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2013.02.011},
  urldate = {2021-03-30},
  abstract = {Young infants' learning of words for abstract concepts like `all gone' and `eat,' in contrast to their learning of more concrete words like `apple' and `shoe,' may follow a relatively protracted developmental course. We examined whether infants know such abstract words. Parents named one of two events shown in side-by-side videos while their 6\textendash 16-month-old infants (n=98) watched. On average, infants successfully looked at the named video by 10months, but not earlier, and infants' looking at the named referent increased robustly at around 14months. Six-month-olds already understand concrete words in this task (Bergelson \& Swingley, 2012). A video-corpus analysis of unscripted mother-infant interaction showed that mothers used the tested abstract words less often in the presence of their referent events than they used concrete words in the presence of their referent objects. We suggest that referential uncertainty in abstract words' teaching conditions may explain the later acquisition of abstract than concrete words, and we discuss the possible role of changes in social-cognitive abilities over the 6\textendash 14month period.},
  langid = {english},
  keywords = {Cognitive development,Infancy,Language acquisition,Psycholinguistics,Word learning},
  file = {/Users/eec35/Zotero/storage/PZ5ZDNNB/Bergelson and Swingley - 2013 - The acquisition of abstract words by young infants.pdf;/Users/eec35/Zotero/storage/XWEW7EG2/S0010027713000395.html}
}

@article{bergelson2019,
  ids = {bergelson2019b},
  title = {Day by Day, Hour by Hour: {{Naturalistic}} Language Input to Infants},
  shorttitle = {Day by Day, Hour by Hour},
  author = {Bergelson, Elika and Amatuni, Andrei and Dailey, Shannon and Koorathota, Sharath and Tor, Shaelise},
  year = {2019},
  month = jan,
  journal = {Developmental Science},
  volume = {22},
  number = {1},
  pages = {e12715},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12715},
  urldate = {2023-04-13},
  langid = {english},
  pmcid = {PMC6294661},
  pmid = {30094888},
  keywords = {Female,Humans,Infant,Language,Language Development,Male,Time Factors,Video Recording},
  file = {/Users/eec35/Zotero/storage/W65KHHUF/Bergelson et al. - 2019 - Day by day, hour by hour Naturalistic language in.pdf}
}

@article{bergelson2019c,
  ids = {bergelson2018,bergelson2019a},
  title = {What {{Do North American Babies Hear}}? {{A}} Large-Scale Cross-Corpus Analysis},
  shorttitle = {What {{Do North American Babies Hear}}?},
  author = {Bergelson, Elika and Casillas, Marisa and Soderstrom, Melanie and Seidl, Amanda and Warlaumont, Anne S. and Amatuni, Andrei},
  year = {2019},
  journal = {Developmental Science},
  volume = {22},
  number = {1},
  pages = {e12724},
  issn = {1467-7687},
  doi = {10.1111/desc.12724},
  urldate = {2023-04-21},
  abstract = {A range of demographic variables influences how much speech young children hear. However, because studies have used vastly different sampling methods, quantitative comparison of interlocking demographic effects has been nearly impossible, across or within studies. We harnessed a unique collection of existing naturalistic, day-long recordings from 61 homes across four North American cities to examine language input as a function of age, gender, and maternal education. We analyzed adult speech heard by 3- to 20-month-olds who wore audio recorders for an entire day. We annotated speaker gender and speech register (child-directed or adult-directed) for 10,861 utterances from female and male adults in these recordings. Examining age, gender, and maternal education collectively in this ecologically valid dataset, we find several key results. First, the speaker gender imbalance in the input is striking: children heard 2\textendash 3\texttimes{} more speech from females than males. Second, children in higher-maternal education homes heard more child-directed speech than those in lower-maternal education homes. Finally, our analyses revealed a previously unreported effect: the proportion of child-directed speech in the input increases with age, due to a decrease in adult-directed speech with age. This large-scale analysis is an important step forward in collectively examining demographic variables that influence early development, made possible by pooled, comparable, day-long recordings of children's language environments. The audio recordings, annotations, and annotation software are readily available for reuse and reanalysis by other researchers.},
  langid = {english},
  pmcid = {PMC6294666},
  pmid = {30369005},
  keywords = {addressee,Adult,child directed speech,{Child, Preschool},Demography,Educational Status,Female,gender,Humans,Infant,language development,Language Development,linguistic input,Male,maternal education,Sex Factors,Speech Perception,Tape Recording,United States},
  file = {/Users/eec35/Zotero/storage/F4WGTGNG/Bergelson et al. - 2018 - What Do North American Babies Hear A large-scale cross-corpus analysis.pdf;/Users/eec35/Zotero/storage/JL95LH6S/Bergelson et al. - 2019 - What Do North American Babies Hear A large-scale .pdf;/Users/eec35/Zotero/storage/Q835ZRA6/desc.html}
}

@article{bergelson2022a,
  title = {Everyday Language Input and Production in 1001 Children from 6 Continents},
  author = {Bergelson, Elika and Soderstrom, Melanie and Schwarz, Iris-Corinna and Rowland, Caroline and {Ramirez-Esparza}, Nairan and Hamrick, Lisa and Marklund, Ellen and Kalashnikova, Marina and Guez, Ava and Casillas, Marisa},
  year = {2022},
  publisher = {{PsyArXiv}}
}

@article{bernsteinratner1984,
  title = {Patterns of Vowel Modification in Mother\textendash Child Speech},
  author = {Bernstein Ratner, Nan},
  year = {1984},
  journal = {Journal of Child Language},
  volume = {11},
  pages = {557--578},
  publisher = {{Cambridge University Press}},
  address = {{United Kingdom}},
  issn = {1469-7602},
  abstract = {Analyzed patterns of vowel articulation in conversational speech to an adult and to child listeners in the speech of 9 mothers. The sample contained 3 mothers with daughters who were preverbal but above 9 mo of age, 3 mothers with daughters who had holophrastic stage language, and 3 mothers with daughters having mean length of utterances between 2.0 and 3.5. Formant frequency analysis of vowels embedded in 2,406 words found in varying syntactic environments and uttered by Ss to preverbal, holophrastic, and more advanced child listeners revealed an emerging pattern of content word clarification, as measured by a wider dispersion and decreased overlap between vowel phoneme categories in formant characteristics. Additionally, function word clarification was noted in speech to the oldest children. It is suggested that vowel production is modulated by child-addressee language ability. Earlier studies suggesting a lack of phonetic clarification in mother\textendash child speech may have investigated speech to children too mature to elicit maternal clarification behaviors. (26 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Articulation (Speech),Conversation,Developmental Stages,Language Development,Mother Child Communication,Mothers,Vowels},
  file = {/Users/eec35/Zotero/storage/QGXETMEF/1985-09153-001.html}
}

@article{bigelow1987,
  title = {Early Words of Blind Children},
  author = {Bigelow, Ann},
  year = {1987},
  month = feb,
  journal = {Journal of Child Language},
  volume = {14},
  number = {1},
  pages = {47--56},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900012721},
  urldate = {2022-09-20},
  abstract = {ABSTRACT              The first 50 words of three blind children were collected and analysed using procedures used by Nelson (1973) on 18 sighted children. The early vocabulary of the blind children paralleled that of the sighted children in the age and speed of acquisition, and in the underlying characteristics of what the children chose to label. These reflect a sensorimotor organization in which self-action and perceptual change are the salient variables. The early words of the blind children differed from those of sighted children in the percentage of words in each of Nelson's grammatical categories. This suggests differences in how the children use language. These differences are discussed as a function of the children's lack of vision and their particular language learning context.},
  langid = {english}
}

@misc{bratt2022,
  title = {Morphemepiece: {{Morpheme Tokenization}}},
  shorttitle = {Morphemepiece},
  author = {Bratt, Jonathan and Harmon, Jon and Learning, Bedford Freeman \& Worth Pub Grp LLC DBA Macmillan},
  year = {2022},
  month = apr,
  urldate = {2023-04-21},
  abstract = {Tokenize text into morphemes. The morphemepiece algorithm uses a lookup table to determine the morpheme breakdown of words, and falls back on a modified wordpiece tokenization algorithm for words not found in the lookup table.},
  copyright = {Apache License ({$\geq$} 2)}
}

@article{brugman2009,
  title = {Annotating {{Multimedia}} / {{Multi-modal}} Resources with {{ELAN}}},
  author = {Brugman, Hennie and Russel, Albert},
  year = {2009},
  month = mar,
  journal = {Proceedings of the Fourth International Conference on Language Resources and Evaluation},
  abstract = {This paper shows the actual state of development of the manual annotation tool ELAN. It presents usage requirements from three different groups of users and how one annotation model and a number of generic design principles guided the choices made during the development process of ELAN.},
  file = {/Users/eec35/Zotero/storage/PVQV9GWE/Brugman and Russel - 2009 - Annotating Multimedia  Multi-modal resources with.pdf}
}

@article{busch2018,
  title = {Correlation and Agreement between {{Language ENvironment Analysis}} ({{LENA}}\texttrademark ) and Manual Transcription for {{Dutch}} Natural Language Recordings},
  author = {Busch, Tobias and Sangen, Anouk and Vanpoucke, Filiep and {van Wieringen}, Astrid},
  year = {2018},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {50},
  number = {5},
  pages = {1921--1932},
  issn = {1554-3528},
  doi = {10.3758/s13428-017-0960-0},
  abstract = {The Language ENvironment Analysis system (LENA\texttrademark ) automatically analyzes the natural sound environments of children. Among other things, it estimates the amounts of adult words (AWC), child vocalizations (CV), conversational turns (CT), and electronic media (TV) that a child is exposed to. To assess LENA's reliability, we compared it to manual transcription. Specifically, we calculated the correlation and agreement between the LENA estimates and manual counts for 48 five-min audio samples. These samples were selected from eight day-long recordings of six Dutch-speaking children (ages 2-5). The correlations were strong for AWC, r\,=\,\,.\,87, and CV, r\,=\,\,.\,77, and comparatively low for CT, r\,=\,\,.\,52, and TV, r\,=\,\,.\,50. However, the agreement analysis revealed a constant bias in AWC counts, and proportional biases for CV and CT (i.e., the bias varied with the values for CV and CT). Agreement for detecting electronic media was poor. Moreover, the limits of agreement were wide for all four metrics. That is, the differences between LENA and the manual transcriptions for individual audio samples varied widely around the mean difference. This variation could indicate that LENA was affected by differences between the samples that did not equally affect the human transcribers. The disagreements and biases cast doubt on the comparability of LENA measurements across families and time, which is crucial for using LENA in research. Our sample is too small to conclude within which limits LENA's measurements are comparable, but it seems advisable to be cautious of factors that could systematically bias LENA's performance and thereby create confounds.},
  langid = {english},
  pmid = {28936690},
  keywords = {Adult,Adult word count,Agreement,Automatic speech recognition,Bias,Child vocalization count,{Child, Preschool},Conversational turn count,Dutch,Electronic media,Environment,Female,Human transcription,Humans,Language,Male,Measurement error,Method comparison,Netherlands,Reliability,Reproducibility of Results,Speech Recognition Software},
  file = {/Users/eec35/Zotero/storage/LKHGYFYQ/Busch et al. - 2018 - Correlation and agreement between Language ENviron.pdf}
}

@article{campbell2003,
  title = {Maternal {{Directives}} to {{Young Children}} Who Are {{Blind}}},
  author = {Campbell, Julie},
  year = {2003},
  month = jun,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {97},
  number = {6},
  pages = {355--365},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X0309700604},
  urldate = {2022-09-15},
  abstract = {The results of a detailed analysis of how mothers direct attention and play with their blind and sighted 18-month-old children found that the mothers of the blind children were no more directive than were the mothers of the sighted children, but that they made some use of directives that were particular to the needs of young blind children.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/XI5S3MP7/Campbell - 2003 - Maternal Directives to Young Children who are Blin.pdf}
}

@article{campbell2022,
  title = {Making Sense of Sensory Language: {{Acquisition}} of Sensory Knowledge by Individuals with Congenital Sensory Impairments},
  shorttitle = {Making Sense of Sensory Language},
  author = {Campbell, Erin E. and Bergelson, Elika},
  year = {2022},
  month = sep,
  journal = {Neuropsychologia},
  volume = {174},
  pages = {108320},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2022.108320},
  urldate = {2022-09-05},
  abstract = {The present article provides a narrative review on how language communicates sensory information and how knowledge of sight and sound develops in individuals born deaf or blind. Studying knowledge of the perceptually inaccessible sensory domain for these populations offers a lens into how humans learn about that which they cannot perceive. We first review the linguistic strategies within language that communicate sensory information. Highlighting the power of language to shape knowledge, we next review the detailed knowledge of sensory information by individuals with congenital sensory impairments, limitations therein, and neural representations of imperceptible phenomena. We suggest that the acquisition of sensory knowledge is supported by language, experience with multiple perceptual domains, and cognitive and social abilities which mature over the first years of life, both in individuals with and without sensory impairment. We conclude by proposing a developmental trajectory for acquiring sensory knowledge in the absence of sensory perception.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/MBKB98QN/Campbell and Bergelson - 2022 - Making sense of sensory language Acquisition of s.pdf;/Users/eec35/Zotero/storage/VHMXDD9P/S0028393222001798.html}
}

@misc{campbellsubmitted,
  title = {The {{Role}} of {{Vision}} in the {{Acquisition}} of {{Words}}: {{Vocabulary Development}} in {{Blind Toddlers}}},
  author = {Campbell, Erin E. and Casillas, Robyn and Bergelson, Elika},
  year = {submitted},
  doi = {10.17605/OSF.IO/UW6ZM}
}

@misc{chernyak,
  title = {3 {{Ways}} to {{Teach Your Blind}} or {{Visually Impaired Child}} to {{Talk}}},
  author = {Chernyak, Paul},
  journal = {WikiHow},
  urldate = {2023-04-21},
  howpublished = {https://www.wikihow.life/Teach-Your-Blind-or-Visually-Impaired-Child-to-Talk},
  file = {/Users/eec35/Zotero/storage/8NLNP82U/Teach-Your-Blind-or-Visually-Impaired-Child-to-Talk.html}
}

@article{chiesa2015,
  title = {Communicative Interactions between Visually Impaired Mothers and Their Sighted Children: Analysis of Gaze, Facial Expressions, Voice and Physical Contacts},
  shorttitle = {Communicative Interactions between Visually Impaired Mothers and Their Sighted Children},
  author = {Chiesa, S. and Galati, D. and Schmidt, S.},
  year = {2015},
  month = nov,
  journal = {Child: Care, Health and Development},
  volume = {41},
  number = {6},
  pages = {1040--1046},
  issn = {1365-2214},
  doi = {10.1111/cch.12274},
  abstract = {BACKGROUND: Social and emotional development of infants and young children is largely based on the communicative interaction with their mother, or principal caretaker (Trevarthen ). The main modalities implied in this early communication are voice, facial expressions and gaze (Stern ). This study aims at analysing early mother-child interactions in the case of visually impaired mothers who do not have access to their children's gaze and facial expressions. METHODS: Spontaneous play interactions between seven visually impaired mothers and their sighted children aged between 6\,months and 3\,years were filmed. These dyads were compared with a control group of sighted mothers and children analysing four modalities of communication and interaction regulation: gaze, physical contacts, verbal productions and facial expressions. RESULTS: The visually impaired mothers' facial expressions differed from the ones of sighted mothers mainly with respect to forehead movements, leading to an impoverishment of conveyed meaning. Regarding the other communicative modalities, results suggest that visually impaired mothers and their children use compensatory strategies to guaranty harmonic interaction despite the mother's impairment: whereas gaze results the main factor of interaction regulation in sighted dyads, physical contacts and verbal productions assume a prevalent role in dyads with visually impaired mothers. Moreover, visually impaired mother's children seem to be able to differentiate between their mother and sighted interaction partners, adapting differential modes of communication. CONCLUSIONS: The results of this study show that, in spite of the obvious differences in the modes of communication, visual impairment does not prevent a harmonious interaction with the child.},
  langid = {english},
  pmid = {26250608},
  keywords = {Child Development,{Child, Preschool},Communication,communication skills,Facial Expression,Female,Humans,Infant,joint attention,Male,mother-child interaction,Mother-Child Relations,Mothers,social development,visually impaired mothers,Visually Impaired Persons},
  file = {/Users/eec35/Zotero/storage/K289D46I/Chiesa et al. - 2015 - Communicative interactions between visually impair.pdf}
}

@article{choi2020,
  title = {Reciprocal {{Influences Between Parent Input}} and {{Child Language Skills}} in {{Dyads Involving High}}- and {{Low}}-{{Risk Infants}} for {{Autism Spectrum Disorder}}},
  author = {Choi, Boin and Nelson, Charles A. and Rowe, Meredith L. and Tager-Flusberg, Helen},
  year = {2020},
  month = jul,
  journal = {Autism Research},
  volume = {13},
  number = {7},
  pages = {1168--1183},
  issn = {1939-3792, 1939-3806},
  doi = {10.1002/aur.2270},
  urldate = {2023-05-03},
  langid = {english}
}

@article{cristia2021b,
  ids = {cristia2021,cristia2021a},
  title = {A Thorough Evaluation of the {{Language Environment Analysis}} ({{LENA}}) System},
  author = {Cristia, Alejandrina and Lavechin, Marvin and Scaff, Camila and Soderstrom, Melanie and Rowland, Caroline and R{\"a}s{\"a}nen, Okko and Bunce, John and Bergelson, Elika},
  year = {2021},
  month = apr,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {2},
  pages = {467--486},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01393-5},
  urldate = {2023-04-22},
  abstract = {In the previous decade, dozens of studies involving thousands of children across several research disciplines have made use of a combined daylong audio-recorder and automated algorithmic analysis called the LENA(R) system, which aims to assess children's language environment. While the system's prevalence in the language acquisition domain is steadily growing, there are only scattered validation efforts on only some of its key characteristics. Here, we assess the LENA(R) system's accuracy across all of its key measures: speaker classification, Child Vocalization Counts (CVC), Conversational Turn Counts (CTC), and Adult Word Counts (AWC). Our assessment is based on manual annotation of clips that have been randomly or periodically sampled out of daylong recordings, collected from (a) populations similar to the system's original training data (North American English-learning children aged 3-36 months), (b) children learning another dialect of English (UK), and (c) slightly older children growing up in a different linguistic and socio-cultural setting (Tsimane' learners in rural Bolivia). We find reasonably high accuracy in some measures (AWC, CVC), with more problematic levels of performance in others (CTC, precision of male adults and other children). Statistical analyses do not support the view that performance is worse for children who are dissimilar from the LENA(R) original training set. Whether LENA(R) results are accurate enough for a given research, educational, or clinical application depends largely on the specifics at hand. We therefore conclude with a set of recommendations to help researchers make this determination for their goals.},
  langid = {english},
  keywords = {Adult Word Count,Agreement,Child Vocalization Count,Conversational Turn Count,English,Human transcription,LENA,Measurement error,Method comparison,Reliability,Speech technology,Tsimane'},
  file = {/Users/eec35/Zotero/storage/NTI57AKQ/Cristia et al. - 2021 - A thorough evaluation of the Language Environment .pdf}
}

@article{demir2015,
  title = {Vocabulary, Syntax, and Narrative Development in Typically Developing Children and Children with Early Unilateral Brain Injury: Early Parental Talk about the "There-and-Then" Matters},
  shorttitle = {Vocabulary, Syntax, and Narrative Development in Typically Developing Children and Children with Early Unilateral Brain Injury},
  author = {Demir, {\"O}zlem Ece and Rowe, Meredith L. and Heller, Gabriella and {Goldin-Meadow}, Susan and Levine, Susan C.},
  year = {2015},
  month = feb,
  journal = {Developmental Psychology},
  volume = {51},
  number = {2},
  pages = {161--175},
  issn = {1939-0599},
  doi = {10.1037/a0038476},
  abstract = {This study examines the role of a particular kind of linguistic input--talk about the past and future, pretend, and explanations, that is, talk that is decontextualized--in the development of vocabulary, syntax, and narrative skill in typically developing (TD) children and children with pre- or perinatal brain injury (BI). Decontextualized talk has been shown to be particularly effective in predicting children's language skills, but it is not clear why. We first explored the nature of parent decontextualized talk and found it to be linguistically richer than contextualized talk in parents of both TD and BI children. We then found, again for both groups, that parent decontextualized talk at child age 30 months was a significant predictor of child vocabulary, syntax, and narrative performance at kindergarten, above and beyond the child's own early language skills, parent contextualized talk and demographic factors. Decontextualized talk played a larger role in predicting kindergarten syntax and narrative outcomes for children with lower syntax and narrative skill at age 30 months, and also a larger role in predicting kindergarten narrative outcomes for children with BI than for TD children. The difference between the 2 groups stemmed primarily from the fact that children with BI had lower narrative (but not vocabulary or syntax) scores than TD children. When the 2 groups were matched in terms of narrative skill at kindergarten, the impact that decontextualized talk had on narrative skill did not differ for children with BI and for TD children. Decontextualized talk is thus a strong predictor of later language skill for all children, but may be particularly potent for children at the lower-end of the distribution for language skill. The findings also suggest that variability in the language development of children with BI is influenced not only by the biological characteristics of their lesions, but also by the language input they receive.},
  langid = {english},
  pmcid = {PMC4307606},
  pmid = {25621756},
  keywords = {Brain Injuries,Case-Control Studies,Child Development,{Child, Preschool},Female,Humans,Language Development,Linguistics,Longitudinal Studies,Male,Parent-Child Relations,Vocabulary},
  file = {/Users/eec35/Zotero/storage/QCRCEKN4/Demir et al. - 2015 - Vocabulary, syntax, and narrative development in t.pdf}
}

@article{devilliers1985,
  title = {Learning How to Use Verbs: Lexical Coding and the Influence of the Input*},
  shorttitle = {Learning How to Use Verbs},
  author = {De Villiers, Jill},
  year = {1985},
  month = oct,
  journal = {Journal of Child Language},
  volume = {12},
  number = {3},
  pages = {587--595},
  publisher = {{Cambridge University Press}},
  issn = {1469-7602, 0305-0009},
  doi = {10.1017/S0305000900006668},
  urldate = {2022-09-15},
  abstract = {Samples of spontaneous speech from two young children and their mothers were analysed to examine how children learn some of the inflectional/syntactic possibilities for individual verbs. Multiple regression analyses were performed to establish predictors of the children's range of grammatical use of particular verbs. Maternal variety of use proved to be a highly significant predictor of the children's use of the same verbs, but maternal frequency was not a significant predictor of children's use. Step-wise regression analyses revealed that each child's own mother's use was a significantly better predictor of the child's use than that of the unacquainted mother. It is argued that the children were monitoring the grammatical patterns of use of individual verbs in the input they received. The extent of novel use of verbs by the child cannot be assessed from these data, and awaits further experimental investigation.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/Y2Y95S7P/86C31542277D235C161A0A0C87F62772.html}
}

@article{dirks2020,
  title = {Talk with Me! {{Parental}} Linguistic Input to Toddlers with Moderate Hearing Loss},
  author = {Dirks, Evelien and Stevens, Angela and Kok, Sigrid and Frijns, Johan and Rieffe, Carolien},
  year = {2020},
  month = jan,
  journal = {Journal of Child Language},
  volume = {47},
  number = {1},
  pages = {186--204},
  publisher = {{Cambridge University Press}},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000667},
  urldate = {2022-08-24},
  abstract = {This study examined the quantity and quality of parental linguistic input to toddlers with moderate hearing loss (MHL) compared with toddlers with normal hearing (NH). The linguistic input to eighteen toddlers with MHL and twenty-four toddlers with NH was examined during a 10-minute free-play activity in their home environment. Results showed that toddlers with MHL were exposed to an equivalent amount of parental linguistic input compared to toddlers with NH. However, parents of toddlers with MHL used less high-level facilitative language techniques, used less mental state language, and used shorter utterances than parents of toddlers with NH. Quantity and quality measures of parental linguistic input were positively related to the expressive language abilities of toddlers with MHL.},
  langid = {english},
  keywords = {hearing loss,language development,parental linguistic input},
  file = {/Users/eec35/Zotero/storage/BX8PAZ5P/Dirks et al. - 2020 - Talk with me! Parental linguistic input to toddler.pdf;/Users/eec35/Zotero/storage/L8S488TN/B444170912B4A3AB5D1087CB16ABFF44.html}
}

@article{donnellan2020,
  title = {Infants' Intentionally Communicative Vocalizations Elicit Responses from Caregivers and Are the Best Predictors of the Transition to Language: {{A}} Longitudinal Investigation of Infants' Vocalizations, Gestures and Word Production},
  shorttitle = {Infants' Intentionally Communicative Vocalizations Elicit Responses from Caregivers and Are the Best Predictors of the Transition to Language},
  author = {Donnellan, Ed and Bannard, Colin and McGillion, Michelle L. and Slocombe, Katie E. and Matthews, Danielle},
  year = {2020},
  month = jan,
  journal = {Developmental Science},
  volume = {23},
  number = {1},
  pages = {e12843},
  issn = {1467-7687},
  doi = {10.1111/desc.12843},
  abstract = {What aspects of infants' prelinguistic communication are most valuable for learning to speak, and why? We test whether early vocalizations and gestures drive the transition to word use because, in addition to indicating motoric readiness, they (a) are early instances of intentional communication and (b) elicit verbal responses from caregivers. In study 1, 11 month olds~(N~=~134) were observed to coordinate vocalizations and gestures with gaze to their caregiver's face at above chance rates, indicating that they are plausibly intentionally communicative. Study 2 tested whether those infant communicative acts that were gaze-coordinated best predicted later expressive vocabulary. We report a novel procedure for predicting vocabulary via multi-model inference over a comprehensive set of infant behaviours produced at 11 and 12 months (n~=~58). This makes it possible to establish the relative predictive value of different behaviours that are hierarchically organized by level of granularity. Gaze-coordinated vocalizations were the most valuable predictors of expressive vocabulary size up to 24~months. Study 3 established that caregivers were more likely to respond to gaze-coordinated behaviours. Moreover, the dyadic combination of infant gaze-coordinated vocalization and caregiver response was by far the best predictor of later vocabulary size. We conclude that practice with prelinguistic intentional communication facilitates the leap to symbol use. Learning is optimized when caregivers respond to intentional vocalizations with appropriate language.},
  langid = {english},
  pmid = {31045301},
  keywords = {Caregivers,Communication,Female,{Fixation, Ocular},Gestures,Humans,infancy,Infant,Infant Behavior,Language,Language Development,learning,Lexicon,Male,parenting,social communication,Vocabulary},
  file = {/Users/eec35/Zotero/storage/LUK8QRHS/Donnellan et al. - 2020 - Infants' intentionally communicative vocalizations.pdf}
}

@article{dote-kwan1995,
  title = {Impact of {{Mothers}}' {{Interactions}} on the {{Development}} of {{Their Young Visually Impaired Children}}},
  author = {{Dote-Kwan}, J.},
  year = {1995},
  month = jan,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {89},
  number = {1},
  pages = {46--58},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X9508900109},
  urldate = {2021-06-21},
  abstract = {This article reports on a study of the relationship between mother-child interactions and children's development for 18 children, aged 20\textendash 36 months with severe visual impairments and no other known handicapping condition. The study found that mother-responsive behaviors were positively related to the children's development, whereas mother-initiated behaviors were either negatively related or not related.},
  langid = {english},
  keywords = {early blindness}
}

@misc{familyconnect,
  title = {Understanding the {{Stages}} of {{Language Development}} for {{Babies Who Are Blind}}},
  author = {FamilyConnect},
  journal = {FamilyConnect},
  urldate = {2023-04-21},
  abstract = {Repeating or echoing what other people say is a stage all children go through. It's a way of practicing speech and learning about language and communication. For blind and visually impaired children, this stage sometimes seems to last a long time. Language is abstract. Words stand for real people, concepts, or things. Until your child \ldots{} Continued},
  langid = {american},
  file = {/Users/eec35/Zotero/storage/Q3XX3QM4/language-development.html}
}

@article{fenson1994,
  title = {Variability in {{Early Communicative Development}}},
  author = {Fenson, Larry and Dale, Philip S. and Reznick, J. Steven and Bates, Elizabeth and Thal, Donna J. and Pethick, Stephen J. and Tomasello, Michael and Mervis, Carolyn B. and Stiles, Joan},
  year = {1994},
  journal = {Monographs of the Society for Research in Child Development},
  volume = {59},
  number = {5},
  pages = {i},
  publisher = {{JSTOR}},
  issn = {0037976X},
  doi = {10.2307/1166093},
  abstract = {Data from parent reports on 1,803 children\textendash derived from a normative study of the MacArthur Communicative Development Inventories (CDIs)\textendash are used to describe the typical course and the extent of variability in major features of communicative development between 8 and 30 months of age. The two instruments, one designed for 8-16-month-old infants, the other for 16-30-month-old toddlers, are both reliable and valid, confirming the value of parent reports that are based on contemporary behavior and a recognition format. Growth trends are described for children scoring at the 10th-, 25th-, 50th-, 75th-, and 90th-percentile levels on receptive and expressive vocabulary, actions and gestures, and a number of aspects of morphology and syntax. Extensive variability exists in the rate of lexical, gestural, and grammatical development. The wide variability across children in the time of onset and course of acquisition of these skills challenges the meaningfulness of the concept of the modal child. At the same time, moderate to high intercorrelations are found among the different skills both concurrently and predictively (across a 6-month period). Sex differences consistently favor females; however, these are very small, typically accounting for 1\%-2\% of the variance. The effects of SES and birth order are even smaller within this age range. The inventories offer objective criteria for defining typicality and exceptionality, and their cost effectiveness facilitates the aggregation of large data sets needed to address many issues of contemporary theoretical interest. The present data also offer unusually detailed information on the course of development of individual lexical, gestural, and grammatical items and features. Adaptations of the CDIs to other languages have opened new possibilities for cross-linguistic explorations of sequence, rate, and variability of communicative development.},
  pmid = {7845413}
}

@article{ferjanramirez2021,
  title = {Comparing {{Automatic}} and {{Manual Measures}} of {{Parent}}\textendash{{Infant Conversational Turns}}: {{A Word}} of {{Caution}}},
  shorttitle = {Comparing {{Automatic}} and {{Manual Measures}} of {{Parent}}\textendash{{Infant Conversational Turns}}},
  author = {Ferjan Ram{\'i}rez, Naja and Hippe, Daniel S. and Kuhl, Patricia K.},
  year = {2021},
  journal = {Child Development},
  volume = {92},
  number = {2},
  pages = {672--681},
  issn = {1467-8624},
  doi = {10.1111/cdev.13495},
  urldate = {2022-11-28},
  abstract = {The Language ENvironment Analysis system (LENA) records children's language environment and provides an automatic estimate of adult\textendash child conversational turn count (CTC). The present study compares LENA's CTC estimate to manually coded CTC on a sample of 70 English-speaking infants recorded longitudinally at 6, 10, 14, 18, and 24 months of age. At each age, LENA's CTC was significantly higher than manually coded CTC (all ps {$<$} .001, Cohen's ds: 0.9\textendash 2.05), with the largest discrepancies between the two methods observed at younger ages. The Limits of Agreement Analyses confirm wide disagreements between the two methods, highlighting potential problems with automatic measurement of parent\textendash infant verbal interaction. These findings suggest that future studies should validate LENA's CTC estimates with manual coding.},
  langid = {english},
  keywords = {LENA},
  file = {/Users/eec35/Zotero/storage/3YKH59ER/Ferjan Ramírez et al. - 2021 - Comparing Automatic and Manual Measures of Parent–.pdf;/Users/eec35/Zotero/storage/R4XKC6KE/cdev.html}
}

@article{fernald1989,
  title = {Intonation and Communicative Intent in Mothers' Speech to Infants: Is the Melody the Message?},
  shorttitle = {Intonation and Communicative Intent in Mothers' Speech to Infants},
  author = {Fernald, A.},
  year = {1989},
  month = dec,
  journal = {Child Development},
  volume = {60},
  number = {6},
  pages = {1497--1510},
  issn = {0009-3920},
  abstract = {This study explores the power of intonation to convey meaningful information about the communicative intent of the speaker in speech addressed to preverbal infants and in speech addressed to adults. Natural samples of infant- and adult-directed speech were recorded from 5 mothers of 12-month-old infants, in 5 standardized interactional contexts: Attention-bid, Approval, Prohibition, Comfort, and Game/Telephone. 25 infant-directed and 25 adult-directed vocalizations were electronically filtered to eliminate linguistic content. The content-filtered speech stimuli were presented to 80 adult subjects: 40 experienced parents and 40 students inexperienced with infants. The subjects' task was to identify the communicative intent of the speaker using only prosodic information, given a 5-alternative forced choice. Listeners were able to use intonation to identify the speaker's intent with significantly higher accuracy in infant-directed speech than in adult-directed speech. These findings suggest that the prosodic patterns of speech to infants are more informative than those of adult-adult speech, and may provide the infant with reliable cues to the communicative intent of the speaker. The interpretation of these results proposed here is that the relation of prosodic form to communicative function is made uniquely salient in the melodies of mothers' speech, and that these characteristic prosodic patterns are potentially meaningful to the preverbal infant.},
  langid = {english},
  pmid = {2612255},
  keywords = {Adult,Affect,Attention,Communication,Female,Humans,Infant,Language Development,Male,Maternal Behavior,Pitch Perception,Verbal Behavior}
}

@article{fraiberg1975,
  title = {The Development of Human Attachments in Infants Blind from Birth},
  author = {Fraiberg, Selma},
  year = {1975},
  journal = {Merrill-Palmer Quarterly},
  volume = {21},
  pages = {315--334},
  publisher = {{Wayne State University Press}},
  address = {{US}},
  issn = {1535-0266},
  abstract = {Normative data on the development of social and motor responses of blind infants was provided by home observations of 5 male and 5 female children 1-24 mo old. The social behaviors studied were (a) tactile discrimination of familiar and unfamiliar faces, (b) smiling to a familiar voice, (c) separation protest, (d) stranger avoidance, and (e) person permanence. Methods for studying these behaviors in blind children are explained, with discussion of their equivalents in sighted children. Norms for 10 gross motor behaviors are presented and compared with the identical behaviors in sighted children. Examples from observational protocols illustrate the methods and criteria employed. (36 ref) (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Blindness,Infant Development,Motor Development,Psychosocial Development},
  file = {/Users/eec35/Zotero/storage/FDLIGTX6/1976-12554-001.html}
}

@book{frank2021,
  title = {Variability and {{Consistency}} in {{Early Language Learning}}: {{The Wordbank Project}}},
  shorttitle = {Variability and {{Consistency}} in {{Early Language Learning}}},
  author = {Frank, Michael C. and Braginsky, Mika and Yurovsky, Daniel and Marchman, Virginia A.},
  year = {2021},
  month = mar,
  publisher = {{The MIT Press}},
  address = {{Cambridge}},
  abstract = {A data-driven exploration of how children's language learning varies across different languages, providing both a theoretical framework and reference.The Wordbank Project examines variability and consistency in children's language learning across different languages and cultures, drawing on Wordbank, an open database with data from more than 75,000 children and twenty-nine languages or dialects. This big data approach makes the book the most comprehensive cross-linguistic analysis to date of early language learning. Moreover, its data-driven picture of which aspects of language learning are consistent across languages suggests constraints on the nature of children's language learning mechanisms. The book provides both a theoretical framework for scholars of language learning, language, and human cognition, and a resource for future research.},
  isbn = {978-0-262-04510-0},
  langid = {english}
}

@article{ganea2013,
  title = {Talking about the near and Dear: {{Infants}}' Comprehension of Displaced Speech},
  shorttitle = {Talking about the near and Dear},
  author = {Ganea, Patricia A. and Saylor, Megan M.},
  year = {2013},
  month = jul,
  journal = {Developmental Psychology},
  volume = {49},
  number = {7},
  pages = {1299--1307},
  issn = {1939-0599},
  doi = {10.1037/a0030086},
  abstract = {The present research investigated the role of familiarity and proximity in infants' comprehension of displaced speech. When 13- and 16-month-old infants heard a researcher talk about a familiar person immediately after she left the room, they showed comprehension of the name by looking, pointing, or searching for the person in question. The majority of 16-month-olds were also able to reveal comprehension of the reference to the absent person after a 16-min delay, and they were able to respond to the name of an unfamiliar person as well. The 13-month-olds had more difficulty responding after the delay and to the name of a less familiar person. Thus, in the early phases of absent reference comprehension, infants' ability to respond to displaced speech can vary as a function of the temporal gap between the verbal reference and the last appearance of the referent, and of how strong their representation of the referent is.},
  langid = {english},
  pmid = {22985298},
  keywords = {Child Development,Comprehension,Female,Humans,Infant,Male,{Models, Psychological},Speech}
}

@article{ganea2018,
  title = {Development of Adaptive Communication Skills in Infants of Blind Parents},
  author = {Ganea, Nata{\c s}a and Hudry, Kristelle and Vernetti, Ang{\'e}lina and Tucker, Leslie and Charman, Tony and Johnson, Mark H. and Senju, Atsushi},
  year = {2018},
  month = dec,
  journal = {Developmental Psychology},
  volume = {54},
  number = {12},
  pages = {2265--2273},
  issn = {1939-0599},
  doi = {10.1037/dev0000564},
  abstract = {A fundamental question about the development of communication behavior in early life is how infants acquire adaptive communication behavior that is well-suited to their individual social environment, and how the experience of parent-child communication affects this development. The current study investigated how infants develop communication skills when their parents are visually impaired and cannot see their infants' eye gaze. We analyzed 6-min video recordings of naturalistic interaction between 14 sighted infants of blind parents (SIBP) with (a) their blind parent, and (b) a sighted experimenter. Data coded from these interactions were compared with those from 28 age-matched sighted infants of sighted parents (controls). Each infant completed two visits, at 6-10 months and 12-16 months of age. Within each interaction sample, we coded the function (initiation or response) and form (face gaze, vocalization, or action) of each infant communication behavior. When interacting with their parents, SIBP made relatively more communicative responses than initiations, and used more face gaze and fewer actions to communicate, than did controls. When interacting with a sighted experimenter, by contrast, SIBP made slightly (but significantly) more communicative initiations than controls, but otherwise used similar forms of communication. The differential communication behavior by infants of blind versus sighted parents was already apparent by 6-10 months of age, and was specific to communication with the parent. These results highlight the flexibility in the early development of human communication behavior, which enables infants to optimize their communicative bids and methods to their unique social environment. (PsycINFO Database Record (c) 2018 APA, all rights reserved).},
  langid = {english},
  pmcid = {PMC6254470},
  pmid = {30335435},
  keywords = {Blindness,Child Development,Child of Impaired Parents,Female,{Fixation, Ocular},Follow-Up Studies,Humans,Infant,Interpersonal Relations,Male,Nonverbal Communication,Parent-Child Relations,Verbal Behavior},
  file = {/Users/eec35/Zotero/storage/KWDN7XVK/Ganea et al. - 2018 - Development of adaptive communication skills in in.pdf}
}

@inproceedings{ganek2016,
  title = {The {{Language ENvironment Analysis}} ({{LENA}}) System: {{A}} Literature Review},
  shorttitle = {The {{Language ENvironment Analysis}} ({{LENA}}) System},
  booktitle = {Proceedings of the Joint Workshop on {{NLP}} for {{Computer Assisted Language Learning}} and {{NLP}} for {{Language Acquisition}}},
  author = {Ganek, Hillary and {Eriks-Brophy}, Alice},
  year = {2016},
  month = nov,
  pages = {24--32},
  publisher = {{LiU Electronic Press}},
  address = {{Ume\aa, Sweden}},
  urldate = {2022-08-24},
  file = {/Users/eec35/Zotero/storage/Q7KWMP5J/Ganek and Eriks-Brophy - 2016 - The Language ENvironment Analysis (LENA) system A.pdf}
}

@article{ganek2018,
  title = {Language {{ENvironment}} Analysis ({{LENA}}) System Investigation of Day Long Recordings in Children: {{A}} Literature Review},
  shorttitle = {Language {{ENvironment}} Analysis ({{LENA}}) System Investigation of Day Long Recordings in Children},
  author = {Ganek, Hillary and {Eriks-Brophy}, Alice},
  year = {2018},
  month = mar,
  journal = {Journal of Communication Disorders},
  volume = {72},
  pages = {77--85},
  issn = {0021-9924},
  doi = {10.1016/j.jcomdis.2017.12.005},
  urldate = {2023-05-04},
  abstract = {The Language ENvironment Analysis (LENA) System is a relatively new recording technology that can be used to investigate typical child language acquisition and populations with language disorders. The purpose of this paper is to familiarize language acquisition researchers and speech-language pathologists with how the LENA System is currently being used in research. The authors outline issues in peer-reviewed research based on the device. Considerations when using the LENA System are discussed.},
  langid = {english},
  keywords = {Automated vocal analysis,Language acquisition,LENA System},
  file = {/Users/eec35/Zotero/storage/ADAIW9NY/S0021992416301861.html}
}

@article{gergle2004,
  title = {Language {{Efficiency}} and {{Visual Technology}}: {{Minimizing Collaborative Effort}} with {{Visual Information}}},
  shorttitle = {Language {{Efficiency}} and {{Visual Technology}}},
  author = {Gergle, Darren and Kraut, Robert E. and Fussell, Susan R.},
  year = {2004},
  month = dec,
  journal = {Journal of Language and Social Psychology},
  volume = {23},
  number = {4},
  pages = {491--517},
  publisher = {{SAGE Publications Inc}},
  issn = {0261-927X},
  doi = {10.1177/0261927X04269589},
  urldate = {2022-08-25},
  abstract = {When collaborators work on a physical task, seeing a common workspace transforms their language use and reduces their overall collaborative effort. This article shows how visual information can make communication more efficient. In an experiment, dyads collaborated on building a puzzle. They communicated without a shared visual space, using a shared space featuring immediately updated visual information, and using a shared space featuring delayed visual updating. Having the shared visual space helps collaborators understand the current state of their task and enables them to ground their conversations efficiently, as seen in the ways in which participants adapted their discourse processes to their level of shared visual information. These processes are associated with faster and better task performance. Delaying the visual update reduces benefits and degrades performance. The shared visual space is more useful when tasks are visually complex or when participants have no simple vocabulary for describing their environments.},
  langid = {english},
  keywords = {collaboration,communication,computer-supported collaborative work,discourse,shared visual space},
  file = {/Users/eec35/Zotero/storage/Z3WEMQZP/Gergle et al. - 2004 - Language Efficiency and Visual Technology Minimiz.pdf}
}

@techreport{gilkerson2008,
  title = {The {{LENA Natural Language Study}}},
  author = {Gilkerson, Jill and Richards, Jeffrey A.},
  year = {2008},
  address = {{Boulder, CO}},
  institution = {{LENA Foundation}},
  abstract = {This paper describes the multiphase LENA Natural Language Study, an ongoing data collection effort designed to investigate the language environment of infants and toddlers. Data collected contributes to product development and normative information for use with the LENA System and child development research. Phase I study participants were representative of the US Census with respect to mothers' attained education and consisted of 329 normally developing infants and toddlers from monolingual Englishspeaking households living in the Denver-metro area. Participants provided day-long audio recordings of their natural language environment once a month, and certified speech language pathologists assessed participant language ability independently through standardized assessments. A subset of 80 Phase I participants has continued to provide monthly recordings in Phase II of the study. The normative database described herein contains over 32,000 hours of spontaneous speech data. This paper describes how normative information was derived for the Adult Word Count estimates (AWC; adult words spoken per day), Conversational Turns estimates (CT; adult-child alternations per day), and Child Vocalization frequency estimates (CV; words, babbles, and ``protophones'' or prespeech communicative sounds) that are reported in the LENA System.}
}

@article{gilkerson2018,
  title = {Language {{Experience}} in the {{Second Year}} of {{Life}} and {{Language Outcomes}} in {{Late Childhood}}},
  author = {Gilkerson, Jill and Richards, Jeffrey A. and Warren, Steven F. and Oller, D. Kimbrough and Russo, Rosemary and Vohr, Betty},
  year = {2018},
  month = oct,
  journal = {Pediatrics},
  volume = {142},
  number = {4},
  pages = {e20174276},
  issn = {0031-4005},
  doi = {10.1542/peds.2017-4276},
  urldate = {2022-08-24},
  abstract = {Quantity of talk and interaction in the home during early childhood is correlated with socioeconomic status (SES) and can be used to predict early language and cognitive outcomes. We tested the effectiveness of automated early language environment estimates for children 2 to 36 months old to predict cognitive and language skills 10 years later and examined effects for specific developmental age periods.Daylong audio recordings for 146 infants and toddlers were completed monthly for 6 months, and the total number of daily adult words and adult-child conversational turnswere automatically estimated with Language Environment Analysis software. Follow-up evaluations at 9 to 14 years of age included language and cognitive testing. Language exposure for 3 age groups was assessed: 2 to 17 months, 18 to 24 months, and {$\geq$}25 months. Pearson correlations and multiple linear regression analyses were conducted.Conversational turn counts at 18 to 24 months of age accounted for 14\% to 27\% of the variance in IQ, verbal comprehension, and receptive and/or expressive vocabulary scores 10 years later after controlling for SES. Adult word counts between 18 and 24 months were correlated with language outcomes but were considerably weakened after controlling for SES.These data support the hypothesis that early talk and interaction, particularly during the relatively narrow developmental window of 18 to 24 months of age, can be used to predict school-age language and cognitive outcomes. With these findings, we underscore the need for effective early intervention programs that support parents in creating an optimal early language learning environment in the home.},
  file = {/Users/eec35/Zotero/storage/CW2IWIEY/Gilkerson et al. - 2018 - Language Experience in the Second Year of Life and.pdf;/Users/eec35/Zotero/storage/6TU8J3WY/37424.html}
}

@article{gleitman1990,
  title = {The {{Structural Sources}} of {{Verb Meanings}}},
  author = {Gleitman, Lila},
  year = {1990},
  journal = {Language Acquisition},
  volume = {1},
  number = {1},
  eprint = {20011341},
  eprinttype = {jstor},
  pages = {3--55},
  publisher = {{Taylor \& Francis, Ltd.}},
  issn = {1048-9223},
  urldate = {2021-04-16}
}

@article{goldstein2008,
  title = {Social Feedback to Infants' Babbling Facilitates Rapid Phonological Learning},
  author = {Goldstein, Michael H. and Schwade, Jennifer A.},
  year = {2008},
  month = may,
  journal = {Psychological Science},
  volume = {19},
  number = {5},
  pages = {515--523},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2008.02117.x},
  abstract = {Infants' prelinguistic vocalizations are rarely considered relevant for communicative development. As a result, there are few studies of mechanisms underlying developmental changes in prelinguistic vocal production. Here we report the first evidence that caregivers' speech to babbling infants provides crucial, real-time guidance to the development of prelinguistic vocalizations. Mothers of 9.5-month-old infants were instructed to provide models of vocal production timed to be either contingent or noncontingent on their infants' babbling. Infants given contingent feedback rapidly restructured their babbling, incorporating phonological patterns from caregivers' speech, but infants given noncontingent feedback did not. The new vocalizations of the infants in the contingent condition shared phonological form but not phonetic content with their mothers' speech. Thus, prelinguistic infants learned new vocal forms by discovering phonological patterns in their mothers' contingent speech and then generalizing from these patterns.},
  langid = {english},
  pmid = {18466414},
  keywords = {{Feedback, Psychological},Female,Humans,Imitative Behavior,Infant,Infant Behavior,Language Development,Maternal Behavior,Mothers,Phonetics,Social Behavior,Speech Acoustics,Speech Perception,Verbal Learning}
}

@incollection{grice1975,
  ids = {kimball1975a},
  title = {{Logic and Conversation}},
  booktitle = {{Syntax and semantics}},
  author = {Grice, Herbert Paul},
  year = {1975},
  publisher = {{Academic press, Harcourt Brace Jovanovich}},
  address = {{New York San Francisco London}},
  isbn = {978-0-12-785423-6},
  langid = {xxx},
  lccn = {80}
}

@article{grigoroglou2016,
  title = {Are Children Flexible Speakers? {{Effects}} of Typicality and Listener Needs in Children's Event Descriptions},
  author = {Grigoroglou, Myrto and Edu, Udel and Papafragou, Anna},
  year = {2016},
  journal = {Cognitive Science},
  pages = {6},
  abstract = {Do children take into account their addressees' needs in spontaneous production? Developmental evidence for speaker adjustments is mixed. Some studies show that children are often under-informative when communicating with ignorant addressees but other studies demonstrate successes in children's ability to integrate another person's perspective. We asked whether children adapt their event descriptions depending on (a) the typicality of event components, and (b) the listener's visual access to the events. We found that children's ability to use information about the listener's visual perspective to make specific adjustments to event descriptions emerged only in highly interactive contexts, in which participants collaborated towards mutual goals.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/RNNMIXKN/Grigoroglou et al. - Are children flexible speakers Effects of typical.pdf}
}

@article{grimminger2020,
  title = {Decontextualized Talk in Caregivers' Input to 12-Month-Old Children during Structured Interaction},
  author = {Grimminger, Angela and Rohlfing, Katharina J. and L{\"u}ke, Carina and Liszkowski, Ulf and Ritterfeld, Ute},
  year = {2020},
  month = mar,
  journal = {Journal of Child Language},
  volume = {47},
  number = {2},
  pages = {418--434},
  publisher = {{Cambridge University Press}},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000710},
  urldate = {2023-05-04},
  abstract = {Decontextualized talk is assumed to be used only rarely when children are younger than 30 months. Motivated by B\"uhler's (1934/1999) linguistic theory that describes different dimensions of (de-)contextualization, we provide evidence that this kind of input can already be found in caregivers' talking to their 12-month-old children. Such early input is characterized by being decontextualized on some dimensions while being grounded in the immediate context on others. In this way, parents may scaffold understanding of talk about the there-and-then. We also examined whether caregivers adapt decontextualized verbal input to individual trajectories in language development. We observed 59 parent\textendash child interactions within a decorated room when children were 12 months old, and assessed the children's linguistic development at 12 and 24 months of age. However, we did not find differences in the input directed toward children with different trajectories in language development.},
  langid = {english},
  keywords = {12-month-olds,decontextualized talk,delayed language development,individual differences},
  file = {/Users/eec35/Zotero/storage/V9UZJ274/Grimminger et al. - 2020 - Decontextualized talk in caregivers’ input to 12-m.pdf}
}

@article{grumi2021,
  title = {Togetherness, beyond the Eyes: {{A}} Systematic Review on the Interaction between Visually Impaired Children and Their Parents},
  shorttitle = {Togetherness, beyond the Eyes},
  author = {Grumi, Serena and Cappagli, Giulia and Aprile, Giorgia and Mascherpa, Eleonora and Gori, Monica and Provenzi, Livio and Signorini, Sabrina},
  year = {2021},
  month = aug,
  journal = {Infant Behavior and Development},
  volume = {64},
  pages = {101590},
  issn = {0163-6383},
  doi = {10.1016/j.infbeh.2021.101590},
  urldate = {2023-02-14},
  abstract = {Background Parent-child interaction is essential to promote adaptive emotional, cognitive, and social development. The majority of previous research on parent-child interaction is largely dependent on face-to-face exchanges that require the interactive partners to visually recognize reciprocal communicative bids. Therefore, previous findings in the field can only partially apply to the early interactive patterns occurring between visually impaired infants and their parents. The present study was aimed to systematically review the available evidence on parent-child interaction in the context of developmental visual impairment. Methods Fourteen papers were finally selected after literature search on PubMed and Scopus. Data synthesis was focused on three core topics: visually impaired children's contribution to the interaction, parental caregiving behaviors with visually impaired children, and the association between parents' behaviors and the developmental outcomes of children with visual impairment. Results Visually impaired children may exhibit reduced reactivity to maternal stimuli and less-than-optimal levels of interactive initiations in social exchanges. Parents of children with visual impairment may use more descriptive communicative acts and greater directiveness compared to mothers of sighted counterparts. Specific caregiving behaviors (e.g., responsiveness and goal setting) of parents of children with visual impairment may significantly support language and socio-emotional development as well as sensorimotor integration. Discussion Children with visual impairment may be less responsive and they may produce less clear communicative bids while interacting with their parents. Their parents may face specific challenges while engaging with them and they may become increasingly directive and intrusive. Nonetheless, even in the presence of visual impairment, the quality of parental caregiving behaviors appears to play a potential preventive role in the face of children's socio-emotional and cognitive outcomes. These results suggest that early interventions focused on parent-child interactions are especially needed in this population.},
  langid = {english},
  keywords = {Children,Dyadic regulation,Parent-child interaction,Sensitivity,Visual impairment},
  file = {/Users/eec35/Zotero/storage/THGCJC8R/S0163638321000655.html}
}

@article{hadley2017,
  ids = {hadley2017a},
  title = {Input {{Subject Diversity Enhances Early Grammatical Growth}}: {{Evidence}} from a {{Parent-Implemented Intervention}}},
  shorttitle = {Input {{Subject Diversity Enhances Early Grammatical Growth}}},
  author = {Hadley, Pamela A. and Rispoli, Matthew and Holt, Janet K. and Papastratakos, Theodora and Hsu, Ning and Kubalanza, Mary and McKenna, Megan M.},
  year = {2017},
  journal = {Language Learning and Development: The Official Journal of the Society for Language Development},
  volume = {13},
  number = {1},
  pages = {54--79},
  issn = {1547-5441},
  doi = {10.1080/15475441.2016.1193020},
  abstract = {PURPOSE: The current study used an intervention design to test the hypothesis that parent input sentences with diverse lexical noun phrase (NP) subjects would accelerate growth in children's sentence diversity. METHOD: Child growth in third person sentence diversity was modeled from 21 to 30 months (n = 38) in conversational language samples obtained at 21, 24, 27, and 30 months. Treatment parents (n = 19) received instruction on strategies designed to increase lexical NP subjects (e.g., The baby is sleeping.). Instruction consisted of one group education session and two individual coaching sessions which took place when children were approximately 22 to 23 months of age. RESULTS: Treatment substantially increased parents' lexical NP subject tokens and types ({$\eta$}p2 {$\geq$} .45) compared to controls. Children's number of different words was a significant predictor of sentence diversity in the analyses of group treatment effects and individual input effects. Treatment condition was not a significant predictor of treatment effects on children's sentence diversity, but parents' lexical NP subject types was a significant predictor of children's sentence diversity growth, even after controlling for children's number of different words over time. CONCLUSIONS: These findings establish a link between subject diversity in parent input and children's early grammatical growth, and the feasibility of using relatively simple strategies to alter this specific grammatical property of parent language input.},
  langid = {english},
  pmcid = {PMC5343515},
  pmid = {28286431},
  keywords = {child-directed speech,language intervention,parent input,syntax,toddlers}
}

@inproceedings{hashemikamangar2020,
  title = {Children {{Semantic Network Growth}}: {{A Graph Theory Analysis}}},
  shorttitle = {Children {{Semantic Network Growth}}},
  booktitle = {2020 27th {{National}} and 5th {{International Iranian Conference}} on {{Biomedical Engineering}} ({{ICBME}})},
  author = {Hashemikamangar, Somayeh Sadat and Bakouie, Fatemeh and Gharibzadeh, Shahriar},
  year = {2020},
  month = nov,
  pages = {318--321},
  doi = {10.1109/ICBME51989.2020.9319438},
  abstract = {In this study, we aim to investigate how children's language develops. To do so, we apply the network model of language and examine the graph-theoretic properties of Word2Vec semantic networks of children through development. The networks are made of words children learn prior to the age of 30 months as the nodes. The links in the word-embedding networks are built from the cosine vector similarity of words normatively acquired by children prior to 2{$\frac{1}{2}$} years of age. By exploiting some graph measures such as the clustering coefficient and path length, the growth pattern of these semantic networks will be revealed. The small-world property allows for high amounts of local structure combined with global access. Within these semantic networks, there is a considerable local structure in the form of clusters of words. For global structure, some nodes act like bridges. They are actually the hubs of the network and connect the clusters which are semantically far-away. We explore the small-world property of these semantic networks and their changes through language development. The results demonstrate that the Word2Vec semantic networks of children show the small-world property from the early age of several months.},
  keywords = {Biomedical engineering,Biomedical measurement,Context modeling,Language Development,Level measurement,Network Analysis,Pediatrics,Semantic Networks,Semantics,Small-world Networks,Vocabulary,Word embedding},
  file = {/Users/eec35/Zotero/storage/JNW7KP9Y/Hashemikamangar et al. - 2020 - Children Semantic Network Growth A Graph Theory A.pdf;/Users/eec35/Zotero/storage/PF6P4FSB/9319438.html}
}

@article{hawkins2021,
  title = {The {{Division}} of {{Labor}} in {{Communication}}: {{Speakers Help Listeners Account}} for {{Asymmetries}} in {{Visual Perspective}}},
  shorttitle = {The {{Division}} of {{Labor}} in {{Communication}}},
  author = {Hawkins, Robert D. and Gweon, Hyowon and Goodman, Noah D.},
  year = {2021},
  journal = {Cognitive Science},
  volume = {45},
  number = {3},
  pages = {e12926},
  issn = {1551-6709},
  doi = {10.1111/cogs.12926},
  urldate = {2022-08-25},
  abstract = {Recent debates over adults' theory of mind use have been fueled by surprising failures of perspective-taking in communication, suggesting that perspective-taking may be relatively effortful. Yet adults routinely engage in effortful processes when needed. How, then, should speakers and listeners allocate their resources to achieve successful communication? We begin with the observation that the shared goal of communication induces a natural division of labor: The resources one agent chooses to allocate toward perspective-taking should depend on their expectations about the other's allocation. We formalize this idea in a resource-rational model augmenting recent probabilistic weighting accounts with a mechanism for (costly) control over the degree of perspective-taking. In a series of simulations, we first derive an intermediate degree of perspective weighting as an optimal trade-off between expected costs and benefits of perspective-taking. We then present two behavioral experiments testing novel predictions of our model. In Experiment 1, we manipulated the presence or absence of occlusions in a director\textendash matcher task. We found that speakers spontaneously modulated the informativeness of their descriptions to account for ``known unknowns'' in their partner's private view, reflecting a higher degree of speaker perspective-taking than previously acknowledged. In Experiment 2, we then compared the scripted utterances used by confederates in prior work with those produced in interactions with unscripted directors. We found that confederates were systematically less informative than listeners would initially expect given the presence of occlusions, but listeners used violations to adaptively make fewer errors over time. Taken together, our work suggests that people are not simply ``mindblind''; they use contextually appropriate expectations to navigate the division of labor with their partner. We discuss how a resource-rational framework may provide a more deeply explanatory foundation for understanding flexible perspective-taking under processing constraints.},
  langid = {english},
  keywords = {Communication,Pragmatics,Resource rationality,Theory of mind},
  file = {/Users/eec35/Zotero/storage/TXLY2MDT/Hawkins et al. - 2021 - The Division of Labor in Communication Speakers H.pdf;/Users/eec35/Zotero/storage/YA737ZH2/cogs.html}
}

@article{hazan2011,
  title = {Acoustic-Phonetic Characteristics of Speech Produced with Communicative Intent to Counter Adverse Listening Conditions},
  author = {Hazan, Valerie and Baker, Rachel},
  year = {2011},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {130},
  number = {4},
  pages = {2139--2152},
  issn = {0001-4966},
  doi = {10.1121/1.3623753},
  urldate = {2022-09-20}
}

@article{hirsh-pasek2015,
  title = {The {{Contribution}} of {{Early Communication Quality}} to {{Low-Income Children}}'s {{Language Success}}},
  author = {{Hirsh-Pasek}, Kathy and Adamson, Lauren B. and Bakeman, Roger and Owen, Margaret Tresch and Golinkoff, Roberta Michnick and Pace, Amy and Yust, Paula K. S. and Suma, Katharine},
  year = {2015},
  month = jul,
  journal = {Psychological Science},
  volume = {26},
  number = {7},
  pages = {1071--1083},
  issn = {1467-9280},
  doi = {10.1177/0956797615581493},
  abstract = {The disparity in the amount and quality of language that low-income children hear relative to their more-affluent peers is often referred to as the 30-million-word gap. Here, we expand the literature about this disparity by reporting the relative contributions of the quality of early parent-child communication and the quantity of language input in 60 low-income families. Including both successful and struggling language learners from the National Institute of Child Health and Human Development Study of Early Child Care and Youth Development, we noted wide variation in the quality of nonverbal and verbal interactions (symbol-infused joint engagement, routines and rituals, fluent and connected communication) at 24 months, which accounted for 27\% of the variance in expressive language 1 year later. These indicators of quality were considerably more potent predictors of later language ability than was the quantity of mothers' words during the interaction or sensitive parenting. Bridging the word gap requires attention to how caregivers and children establish a communication foundation within low-income families.},
  langid = {english},
  pmid = {26048887},
  keywords = {Adult,Child,Child Language,{Child, Preschool},Communication,Female,Humans,Infant,Interpersonal Relations,language development,Male,Mother-Child Relations,Parenting,Poverty,psycholinguistics,Psycholinguistics,relationship quality,social interaction,Vocabulary}
}

@article{hoff2002,
  title = {How Children Use Input to Acquire a Lexicon},
  author = {Hoff, Erika and Naigles, Letitia},
  year = {2002 Mar-Apr},
  journal = {Child Development},
  volume = {73},
  number = {2},
  pages = {418--433},
  issn = {0009-3920},
  doi = {10.1111/1467-8624.00415},
  abstract = {The contributions of social processes and computational processes to early lexical development were evaluated. A re-analysis and review of previous research cast doubt on the sufficiency of social approaches to word learning. An empirical investigation of the relation of social-pragmatic and data-providing features of input to the productive vocabulary of sixty-three 2-year-old children revealed benefits of data provided in mother-child conversation, but no effects of social aspects of those conversations. The findings further revealed that the properties of data that benefit lexical development in 2-year-olds are quantity, lexical richness, and syntactic complexity. The nature of the computational mechanisms implied by these findings is discussed. An integrated account of the roles of social and computational processes to lexical development is proposed.},
  langid = {english},
  pmid = {11949900},
  keywords = {{Child, Preschool},Female,Follow-Up Studies,Humans,Infant,Language Development,Male,Mother-Child Relations,Social Environment,Verbal Behavior,Verbal Learning,Vocabulary}
}

@article{hoff2003,
  title = {The Specificity of Environmental Influence: Socioeconomic Status Affects Early Vocabulary Development via Maternal Speech},
  shorttitle = {The Specificity of Environmental Influence},
  author = {Hoff, Erika},
  year = {2003 Sep-Oct},
  journal = {Child Development},
  volume = {74},
  number = {5},
  pages = {1368--1378},
  issn = {0009-3920},
  doi = {10.1111/1467-8624.00612},
  abstract = {The hypothesis was tested that children whose families differ in socioeconomic status (SES) differ in their rates of productive vocabulary development because they have different language-learning experiences. Naturalistic interaction between 33 high-SES and 30 mid-SES mothers and their 2-year-old children was recorded at 2 time points 10 weeks apart. Transcripts of these interactions provided the basis for estimating the growth in children's productive vocabularies between the first and second visits and properties of maternal speech at the first visit. The high-SES children grew more than the mid-SES children in the size of their productive vocabularies. Properties of maternal speech that differed as a function of SES fully accounted for this difference. Implications of these findings for mechanisms of environmental influence on child development are discussed.},
  langid = {english},
  pmid = {14552403},
  keywords = {{Child, Preschool},Female,Follow-Up Studies,Humans,Language Development,Male,Mother-Child Relations,Social Environment,Socioeconomic Factors,Verbal Behavior,Vocabulary},
  file = {/Users/eec35/Zotero/storage/UMSXULUR/Hoff - 2003 - The specificity of environmental influence socioe.pdf}
}

@article{howe2006,
  title = {Disabled Children, Parent-Child Interaction and Attachment},
  author = {Howe, David},
  year = {2006},
  month = may,
  journal = {Child {$<$}html\_ent glyph="@amp;" ascii="\&amp;"/{$>$} Family Social Work},
  volume = {11},
  number = {2},
  pages = {95--106},
  issn = {1356-7500, 1365-2206},
  doi = {10.1111/j.1365-2206.2006.00397.x},
  urldate = {2023-01-25},
  langid = {english}
}

@article{hsu2017,
  title = {Diversity Matters: Parent Input Predicts Toddler Verb Production},
  shorttitle = {Diversity Matters},
  author = {Hsu, Ning and Hadley, Pamela A. and Rispoli, Matthew},
  year = {2017},
  month = jan,
  journal = {Journal of Child Language},
  volume = {44},
  number = {1},
  pages = {63--86},
  issn = {1469-7602},
  doi = {10.1017/S0305000915000690},
  abstract = {The contribution of parent input to children's subsequent expressive verb diversity was explored in twenty typically developing toddlers with small verb lexicons. Child developmental factors and parent input measures (i.e. verb quantity, verb diversity, and verb-related structural cues) at age 1;9 were examined as potential predictors of children's verb production in spontaneous language samples at age 2;3. Parent verb input diversity, rather than input quantity, was the primary input factor contributing to children's subsequent verb diversity. Regression analysis showed that verb diversity in parent input at age 1;9 accounted for 30\% of the variance in children's verb production six months later, with children's total vocabulary size at age 1;9 accounting for an additional 16\% of the variance. These findings demonstrate the relative contributions of developmental and input factors to individual differences in toddlers' language development and establish the importance of input diversity to verb acquisition.},
  langid = {english},
  pmid = {26638832},
  keywords = {Child Development,{Child, Preschool},Cues,Female,Humans,Individuality,Infant,Language,Language Development,Male,Parents,Vocabulary}
}

@article{hudson2002,
  title = {"{{Do You Know What We}}'re {{Going}} to {{Do This Summer}}?": {{Mothers}}' {{Talk}} to {{Preschool Children About Future Events}}},
  shorttitle = {"{{Do You Know What We}}'re {{Going}} to {{Do This Summer}}?},
  author = {Hudson, Judith A.},
  year = {2002},
  month = feb,
  journal = {Journal of Cognition and Development},
  volume = {3},
  number = {1},
  pages = {49--71},
  publisher = {{Routledge}},
  issn = {1524-8372},
  doi = {10.1207/S15327647JCD0301_4},
  urldate = {2023-05-04},
  abstract = {Mothers engaged their 21/2- and 4-year-old children in conversations about novel and familiar past and future events. Analyses focused on (a) evidence for style differences in mothers' elicitation of future event talk, (b) the temporal frames of references (past, future, general, and hypothetical) mothers used across conversations, and (c) mothers' use of conventional time terms (e.g., last week, on Sunday). Mothers showed little consistency in style of elicitation over past and future conversations. In conversations about future events, mothers produced more references to future time, more hypothetical references, and more conventional time references. In talking about the past, mothers referred to the past more often and used more sequence terms. Mothers also varied their temporal references when talking about novel and familiar events. Results are discussed in terms of how conversations about future events can contribute to the development of children's concepts of time.}
}

@article{huttenlocher1991,
  title = {Early Vocabulary Growth: {{Relation}} to Language Input and Gender},
  shorttitle = {Early Vocabulary Growth},
  author = {Huttenlocher, Janellen and Haight, Wendy and Bryk, Anthony and Seltzer, Michael and Lyons, Thomas},
  year = {1991},
  journal = {Developmental Psychology},
  volume = {27},
  pages = {236--248},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-0599},
  doi = {10.1037/0012-1649.27.2.236},
  abstract = {Examines the role of exposure to speech in children's early vocabulary growth. It is generally assumed that individual differences in vocabulary depend, in large part, on variations in learning capacity. However, variations in exposure have not been systematically explored. In this study vocabulary growth rates are characterized for each of 22 children by using data obtained at several time points from 14 to 26 mo. A substantial relation between individual differences in vocabulary acquisition and variations in the amount that particular mothers speak to their children was found. It is argued that the relation between amount of parent speech and vocabulary growth reflects parent effects on the child, rather than child-ability effects on the parent or hereditary factors. It was also found that gender is an important factor in rate of vocabulary growth. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Human Sex Differences,Interpersonal Communication,Language Development,Parents,Vocabulary},
  file = {/Users/eec35/Zotero/storage/A7QZV495/doiLanding.html}
}

@article{huttenlocher2002,
  title = {Language Input and Child Syntax},
  author = {Huttenlocher, Janellen and Vasilyeva, Marina and Cymerman, Elina and Levine, Susan},
  year = {2002},
  month = nov,
  journal = {Cognitive Psychology},
  volume = {45},
  number = {3},
  pages = {337--374},
  issn = {0010-0285},
  doi = {10.1016/s0010-0285(02)00500-5},
  abstract = {Existing work on the acquisition of syntax has been concerned mainly with the early stages of syntactic development. In the present study we examine later syntactic development in children. Also, existing work has focused on commonalities in the emergence of syntax. Here we explore individual differences among children and their relation to variations in language input. In Study 1 we find substantial individual differences in children's mastery of multiclause sentences and a significant relation between those differences and the proportion of multiclause sentences in parent speech. We also find individual differences in the number of noun phrases in children's utterances and a significant relation between those differences and the number of noun phrases in parent speech. In Study 2 we find greater syntactic growth over a year of preschool in classes where teachers' speech is more syntactically complex. The implications of our findings for the understanding of the sources of syntactic development are discussed.},
  langid = {english},
  pmid = {12480478},
  keywords = {Child Language,{Child, Preschool},Female,Humans,Interpersonal Relations,Male,Multivariate Analysis,Observation,Regression Analysis,Social Environment,Socioeconomic Factors}
}

@article{huttenlocher2010,
  title = {Sources of Variability in Children's Language Growth},
  author = {Huttenlocher, Janellen and Waterfall, Heidi and Vasilyeva, Marina and Vevea, Jack and Hedges, Larry V.},
  year = {2010},
  month = dec,
  journal = {Cognitive Psychology},
  volume = {61},
  number = {4},
  pages = {343--365},
  issn = {1095-5623},
  doi = {10.1016/j.cogpsych.2010.08.002},
  abstract = {The present longitudinal study examines the role of caregiver speech in language development, especially syntactic development, using 47 parent-child pairs of diverse SES background from 14 to 46 months. We assess the diversity (variety) of words and syntactic structures produced by caregivers and children. We use lagged correlations to examine language growth and its relation to caregiver speech. Results show substantial individual differences among children, and indicate that diversity of earlier caregiver speech significantly predicts corresponding diversity in later child speech. For vocabulary, earlier child speech also predicts later caregiver speech, suggesting mutual influence. However, for syntax, earlier child speech does not significantly predict later caregiver speech, suggesting a causal flow from caregiver to child. Finally, demographic factors, notably SES, are related to language growth, and are, at least partially, mediated by differences in caregiver speech, showing the pervasive influence of caregiver speech on language growth.},
  langid = {english},
  pmcid = {PMC2981670},
  pmid = {20832781},
  keywords = {Caregivers,{Child, Preschool},{Critical Period, Psychological},Female,Humans,Infant,Language Development,Longitudinal Studies,Male,Speech,Vocabulary},
  file = {/Users/eec35/Zotero/storage/8TIT4ZRN/Huttenlocher et al. - 2010 - Sources of variability in children's language grow.pdf}
}

@article{jara-ettinger2021,
  title = {The Social Basis of Referential Communication: {{Speakers}} Construct Physical Reference Based on Listeners' Expected Visual Search},
  shorttitle = {The Social Basis of Referential Communication},
  author = {{Jara-Ettinger}, Julian and {Rubio-Fernandez}, Paula},
  year = {2021},
  journal = {Psychological Review},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/rev0000345},
  abstract = {A foundational assumption of human communication is that speakers should say as much as necessary, but no more. Yet, people routinely produce redundant adjectives and their propensity to do so varies cross-linguistically. Here, we propose a computational theory, whereby speakers create referential expressions designed to facilitate listeners' reference resolution, as they process words in real time. We present a computational model of our account, the Incremental Collaborative Efficiency (ICE) model, which generates referential expressions by considering listeners' real-time incremental processing and reference identification. We apply the ICE framework to physical reference, showing that listeners construct expressions designed to minimize listeners' expected visual search effort during online language processing. Our model captures a number of known effects in the literature, including cross-linguistic differences in speakers' propensity to over-specify. Moreover, the ICE model predicts graded acceptability judgments with quantitative accuracy, systematically outperforming an alternative, brevity-based model. Our findings suggest that physical reference production is best understood as driven by a collaborative goal to help the listener identify the intended referent, rather than by an egocentric effort to minimize utterance length. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Audiences,Communication,Computational Modeling,Pragmatics,Social Cognition,Visual Search},
  file = {/Users/eec35/Zotero/storage/VY84QYHX/2022-16904-001.html}
}

@article{kekelis1984,
  title = {Family {{Communication Styles}} and {{Language Development}}},
  author = {Kekelis, Linda S. and Andersen, Elaine S.},
  year = {1984},
  month = feb,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {78},
  number = {2},
  pages = {54--65},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X8407800202},
  urldate = {2021-06-21},
  abstract = {This study examines the effects of visual impairment on parent/child interaction. Six children (aged 1 to 3 years) with varying degrees of vision were video-recorded in naturalistic interactions with their families. Results indicate that caregivers of the blind provide highly directive input, offer relatively few descriptions, and initiate a greater proportion of topics than their children, focusing almost exclusively on child-centered topics. The special needs of blind children (e.g., for locomotor stimulation) as well as the absence of visual cues from and to the child motivate many of these modifications. We propose alternative ways for families to engage in satisfying interactions with their blind children.},
  langid = {english}
}

@book{kimball1975,
  title = {{Syntax and semantics}},
  author = {Kimball, John P. and Morgan, Jerry L. and Cole, Peter},
  year = {1975},
  publisher = {{Academic press, Harcourt Brace Jovanovich}},
  address = {{New York San Francisco London}},
  isbn = {978-0-12-785423-6},
  langid = {xxx},
  lccn = {80},
  file = {/Users/eec35/Zotero/storage/5UDQ4UQI/Grice-Logic.pdf}
}

@article{kramer1975,
  title = {Infants' {{Development}} of {{Object Permanence}}: {{A Refined Methodology}} and {{New Evidence}} for {{Piaget}}'s {{Hypothesized Ordinality}}},
  shorttitle = {Infants' {{Development}} of {{Object Permanence}}},
  author = {Kramer, Judith A. and Hill, Kennedy T. and Cohen, Leslie B.},
  year = {1975},
  journal = {Child Development},
  volume = {46},
  number = {1},
  eprint = {1128843},
  eprinttype = {jstor},
  pages = {149--155},
  publisher = {{[Wiley, Society for Research in Child Development]}},
  issn = {0009-3920},
  doi = {10.2307/1128843},
  urldate = {2023-05-04},
  abstract = {To investigate Piaget's theory of object concept development, a series of 6 tasks was administered in a combined longitudinal/cross-sectional design incorporating a number of methodological controls. The tasks spanned the entire sensorimotor period and included single versus sequential displacements combined with visible or invisible hidings. 36 infants from 5 to 32 months of age at initial testing were drawn equally from day-care and home settings. All infants received the 6 tasks during each of 3 testing sessions over a 6-month period. Clear evidence was obtained for task ordinality as proposed by Piaget, with ordinality coefficients ranging from .71 to .82 for the 3 testing sessions. Performance changes across the 3 sessions were also ordinal in 80\% of the cases. Expected age, task, and session effects and accompanying interactions were also obtained.},
  file = {/Users/eec35/Zotero/storage/X4WSRMMM/Kramer et al. - 1975 - Infants' Development of Object Permanence A Refin.pdf}
}

@book{landau1985,
  title = {Language and Experience:  {{Evidence}} from the Blind Child},
  shorttitle = {Language and Experience},
  author = {Landau, Barbara and Gleitman, Lila R.},
  year = {1985},
  series = {Language and Experience:  {{Evidence}} from the Blind Child},
  pages = {xi, 250},
  publisher = {{Harvard University Press}},
  address = {{Cambridge, MA, US}},
  abstract = {We ask in this book how children learn which of the words in their language encode which of the meanings. We accept as self-evident that any explanation of this learning must take nonlinguistic experience as relevant: When children hear words spoken by adults, they also observe objects, scenes, and events. Yet the issues here are quite perplexing because, at least to first inspection, heard words seem to map only very inexactly onto the child's observations of objects, scenes, and events.  In light of such difficulties, we tried to get some insight into how the child constructs the right mappings between words and the world by examining a situation in which the opportunities to observe the world are diminished: the case of langauge learning by congenitally blind children.  There is an evidently unshakable tradition which asserts that the blind must in principle be defective in their learning\textemdash of language, of space, and more.  We shall document that these a priori opinions cannot survive confrontation with the reality of language learning in congenitally blind children. Blind learners not only learn the forms of language but their meanings as well; their speech cannot be characterized as replete with "verbalisms" (the clinical term for blind learners' putative use of certain words as "sound without meaning"). (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-674-51025-8},
  keywords = {Blind,Congenital Disorders,Language Development},
  file = {/Users/eec35/Zotero/storage/LXWYNHJ8/1985-97756-000.html}
}

@misc{lavechin2021,
  title = {An Open-Source Voice Type Classifier for Child-Centered Daylong Recordings},
  author = {Lavechin, Marvin and Bousbib, Ruben and Bredin, Herv{\'e} and Dupoux, Emmanuel and Cristia, Alejandrina},
  year = {2021},
  month = jan,
  number = {arXiv:2005.12656},
  eprint = {2005.12656},
  primaryclass = {eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2005.12656},
  urldate = {2023-01-02},
  abstract = {Spontaneous conversations in real-world settings such as those found in child-centered recordings have been shown to be amongst the most challenging audio files to process. Nevertheless, building speech processing models handling such a wide variety of conditions would be particularly useful for language acquisition studies in which researchers are interested in the quantity and quality of the speech that children hear and produce, as well as for early diagnosis and measuring effects of remediation. In this paper, we present our approach to designing an open-source neural network to classify audio segments into vocalizations produced by the child wearing the recording device, vocalizations produced by other children, adult male speech, and adult female speech. To this end, we gathered diverse child-centered corpora which sums up to a total of 260 hours of recordings and covers 10 languages. Our model can be used as input for downstream tasks such as estimating the number of words produced by adult speakers, or the number of linguistic units produced by children. Our architecture combines SincNet filters with a stack of recurrent layers and outperforms by a large margin the state-of-the-art system, the Language ENvironment Analysis (LENA) that has been used in numerous child language studies.},
  archiveprefix = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing,I.2.7},
  file = {/Users/eec35/Zotero/storage/IVBY8CAF/Lavechin et al. - 2021 - An open-source voice type classifier for child-cen.pdf;/Users/eec35/Zotero/storage/IXTBIKCH/2005.html}
}

@article{lehet2021,
  title = {Circumspection in Using Automated Measures: {{Talker}} Gender and Addressee Affect Error Rates for Adult Speech Detection in the {{Language ENvironment Analysis}} ({{LENA}}) System},
  author = {Lehet, Matthew and Arjmandi, Meisam K. and Houston, Derek and Dilley, Laura},
  year = {2021},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {1},
  pages = {113--138},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01419-y},
  abstract = {Automatic speech processing devices have become popular for quantifying amounts of ambient language input to children in their home environments. We assessed error rates for language input estimates for the Language ENvironment Analysis (LENA) audio processing system, asking whether error rates differed as a function of adult talkers' gender and whether they were speaking to children or adults. Audio was sampled from within LENA recordings from 23 families with children aged 4\textendash 34 months. Human coders identified vocalizations by adults and children, counted intelligible words, and determined whether adults' speech was addressed to children or adults. LENA's classification accuracy was assessed by parceling audio into 100-ms frames and comparing, for each frame, human and LENA classifications. LENA correctly classified adult speech 67\% of the time across families (average false negative rate: 33\%). LENA's adult word count showed a mean +47\% error relative to human counts. Classification and Adult Word Count error rates were significantly affected by talkers' gender and whether speech was addressed to a child or an adult. The largest systematic errors occurred when adult females addressed children. Results show LENA's classifications and Adult Word Count entailed random \textendash{} and sometimes large \textendash{} errors across recordings, as well as systematic errors as a function of talker gender and addressee. Due to systematic and sometimes high error in estimates of amount of adult language input, relying on this metric alone may lead to invalid clinical and/or research conclusions. Further validation studies and circumspect usage of LENA are warranted.}
}

@article{loots2003,
  title = {The {{Interaction}} between {{Mothers}} and Their {{Visually Impaired Infants}}: {{An Intersubjective Developmental Perspective}}},
  shorttitle = {The {{Interaction}} between {{Mothers}} and Their {{Visually Impaired Infants}}},
  author = {Loots, Gerrit and Devise, Isabel and Sermijn, Jasmina},
  year = {2003},
  month = jul,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {97},
  number = {7},
  pages = {403--417},
  issn = {0145-482X, 1559-1476},
  doi = {10.1177/0145482X0309700703},
  urldate = {2023-01-25},
  abstract = {In this article, an intersubjective developmental theory that focuses primarily on the development of the interworld between the caregiver and the infant is used to integrate and interpret the seemingly incoherent and contradictory research findings on the interactions between mothers and their infants with visual impairments. The implications for further research and early intervention practices are presented.},
  langid = {english}
}

@article{lucariello1987,
  title = {Remembering and Planning Talk between Mothers and Children},
  author = {Lucariello, Joan and Nelson, Katherine},
  year = {1987},
  month = jul,
  journal = {Discourse Processes},
  volume = {10},
  number = {3},
  pages = {219--235},
  publisher = {{Routledge}},
  issn = {0163-853X},
  doi = {10.1080/01638538709544673},
  urldate = {2023-05-04},
  abstract = {Three aspects of temporally displaced (TD) talk between mothers and children were explored: the role of the knowledge base in such talk, the effect of mother talk on child talk, and the impact of such talk on the child's knowledge base. Mother-child (2-year-old) speech was observed in three contexts: (a) routine or scripted; (b) free play; and (c) novel play. Such talk occurred almost exclusively in the scripted context and its topics were predominantly based on other routine activities in which the dyad was not presently engaged. These results point to the strong influence of the knowledge base in terms of event schemas (representations of routine activities) in supporting TD talk. Maternal talk was characterized by the use of adverbial temporal markers, hypothetical and conditional expressions, conversational routines, and Wh- questions. These aspects of maternal speech indicate ``scaffolding'' and may facilitate the child's acquisition of the appropriate form, content, and organization of TD talk. Analyses of the relation between TD talk and child knowledge indicated that for past events, maternal speech can mediate information and experience and thereby contribute to and transform the child's world knowledge.}
}

@article{lucca2018,
  title = {Communicating to {{Learn}}: {{Infants}}' {{Pointing Gestures Result}} in {{Optimal Learning}}},
  shorttitle = {Communicating to {{Learn}}},
  author = {Lucca, Kelsey and Wilbourn, Makeba Parramore},
  year = {2018},
  month = may,
  journal = {Child Development},
  volume = {89},
  number = {3},
  pages = {941--960},
  issn = {1467-8624},
  doi = {10.1111/cdev.12707},
  abstract = {Infants' pointing gestures are a critical predictor of early vocabulary size. However, it remains unknown precisely how pointing relates to word learning. The current study addressed this question in a sample of 108 infants, testing one mechanism by which infants' pointing may influence their learning. In Study 1, 18-month-olds, but not 12-month-olds, more readily mapped labels to objects if they had first pointed toward those objects than if they had referenced those objects via other communicative behaviors, such as reaching or gaze alternations. In Study 2, when an experimenter labeled a not pointed-to-object, 18-month-olds' pointing was no longer related to enhanced fast mapping. These findings suggest that infants' pointing gestures reflect a readiness and, potentially, a desire to learn.},
  langid = {english},
  pmid = {28032638},
  keywords = {Age Factors,Child Development,Female,Gestures,Humans,Infant,Infant Behavior,Learning,Male},
  file = {/Users/eec35/Zotero/storage/5NUAS5HN/Lucca and Wilbourn - 2018 - Communicating to Learn Infants' Pointing Gestures.pdf}
}

@techreport{luchkina2020,
  type = {Preprint},
  title = {Sixteen-Month-Olds Comprehend Unanchored Absent Reference},
  author = {Luchkina, Elena and Xu, Fei and Sobel, David and Morgan, James},
  year = {2020},
  month = feb,
  institution = {{Open Science Framework}},
  doi = {10.31219/osf.io/5tc6d},
  urldate = {2023-05-04},
  abstract = {A nascent understanding of absent reference emerges around 12 months: provided with rich contextual support, infants look and point to the location of a displaced object. When can infants understand absent reference without contextual support? Using a procedure modified from Hendrickson and Sundara (2017), 13- and 16-montholds first listened to utterances containing familiar target words, while viewing a checkerboard. Then, two objects \textendash{} a referent and a distractor (e.g., a cup and a shoe) \textendash{} appeared on the screen. Only 16-month-olds demonstrated a reliable looking preference for the referents, suggesting that listening to the utterances activated their mental images of the referents. These results establish that at 16 months, infants comprehend reference to absent entities without any contextual support.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/FYVUE644/Luchkina et al. - 2020 - Sixteen-month-olds comprehend unanchored absent re.pdf}
}

@article{lynott2020,
  title = {The {{Lancaster Sensorimotor Norms}}: Multidimensional Measures of Perceptual and Action Strength for 40,000 {{English}} Words},
  shorttitle = {The {{Lancaster Sensorimotor Norms}}},
  author = {Lynott, Dermot and Connell, Louise and Brysbaert, Marc and Brand, James and Carney, James},
  year = {2020},
  month = jun,
  journal = {Behavior Research Methods},
  volume = {52},
  number = {3},
  pages = {1271--1291},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01316-z},
  abstract = {Sensorimotor information plays a fundamental role in cognition. However, the existing materials that measure the sensorimotor basis of word meanings and concepts have been restricted in terms of their sample size and breadth of sensorimotor experience. Here we present norms of sensorimotor strength for 39,707 concepts across six perceptual modalities (touch, hearing, smell, taste, vision, and interoception) and five action effectors (mouth/throat, hand/arm, foot/leg, head excluding mouth/throat, and torso), gathered from a total of 3,500 individual participants using Amazon's Mechanical Turk platform. The Lancaster Sensorimotor Norms are unique and innovative in a number of respects: They represent the largest-ever set of semantic norms for English, at 40,000 words \texttimes{} 11 dimensions (plus several informative cross-dimensional variables), they extend perceptual strength norming to the new modality of interoception, and they include the first norming of action strength across separate bodily effectors. In the first study, we describe the data collection procedures, provide summary descriptives of the dataset, and interpret the relations observed between sensorimotor dimensions. We then report two further studies, in which we (1) extracted an optimal single-variable composite of the 11-dimension sensorimotor profile (Minkowski 3 strength) and (2) demonstrated the utility of both perceptual and action strength in facilitating lexical decision times and accuracy in two separate datasets. These norms provide a valuable resource to researchers in diverse areas, including psycholinguistics, grounded cognition, cognitive semantics, knowledge representation, machine learning, and big-data approaches to the analysis of language and conceptual representations. The data are accessible via the Open Science Framework (http://osf.io/7emr6/) and an interactive web application (https://www.lancaster.ac.uk/psychology/lsnorms/).},
  langid = {english},
  pmcid = {PMC7280349},
  pmid = {31832879},
  file = {/Users/eec35/Zotero/storage/DH522T4K/Lynott et al. - 2020 - The Lancaster Sensorimotor Norms multidimensional.pdf}
}

@article{macleod2023,
  title = {Transmitting White Monolingual {{Anglo-American}} Norms: {{A}} Concept Analysis of ``Quality of Language'' in Parent-Child Interactions},
  shorttitle = {Transmitting White Monolingual {{Anglo-American}} Norms},
  author = {MacLeod, Andrea A.N. and Demers, Catrine},
  year = {2023},
  month = mar,
  journal = {Applied Psycholinguistics},
  pages = {1--29},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S014271642300005X},
  urldate = {2023-04-04},
  abstract = {White monolingual Anglo-American values permeate language acquisition research, which extends into public health and educational policies. ``Quality of language'' in parent-child interactions is often called upon to explain weaknesses in the language development of children who are racialized, experiencing poverty, or bilingual. Indeed, many early intervention approaches build on this premise by aiming to improve the ``quality of language'' used by parents. We aimed to understand the conceptualizations of ``quality of language'' in studies of parent-child interaction through the critical lens of Community Cultural Wealth Theory and perspectives from development research across cultures. We completed a Systematic Concept Analysis of articles published from 2010 to 2022 and focused on parent-child interactions in the home environment. Our search identified 972 articles and 78 met the inclusion criteria, but only 45 papers provided a definition. These definitions covered eight conceptualizations but only three were previously described. We also found inequity in the use of this terminology, which focused on children who were bilingual, had disability, or experiencing poverty. Informed by a critical lens, we recommend the use of four new terms to encompass ``quality of language.'' We also recommend refraining from using this term as it is value-laden, poorly defined, and diminishes culturally sustaining language transmission practices.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/VSR8RJ89/MacLeod and Demers - 2023 - Transmitting white monolingual Anglo-American norm.pdf}
}

@article{macwhinney2018,
  title = {{{CLAN Manual}}},
  author = {MacWhinney, Brian},
  year = {2018},
  publisher = {{TalkBank}},
  doi = {10.21415/T5G10R},
  urldate = {2022-08-24},
  file = {/Users/eec35/Zotero/storage/Y2BLB8ID/MacWhinney - 2018 - CLAN Manual.pdf}
}

@article{macwhinney2019,
  title = {{{CHAT Manual}}},
  author = {MacWhinney, Brian},
  year = {2019},
  publisher = {{TalkBank}},
  doi = {10.21415/3MHN-0Z89},
  urldate = {2022-08-24},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/9FZEG3ZU/2019 - CHAT Manual.pdf}
}

@article{magimairaj2022,
  title = {A {{Systematic Review}} of the {{Effects}} of {{LENA-based Feedback}} on {{Parent-Child Language Interactions}} in {{Families}} with {{Young Children}}},
  author = {Magimairaj, Beula and Nagaraj, Naveen and Caballero, Ana and Munoz, Karen and White, Karl},
  year = {2022},
  month = nov,
  journal = {Journal of Early Hearing Detection and Intervention},
  volume = {7},
  number = {3},
  pages = {47--60},
  issn = {2381-2362},
  doi = {10.26077/6c72-973b},
  file = {/Users/eec35/Zotero/storage/A5SPST8H/6.html}
}

@phdthesis{mcrae2002,
  title = {Attachment in Blind Infants : A Systematic Investigation Using {{Ainsworth}}'s {{Strange Situation}}.},
  author = {McRae, Kelly Anne},
  year = {2002},
  address = {{Toronto, Canada}},
  urldate = {2023-04-19},
  abstract = {The purpose of this study was to examine the quality of attachment that exists between blind infants and their mothers. The sample included 16 mothers and blind infants who were videotaped in the Ainsworth Strange Situation, a standardized measure of infant-mother attachment. The mothers also participated in a semi-structured interview designed to provide information regarding the infants' behaviour at home and in the community, amidst both familiar and unfamiliar people. The data were analyzed by comparing the results of the Strange Situation Procedure to normative data and also by using a Muhiple-Case Analysis of other descriptive information. This study showed that the infants who were partially sighted (yet still legally blind) generally behaved in a similar manner to sighted children with respect to their attachment behaviour at home, in the community and during the Ainsworth Strange Situation. The attachment behaviour of infants who were totally blind, however, generally differed from that of sighted children in the Ainsworth Strange Situation, as well in home and community contexts. Infants who were totally blind from birth were more often classified as insecurely attached, Category A, (80\%), as compared to normative samples (22\%). A rationale based on Culture theory, is developed to explain why the totally blind infants react differently from children with some sight. Lastly, limitations on the applicability of the Attachment Theory and Ainsworth's Strange Situation procedure when used on totally blind children were identified.},
  langid = {english},
  school = {University of Toronto},
  annotation = {Last Modified: 2022-09-01},
  file = {/Users/eec35/Zotero/storage/DX23GC8K/item.html}
}

@article{montag2018,
  title = {Quantity and {{Diversity}}: {{Simulating Early Word Learning Environments}}},
  shorttitle = {Quantity and {{Diversity}}},
  author = {Montag, Jessica L. and Jones, Michael N. and Smith, Linda B.},
  year = {2018},
  month = may,
  journal = {Cognitive Science},
  volume = {42 Suppl 2},
  number = {Suppl 2},
  pages = {375--412},
  issn = {1551-6709},
  doi = {10.1111/cogs.12592},
  abstract = {The words in children's language learning environments are strongly predictive of cognitive development and school achievement. But how do we measure language environments and do so at the scale of the many words that children hear day in, day out? The quantity and quality of words in a child's input are typically measured in terms of total amount of talk and the lexical diversity in that talk. There are disagreements in the literature whether amount or diversity is the more critical measure of the input. Here we analyze the properties of a large corpus (6.5~million words) of speech to children and simulate learning environments that differ in amount of talk per unit time, lexical diversity, and the contexts of talk. The central conclusion is that what researchers need to theoretically understand, measure, and change is not the total amount of words, or the diversity of words, but the function that relates total words to the diversity of words, and how that function changes across different contexts of talk.},
  langid = {english},
  pmcid = {PMC5980672},
  pmid = {29411899},
  keywords = {Child Language,Child-directed speech,{Child, Preschool},Computer simulation,Computer Simulation,Female,Humans,Individual differences,Individuality,Language development,Language Development,Linguistic quantity and quality,Male,Speech,Verbal Learning,Vocabulary},
  file = {/Users/eec35/Zotero/storage/XDZ2DUTC/Montag et al. - 2018 - Quantity and Diversity Simulating Early Word Lear.pdf}
}

@article{moore1994a,
  ids = {moore1994},
  title = {Communication between Blind and Severely Visually Impaired Children and Their Parents},
  author = {Moore, Vanessa and McConachie, Helen},
  year = {1994},
  journal = {British Journal of Developmental Psychology},
  volume = {12},
  number = {4},
  pages = {491--502},
  issn = {2044-835X},
  doi = {10.1111/j.2044-835X.1994.tb00650.x},
  urldate = {2023-05-04},
  abstract = {This study examines communications directed to young visually impaired children by their parents. Eight totally blind children and eight children whose vision was severely impaired were visited at home at around 18 months of age and video-recordings were made of each child interacting with a familiar caretaker. It was found that the parents of blind children were more likely to initiate interactions themselves and tended to use verbal comments unaccompanied by actions more frequently. They were less likely to talk about objects which were at the child's current focus of attention and were more likely to describe the properties of objects to the child using general terms such as pronouns or general nouns. In addition, they tended to request verbal information from their children in contrast to the parents of severely visually impaired children, who were more likely to describe objects for them. Children in both groups received more requests for action than any other utterance type and all parents made infrequent mention of the attributes of objects. The differences between the groups are discussed in terms of the difficulties faced particularly by parents of blind children in initiating and sustaining interactions.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/6J2I4YXN/Moore and McConachie - 1994 - Communication between blind and severely visually .pdf;/Users/eec35/Zotero/storage/FPCASS9R/j.2044-835X.1994.tb00650.html}
}

@article{muraki2022,
  title = {Quantifying Children's Sensorimotor Experience: {{Child}} Body-Object Interaction Ratings for 3359 {{English}} Words},
  shorttitle = {Quantifying Children's Sensorimotor Experience},
  author = {Muraki, Emiko J. and Siddiqui, Israa A. and Pexman, Penny M.},
  year = {2022},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {54},
  number = {6},
  pages = {2864--2877},
  issn = {1554-3528},
  doi = {10.3758/s13428-022-01798-4},
  abstract = {Body-object interaction (BOI) ratings measure how easily the human body can physically interact with a word's referent. Previous research has found that words higher in BOI tend to be processed more quickly and accurately in tasks such as lexical decision, semantic decision, and syntactic classification, suggesting that sensorimotor information is an important aspect of lexical knowledge. However, limited research has examined the importance of sensorimotor information from a developmental perspective. One barrier to addressing such theoretical questions has been a lack of semantic dimension ratings that take into account child sensorimotor experience. The goal of the current study was to collect Child BOI rating norms. Parents of children aged 5 to 9 years old were asked to rate words according to how easily an average 6-year-old child can interact with each word's referent. The relationships of Child and Adult BOI ratings with other lexical semantic dimensions were assessed, as well as the relationships of Child and Adult BOI ratings with age of acquisition. Child BOI ratings were more strongly related to valence and sensory experience ratings than Adult BOI ratings and were a better predictor of three different measures of age of acquisition. The results suggest that child-centric ratings such as those reported here provide a more sensitive measure of children's experience that can be used to address theoretical questions in embodied cognition from a developmental perspective.},
  langid = {english},
  pmid = {35112287},
  file = {/Users/eec35/Zotero/storage/2B2HT92C/Muraki et al. - 2022 - Quantifying children's sensorimotor experience Ch.pdf}
}

@article{nagayoshi2017,
  title = {Related Visual Impairment to Mother-Infant Interaction and Development in Infants with Bilateral Retinoblastoma},
  author = {Nagayoshi, Michie and Hirose, Taiko and Toju, Kyoko and Suzuki, Shigenobu and Okamitsu, Motoko and Teramoto, Taeko and Omori, Takahide and Kawamura, Aki and Takeo, Naoko},
  year = {2017},
  month = jun,
  journal = {European Journal of Oncology Nursing: The Official Journal of European Oncology Nursing Society},
  volume = {28},
  pages = {28--34},
  issn = {1532-2122},
  doi = {10.1016/j.ejon.2017.02.002},
  abstract = {PURPOSE: This study was conducted with infants diagnosed with bilateral retinoblastoma (RB) and their mothers. It explored characteristics of the mother-infant interaction, the infants' developmental characteristics and related risk factors. METHOD: Cross-sectional statistical analysis was performed with 18 dyads of one-year-old infants with bilateral RB and their mothers. RESULTS: Using the Japanese Nursing Child Assessment Teaching Scale (JNCATS) results showed that infants with RB had significantly lower scores compared to normative Japanese scores on all of the infants' subscales and "Child's contingency" (p~{$<~$}0.01). Five infants with visual impairment at high risk of developmental problems had a pass rate of 0\% on six JNCATS items. There were positive correlations between Developmental quotients (DQ) and JNCATS score of "Responsiveness to caregiver" ({$\rho~$}=~0.50, p~{$<~$}0.05) and DQ and "Child's contingency" ({$\rho~$}=~0.47, p~{$<~$}0.05). CONCLUSIONS: Infants with visual impairment were characterized by high likelihood of developmental delays and problematic behaviors; they tended not to turn their face or eyes toward their mothers, smile in response to their mothers' talking to them or the latter's changing body language or facial expressions, or react in a contingent manner in their interactions. These infant behaviors noted by their mothers shared similarities with developmental characteristics of children with visual impairments. These findings indicated a need to provide support promoting mother-infant interactions consistent with the developmental characteristics of RB infants with visual impairment.},
  langid = {english},
  pmid = {28478852},
  keywords = {Adolescent,Adult,Asian People,Child,Child Development,{Child, Preschool},Cross-Sectional Studies,Female,Humans,Infant,Infant Behavior,Japan,Male,Middle Aged,Mother-Child Relations,Mothers,Retinoblastoma,Risk Factors,Vision Disorders}
}

@article{naigles1998,
  title = {Why Are Some Verbs Learned before Other Verbs? {{Effects}} of Input Frequency and Structure on Children's Early Verb Use},
  shorttitle = {Why Are Some Verbs Learned before Other Verbs?},
  author = {Naigles, Letitia R. and {Hoff-Ginsberg}, Erika},
  year = {1998},
  month = feb,
  journal = {Journal of Child Language},
  volume = {25},
  number = {1},
  pages = {95--120},
  publisher = {{Cambridge University Press}},
  issn = {1469-7602, 0305-0009},
  doi = {10.1017/S0305000997003358},
  urldate = {2022-09-04},
  abstract = {This study investigated the extent to which the nature of verb  input  accounts for the order in which children acquire verbs. We assessed the   nature of verb input using a combined sample of the speech of 57  mothers addressing their Stage I children. We assessed the order of verb   acquisition using as our database a combined sample of those children's   speech 10 weeks later and using as our measure of order of acquisition   the frequency of verb occurrence. The first set of analyses established   the validity of this measure of acquisition order by comparing it with   order of acquisition data obtained from checklist and diary data. The  second set of analyses revealed that three properties of the input were   significant predictors of the order of acquisition of the 25 verbs that  were  the focus of this study. The predictive properties of input were the total   frequency, final position frequency, and diversity of syntactic environments   in which the verbs appeared. These findings suggest that the way  verbs appear in input influences their ease of acquisition. More specifically,   the effect of syntactic diversity in input provides support for the  syntactic bootstrapping account of how children use structural information   to learn the meaning of new verbs.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/9IW4BCI5/AD0CD2EA85B15B064306AC09EE887EAF.html}
}

@article{newman2016,
  ids = {newman2016a,newman2016b},
  title = {Input and Uptake at 7 Months Predicts Toddler Vocabulary: The Role of Child-Directed Speech and Infant Processing Skills in Language Development},
  shorttitle = {Input and Uptake at 7 Months Predicts Toddler Vocabulary},
  author = {Newman, Rochelle S. and Rowe, Meredith L. and Bernstein Ratner, Nan},
  year = {2016},
  month = sep,
  journal = {Journal of Child Language},
  volume = {43},
  number = {5},
  pages = {1158--1173},
  publisher = {{Cambridge University Press}},
  issn = {1469-7602},
  doi = {10.1017/S0305000915000446},
  abstract = {Both the input directed to the child, and the child's ability to process that input, are likely to impact the child's language acquisition. We explore how these factors inter-relate by tracking the relationships among: (a) lexical properties of maternal child-directed speech to prelinguistic (7-month-old) infants (N = 121); (b) these infants' abilities to segment lexical targets from conversational child-directed utterances in an experimental paradigm; and (c) the children's vocabulary outcomes at age 2;0. Both repetitiveness in maternal input and the child's speech segmentation skills at age 0;7 predicted language outcomes at 2;0; moreover, while these factors were somewhat inter-related, they each had independent effects on toddler vocabulary skill, and there was no interaction between the two.},
  langid = {english},
  pmid = {26300377},
  keywords = {Child,Child Language,{Child, Preschool},Communication,Comprehension,Female,Humans,Infant,Language Development,Male,Mother-Child Relations,Speech Perception,Verbal Behavior,Vocabulary},
  file = {/Users/eec35/Zotero/storage/7MVQPC6D/Newman et al. - 2016 - Input and uptake at 7 months predicts toddler voca.pdf}
}

@article{oller2010,
  ids = {oller2010a},
  title = {Automated Vocal Analysis of Naturalistic Recordings from Children with Autism, Language Delay, and Typical Development},
  author = {Oller, D. K. and Niyogi, P. and Gray, S. and Richards, J. A. and Gilkerson, J. and Xu, D. and Yapanel, U. and Warren, S. F.},
  year = {2010},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {107},
  number = {30},
  pages = {13354--13359},
  issn = {1091-6490},
  doi = {10.1073/pnas.1003882107},
  abstract = {For generations the study of vocal development and its role in language has been conducted laboriously, with human transcribers and analysts coding and taking measurements from small recorded samples. Our research illustrates a method to obtain measures of early speech development through automated analysis of massive quantities of day-long audio recordings collected naturalistically in children's homes. A primary goal is to provide insights into the development of infant control over infrastructural characteristics of speech through large-scale statistical analysis of strategically selected acoustic parameters. In pursuit of this goal we have discovered that the first automated approach we implemented is not only able to track children's development on acoustic parameters known to play key roles in speech, but also is able to differentiate vocalizations from typically developing children and children with autism or language delay. The method is totally automated, with no human intervention, allowing efficient sampling and analysis at unprecedented scales. The work shows the potential to fundamentally enhance research in vocal development and to add a fully objective measure to the battery used to detect speech-related disorders in early childhood. Thus, automated analysis should soon be able to contribute to screening and diagnosis procedures for early disorders, and more generally, the findings suggest fundamental methods for the study of language in natural environments.},
  langid = {english},
  pmcid = {PMC2922144},
  pmid = {20643944},
  keywords = {Autistic Disorder,{Child, Preschool},Female,Humans,Infant,Language Development,Language Development Disorders,Linear Models,Male,Multivariate Analysis,Speech Disorders,Speech Production Measurement}
}

@article{osina2013,
  title = {When Familiar Is Not Better: 12-Month-Old Infants Respond to Talk about Absent Objects},
  shorttitle = {When Familiar Is Not Better},
  author = {Osina, Maria A. and Saylor, Megan M. and Ganea, Patricia A.},
  year = {2013},
  journal = {Developmental Psychology},
  volume = {49},
  pages = {138--145},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-0599},
  doi = {10.1037/a0027903},
  abstract = {Three experiments that demonstrate a novel constraint on infants' language skills are described. Across the experiments it is shown that as babies near their 1st birthday, their ability to respond to talk about an absent object is influenced by a referent's spatiotemporal history: familiarizing infants with an object in 1 or several nontest locations before the study interferes with their ability to respond to talk about the object when it is out of view. Familiarity with an object may not always strengthen infants' object representations and therefore facilitate their ability to appropriately react to the mention of absent objects. On the contrary, early in development, irrelevant information about prior location may be bound to representations of familiar objects and thus interfere with infants' ability to respond to talk about absent things. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Contextual Associations,Conversation,Familiarity,Infant Development,Language Development,Memory},
  file = {/Users/eec35/Zotero/storage/WA3T2SWP/2012-07968-001.html}
}

@article{ostarek2019,
  title = {Sighted People's Language Is Not Helpful for Blind Individuals' Acquisition of Typical Animal Colors},
  author = {Ostarek, Markus and van Paridon, Jeroen and {Montero-Melis}, Guillermo},
  year = {2019},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {44},
  pages = {21972--21973},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1912302116},
  urldate = {2021-02-06},
  abstract = {How do you learn what things look like if you cannot see? Kim et al. (1) tackle this intriguing question by assessing knowledge about animal appearance in blind and sighted individuals. The authors evaluated 2 plausible hypotheses: The learn-from-description hypothesis that blind individuals learn directly from sighted people's descriptions (e.g., ``elephants are gray'') and the learn-from-kind hypothesis that blind people infer visual animal properties from knowledge they have about the animal's taxonomic class (e.g., a crow is a bird and birds have feathers). While group differences were observed for all visual properties, blindness had the largest effect on color knowledge: Only sighted participants consistently grouped animals with the same canonical color together. This striking difference between blind and sighted participants \ldots{}  [{$\carriagereturn$}][1]1To whom correspondence may be addressed. Email: markus.ostarek\{at\}mpi.nl.  [1]: \#xref-corresp-1-1},
  chapter = {Letter},
  copyright = {\textcopyright{} 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  langid = {english},
  pmid = {31615880},
  file = {/Users/eec35/Zotero/storage/F8PWMVR3/Ostarek et al. - 2019 - Sighted people’s language is not helpful for blind.pdf;/Users/eec35/Zotero/storage/796DGIEI/21972.html}
}

@article{pancsofar2006,
  title = {Mother and Father Language Input to Young Children: {{Contributions}} to Later Language Development},
  shorttitle = {Mother and Father Language Input to Young Children},
  author = {Pancsofar, Nadya and {Vernon-Feagans}, Lynne},
  year = {2006},
  month = nov,
  journal = {Journal of Applied Developmental Psychology},
  volume = {27},
  number = {6},
  pages = {571--587},
  issn = {0193-3973},
  doi = {10.1016/j.appdev.2006.08.003},
  urldate = {2023-05-04},
  abstract = {There has been little research comparing the nature and contributions of language input of mothers and fathers to their young children. This study examined differences in mother and father talk to their 24~month-old children. This study also considered contributions of parent education, child care quality and mother and father language (output, vocabulary, complexity, questions, and pragmatics) to children's expressive language development at 36~months. It was found that fathers' language input was less than mothers' language input on the following: verbal output, turn length, different word roots, and wh-questions. Mothers and fathers did not differ on type-token ratio, mean length of utterance, or the proportion of questions. At age 36~months, parent level of education, the total quality of child care and paternal different words were significant predictors of child language. Mothers' language was not a significant predictor of child language.},
  langid = {english},
  keywords = {Child care,Child language development,Father language input,Mother language input},
  file = {/Users/eec35/Zotero/storage/A2ETFB46/Pancsofar and Vernon-Feagans - 2006 - Mother and father language input to young children.pdf;/Users/eec35/Zotero/storage/LXKUD5X8/S0193397306000980.html}
}

@book{perez-pereira1999,
  title = {Language {{Development}} and {{Social Interaction}} in {{Blind Children}}},
  author = {{Perez-Pereira}, Miguel and {Conti-Ramsden}, Gina},
  year = {1999},
  month = sep,
  publisher = {{Psychology Press}},
  address = {{London}},
  doi = {10.4324/9780203776087},
  abstract = {This book provides an up-to-date account of blind children's developing communicative abilities with particular emphasis on social cognition and language acquisition from infancy to early school age. It purports to foster dialogue between those interested in the study of typically developing children and those interested in the development of children who are blind and to provide insights and new explanations of why the development of blind children may differ from that of sighted children. The book also aims to identify and examine current theoretical issues which are likely to be at the centre of developments in the fields of child language and developmental psychology.Language Development and Social Interaction in Blind Children is also a timely book. The study of blind children's development constitutes a unique opportunity to study the effect of vision on development, and more specifically on the development of language and certain aspects of social cognition. Current interest in the development of "theory of mind" and perspective taking in language learning, make the case of blind children crucial to our understanding of certain aspects of psychological functioning. The book explores these issues, challenges some widely-held beliefs about the development of communication in blind children, and provides a cohesive picture of our knowledge to date.},
  isbn = {978-0-203-77608-7}
}

@article{perez-pereira2001,
  title = {The Use of {{Directives}} in {{Verbal Interactions}} between {{Blind Children}} and Their {{Mothers}}},
  author = {{P{\'e}rez-Pereira}, Miguel and {Conti-Ramsden}, Gina},
  year = {2001},
  month = mar,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {95},
  number = {3},
  pages = {133--149},
  doi = {10.1177/0145482x0109500302},
  abstract = {Verbal interactions between three mothers and their young blind children, with special attention to the use of maternal directives, were examined. It was found that a simple analysis of maternal di...},
  annotation = {MAG ID: 68408239}
}

@book{pisani2021,
  title = {Long-Form Recordings: {{From A}} to {{Z}}},
  shorttitle = {Long-Form Recordings},
  author = {Pisani, Sara and Gautheron, Lucas and Cristia, Alejandrina},
  year = {2021},
  urldate = {2023-05-03},
  abstract = {This bookdown contains the scripts of instructional videos created in the context of the ExELang Project (exelang.fr).},
  file = {/Users/eec35/Zotero/storage/IC2J2X2F/exelang-book.html}
}

@article{preisler1991,
  ids = {preisler1991a},
  title = {Early Patterns of Interaction between Blind Infants and Their Sighted Mothers},
  author = {Preisler, Gunilla M.},
  year = {1991},
  journal = {Child: Care, Health and Development},
  volume = {17},
  number = {2},
  pages = {65--90},
  issn = {1365-2214},
  doi = {10.1111/j.1365-2214.1991.tb00680.x},
  urldate = {2022-09-15},
  abstract = {In a longitudinal, descriptive study of blind infant\textemdash sighted mother interaction during the age period 3 to 12 months, 10 infants, seven blind and three severely visually impaired, were video-recorded in natural interactional settings with their parents. The objective was to describe which communicative expressions the infants, as well as their mothers use in interaction and how they respond to each others'communications. Detailed analyses of the infants'and mothers'communicative behaviours were carried out. The blind infants exhibited a variety of communicative expressions in interaction with their mothers; they took an active part in proto-conversations and dialogues with their mothers. The blind infants had difficulties in sharing their opinions about objects with their mothers during the age period studied. Comparisons between the blind and the severely visually impaired infants showed that even very low vision improves the infant's opportunities to take part in interpersonal communication and to share meanings. The results are discussed in relation to Trevarthen's view of the infant having an innate motive for intersubjectivity \textemdash{} for communication \textemdash{} and Stern's theory of the development of the self.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/9ZGT7WMH/j.1365-2214.1991.tb00680.html}
}

@article{preisler1995,
  title = {The Development of Communication in Blind and in Deaf Infants--Similarities and Differences},
  author = {Preisler, G. M.},
  year = {1995},
  month = mar,
  journal = {Child: Care, Health and Development},
  volume = {21},
  number = {2},
  pages = {79--110},
  issn = {0305-1862},
  doi = {10.1111/j.1365-2214.1995.tb00412.x},
  abstract = {Results from two longitudinal studies of blind infant--sighted mother and of deaf infant-hearing mother/deaf mother interaction, are summarized in this paper. The aim is to shed light on the role of visual and auditory stimulation in the development of communication. Video-recorded interactions taken during infancy were transcribed in a systematic, objective and detailed way. The development of communication is described with a focus on pre-verbal abilities, exploration of toys, social and symbolic play, communicative intent and sharing of experiences. The results show a delay in the development of communication in the blind infants compared with the deaf infants, indicating a more critical role of visual stimulation compared with auditory stimulation during the infancy period to this development.},
  langid = {english},
  pmid = {7781155},
  keywords = {Blindness,Child,{Child, Preschool},Communication,Deafness,{Early Intervention, Educational},Exploratory Behavior,Female,Humans,Infant,Language Development,Longitudinal Studies,Male,Mother-Child Relations,Motor Skills,Personality Development,Play and Playthings,Psychomotor Performance,Sign Language,Social Environment}
}

@article{richards1987,
  title = {Type/{{Token Ratios}}: What Do They Really Tell Us?},
  author = {Richards, B.},
  year = {1987},
  journal = {Journal of Child Language},
  volume = {14},
  number = {2},
  pages = {201},
  doi = {doi:10.1017/s0305000900012885},
  abstract = {Type/Token Ratios have been extensively used in child language research as an index of lexical diversity. This paper shows that the measure has frequently failed to discriminate between children at widely different stages of language development, and that the ratio may in fact fall as children get older. It is suggested here that such effects are caused by a negative, though non-linear, relationship between sample size (i.e. number of tokens) and Type/Token Ratio. Effects of open and closed class items are considered and an alternative Verbal Diversity measure is examined. Standardization of the number of tokens before computing Type/Token Ratios is recommended.}
}

@techreport{richards2009,
  title = {The {{LENA Automatic Vocalization Assessment}}},
  author = {Richards, Jeffrey A. and Gilkerson, Jill and Paul, Terrance and Xu, Dongxin},
  year = {2009},
  pages = {1--20},
  address = {{Boulder, CO}},
  institution = {{The LENA Foundation}},
  urldate = {2023-04-04},
  abstract = {This report describes the development of the LENA Foundation's automatic vocalization assessment (AVATM) software. AVA software is designed to provide both parents and professionals with automatically generated information about the expressive language development of children ages 2 months to 48 months. Expressive language estimates are produced based on 12- to 16-hour audio recordings collected in the natural home environment using the LENA language environment analysis system. AVA software uses automatic speech recognition technology to categorize and quantify the sounds in child vocalizations (e.g., protophones and phonemes). These quantitative acoustic information data (expressed as ``phone'' and ``biphone'' frequencies) are reduced to principal components which are applied as input for age-based multiple linear regression models. The AVA software utilizes these regression models to generate information about expressive language development as standard scores, developmental age estimates, and estimated mean length of utterance (EMLU). AVA expressive language estimates demonstrate statistical reliability and validity comparable to standard expressive language assessments commonly administered by speech language pathologists.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/8Y2RR6IA/LTR-08-1_Automatic_Vocalization_Assessment.pdf}
}

@article{richards2017a,
  ids = {richards2017},
  title = {Automated {{Assessment}} of {{Child Vocalization Development Using LENA}}},
  author = {Richards, Jeffrey A. and Xu, Dongxin and Gilkerson, Jill and Yapanel, Umit and Gray, Sharmistha and Paul, Terrance},
  year = {2017},
  month = jul,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {60},
  number = {7},
  pages = {2047--2063},
  publisher = {{American Speech-Language-Hearing Association}},
  doi = {10.1044/2017_JSLHR-L-16-0157},
  urldate = {2023-04-04},
  abstract = {Purpose  To produce a novel, efficient measure of children's expressive vocal development on the basis of automatic vocalization assessment (AVA), child vocalizations were automatically identified and extracted from audio recordings using Language Environment Analysis (LENA) System technology. Method  Assessment was based on full-day audio recordings collected in a child's unrestricted, natural language environment. AVA estimates were derived using automatic speech recognition modeling techniques to categorize and quantify the sounds in child vocalizations (e.g., protophones and phonemes). These were expressed as phone and biphone frequencies, reduced to principal components, and inputted to age-based multiple linear regression models to predict independently collected criterion-expressive language scores. From these models, we generated vocal development AVA estimates as age-standardized scores and development age estimates. Result  AVA estimates demonstrated strong statistical reliability and validity when compared with standard criterion expressive language assessments. Conclusions  Automated analysis of child vocalizations extracted from full-day recordings in natural settings offers a novel and efficient means to assess children's expressive vocal development. More research remains to identify specific mechanisms of operation.}
}

@article{roder2000,
  title = {Event-Related Potentials during Auditory Language Processing in Congenitally Blind and Sighted People},
  author = {R{\"o}der, Brigitte and R{\"o}sler, Frank and Neville, Helen J},
  year = {2000},
  month = oct,
  journal = {Neuropsychologia},
  volume = {38},
  number = {11},
  pages = {1482--1502},
  issn = {0028-3932},
  doi = {10.1016/S0028-3932(00)00057-9},
  urldate = {2022-09-20},
  abstract = {While behavioral studies have documented delayed language acquisition in blind children, other studies have revealed better speech discrimination abilities for blind than sighted adults. Several brain imaging studies have provided evidence for cortical reorganization due to visual deprivation but the cerebral organization of language in blind humans is not known yet. We hypothesized that the increasing specialization of language systems normally observed during development may not take place to the same degree in blind individuals since posterior visual areas do not receive their adequate input. On the other hand, we hypothesized that blind people, due to their greater reliance upon the auditory language signal, may process speech faster than sighted people. To test these assumptions, event-related potentials were recorded while 11 congenitally blind and 11 sighted adults matched in age, gender, handedness and education were engaged in a language task. Participants listened to sentences in order to decide after each sentence if it was meaningful or not. Incongruous sentence-final words elicited an N400 effect in both groups. The N400 effect had a left-lateralized fronto-central scalp distribution in the sighted but a symmetric and broad topography in the blind. Furthermore, the N400 effect started earlier in the blind than in the sighted. Closed class compared to open class sentence middle words elicited a more pronounced late negativity in the blind than in the sighted. These results suggest that blind people process auditory language stimuli faster than sighted people and that some language functions may be reorganized in the blind.},
  langid = {english},
  keywords = {Blindness,Cross-modal compensation,Language perception,Neural plasticity}
}

@article{roder2003,
  title = {Semantic and Morpho-Syntactic Priming in Auditory Word Recognition in Congenitally Blind Adults},
  author = {R{\"o}der, Brigitte and Demuth, Lisa and Streb, Judith and R{\"o}sler, Frank},
  year = {2003},
  month = feb,
  journal = {Language and Cognitive Processes},
  volume = {18},
  number = {1},
  pages = {1--20},
  issn = {0169-0965},
  doi = {10.1080/01690960143000407},
  urldate = {2022-09-20},
  abstract = {While several studies have reported a deviation from the normal time course of language acquisition in blind children others have provided evidence for a more efficient processing of the language input in blind than sighted adults. The present study used a semantic and morpho-syntactic priming paradigm to address the question at which processing stage the advantage of blind adults may arise. Congenitally blind adults and sighted controls matched for age, gender and education, first heard an adjective followed by a noun or a pseudo-word. The adjective was or was not semantically associated with the target and it was either correctly or incorrectly inflected for gender with respect to the following noun. Participants decided whether or not the target noun was a legal German word. Nouns primed semantically and morpho-syntactically had shorter lexical decision times than those primed only semantically or only morpho-syntactically and decision times for the latter two conditions were shorter than in a condition without a semantically or morpho-syntactically congruent context. This response pattern did not differ between groups. However, blind participants had shorter reaction times than sighted for pseudo-words, and overall decision times for words tended to be shorter in the blind as well. It is concluded that the faster speech comprehension skills of blind adults most likely originate from a more efficient perceptual analysis rather than from a more extended use of semantic or morpho-syntactic context information.}
}

@article{rogers1984,
  title = {Social {{Characteristics}} of {{Visually Impaired Infants}}' {{Play}}},
  author = {Rogers, Sally J. and Puchalski, Carol B.},
  year = {1984},
  month = jan,
  journal = {Topics in Early Childhood Special Education},
  volume = {3},
  number = {4},
  pages = {52--56},
  publisher = {{SAGE Publications Inc}},
  issn = {0271-1214},
  doi = {10.1177/027112148400300409},
  urldate = {2023-04-21},
  abstract = {This cross-sectional study explores the extent to which the visually impaired infant and mother are able to use play to facilitate rewarding social interactions. Mother-child interactions were observed in 21 visually impaired infants and 16 nonhandicapped infants. From videotape ratings of five child behaviors and five maternal behaviors, significant differences were found in several variables. Visually impaired infants demonstrated fewer periods of positive vocalization and positive responses to the mother, fewer social initiations to the mother, more negative vocalizations, more periods of negative affect, and more ignoring of the mother than did the controls. Mothers of visually impaired infants demonstrated less en-facing positioning, fewer positive vocalizations, and more periods of neutral vocalizations than did the mothers of nonhandicapped children.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/E6AQ72I4/Rogers and Puchalski - 1984 - Social Characteristics of Visually Impaired Infant.pdf}
}

@article{rogers1988,
  title = {Development of {{Object Permanence}} in {{Visually Impaired Infants}}},
  author = {Rogers, S. J. and Puchalski, C.B.},
  year = {1988},
  month = apr,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {82},
  number = {4},
  pages = {137--142},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X8808200407},
  urldate = {2023-05-04},
  abstract = {The development of object permanence skills in 20 visually impaired infants between the ages of 4 and 25 months was examined longitudinally. Other areas of development which were examined in relationship to object permanence included motor skills, various aspects of language and social adaptation, symbolic play, and stranger and separation distress. Parallels to object permanence development in sighted infants that were found included order of skill acquisition and the span of time across which the skills were mastered. The visually impaired subjects as a group were 8 to 12 months older than the sighted infants at the time of similar object permanence skills, but the greater maturity of the visually impaired subjects seemed to be demonstrated in the lack of A?B error and the ability of visually impaired infants to perform the tasks on the basis of discontinuous sensory information. No relationships between object permanence levels and either symbolic play abilities and separation or stranger distress were found.},
  langid = {english}
}

@article{romeo2018,
  title = {Beyond the 30-{{Million-Word Gap}}: {{Children}}'s {{Conversational Exposure Is Associated With Language-Related Brain Function}}},
  shorttitle = {Beyond the 30-{{Million-Word Gap}}},
  author = {Romeo, Rachel R. and Leonard, Julia A. and Robinson, Sydney T. and West, Martin R. and Mackey, Allyson P. and Rowe, Meredith L. and Gabrieli, John D. E.},
  year = {2018},
  month = may,
  journal = {Psychological Science},
  volume = {29},
  number = {5},
  pages = {700--710},
  issn = {1467-9280},
  doi = {10.1177/0956797617742725},
  abstract = {Children's early language exposure impacts their later linguistic skills, cognitive abilities, and academic achievement, and large disparities in language exposure are associated with family socioeconomic status (SES). However, there is little evidence about the neural mechanisms underlying the relation between language experience and linguistic and cognitive development. Here, language experience was measured from home audio recordings of 36 SES-diverse 4- to 6-year-old children. During a story-listening functional MRI task, children who had experienced more conversational turns with adults-independently of SES, IQ, and adult-child utterances alone-exhibited greater left inferior frontal (Broca's area) activation, which significantly explained the relation between children's language exposure and verbal skill. This is the first evidence directly relating children's language environments with neural language processing, specifying both an environmental and a neural mechanism underlying SES disparities in children's language skills. Furthermore, results suggest that conversational experience impacts neural language processing over and above SES or the sheer quantity of words heard.},
  langid = {english},
  pmcid = {PMC5945324},
  pmid = {29442613},
  keywords = {Brain Mapping,Broca Area,Child,{Child, Preschool},Female,fMRI,Humans,Interpersonal Relations,language,Language,Language Development,LENA,Magnetic Resonance Imaging,Male,open data,open materials,Social Class,Social Environment,socioeconomic status,turn taking},
  file = {/Users/eec35/Zotero/storage/AYMA8CVP/Romeo et al. - 2018 - Beyond the 30-Million-Word Gap Children's Convers.pdf}
}

@article{roseberry2014,
  title = {Skype Me! {{Socially}} Contingent Interactions Help Toddlers Learn Language},
  author = {Roseberry, Sarah and {Hirsh-Pasek}, Kathy and Golinkoff, Roberta M.},
  year = {2014 May-Jun},
  journal = {Child Development},
  volume = {85},
  number = {3},
  pages = {956--970},
  issn = {1467-8624},
  doi = {10.1111/cdev.12166},
  abstract = {Language learning takes place in the context of social interactions, yet the mechanisms that render social interactions useful for learning language remain unclear. This study focuses on whether social contingency might support word learning. Toddlers aged 24-30 months (N = 36) were exposed to novel verbs in one of three conditions: live interaction training, socially contingent video training over video chat, and noncontingent video training (yoked video). Results suggest that children only learned novel verbs in socially contingent interactions (live interactions and video chat). This study highlights the importance of social contingency in interactions for language learning and informs the literature on learning through screen media as the first study to examine word learning through video chat technology.},
  langid = {english},
  pmcid = {PMC3962808},
  pmid = {24112079},
  keywords = {{Child, Preschool},Female,Humans,Interpersonal Relations,Language Development,Learning,Male,Random Allocation,Video Recording,Videoconferencing},
  file = {/Users/eec35/Zotero/storage/A6JQ4UGU/Roseberry et al. - 2014 - Skype me! Socially contingent interactions help to.pdf}
}

@article{rowe2008,
  title = {Child-Directed Speech: Relation to Socioeconomic Status, Knowledge of Child Development and Child Vocabulary Skill*},
  shorttitle = {Child-Directed Speech},
  author = {Rowe, Meredith L.},
  year = {2008},
  month = feb,
  journal = {Journal of Child Language},
  volume = {35},
  number = {1},
  pages = {185--205},
  publisher = {{Cambridge University Press}},
  issn = {1469-7602, 0305-0009},
  doi = {10.1017/S0305000907008343},
  urldate = {2022-08-24},
  abstract = {This study sought to determine why American parents from different socioeconomic backgrounds communicate in different ways with their children. Forty-seven parent\textendash child dyads were videotaped engaging in naturalistic interactions in the home for ninety minutes at child age 2~;~6. Transcripts of these interactions provided measures of child-directed speech. Children's vocabulary comprehension skills were measured using the Peabody Picture Vocabulary Test at 2~;~6 and one year later at 3~;~6. Results indicate that: (1) child-directed speech with toddlers aged 2~;~6 predicts child vocabulary skill one year later, controlling for earlier toddler vocabulary skill; (2) child-directed speech relates to socioeconomic status as measured by income and education; and (3) the relation between socioeconomic status and child-directed speech is mediated by parental knowledge of child development. Potential mechanisms through which parental knowledge influences communicative behavior are discussed.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/K29Y4MTK/Rowe - 2008 - Child-directed speech relation to socioeconomic s.pdf;/Users/eec35/Zotero/storage/9E737PLN/9A6AE54D0489EECB7F665B04DC61D365.html}
}

@article{rowe2012,
  title = {A {{Longitudinal Investigation}} of the {{Role}} of {{Quantity}} and {{Quality}} of {{Child-Directed Speech}} in {{Vocabulary Development}}},
  author = {Rowe, Meredith L.},
  year = {2012},
  journal = {Child Development},
  volume = {83},
  number = {5},
  pages = {1762--1774},
  issn = {1467-8624},
  doi = {10.1111/j.1467-8624.2012.01805.x},
  urldate = {2022-08-25},
  abstract = {Quantity and quality of caregiver input was examined longitudinally in a sample of 50 parent\textendash child dyads to determine which aspects of input contribute most to children's vocabulary skill across early development. Measures of input gleaned from parent\textendash child interactions at child ages 18, 30, and 42 months were examined in relation to children's vocabulary skill on a standardized measure 1 year later (e.g., 30, 42, and 54 months). Results show that controlling for socioeconomic status, input quantity, and children's previous vocabulary skill; using a diverse and sophisticated vocabulary with toddlers; and using decontextualized language (e.g., narrative) with preschoolers explains additional variation in later vocabulary ability. The differential effects of various aspects of the communicative environment at several points in early vocabulary development are discussed.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/27799FS9/Rowe - 2012 - A Longitudinal Investigation of the Role of Quanti.pdf;/Users/eec35/Zotero/storage/RKR2LYRI/j.1467-8624.2012.01805.html}
}

@article{rowe2013,
  title = {Decontextualized {{Language Input}} and {{Preschoolers}}' {{Vocabulary Development}}},
  author = {Rowe, Meredith L.},
  year = {2013},
  month = nov,
  journal = {Seminars in Speech and Language},
  volume = {34},
  number = {4},
  pages = {260--266},
  issn = {0734-0478, 1098-9056},
  doi = {10.1055/s-0033-1353444},
  urldate = {2022-09-20},
  abstract = {This article discusses the importance of using decontextualized language, or language that is removed from the here and now including pretend, narrative, and explanatory talk, with preschool children. The literature on parents' use of decontextualized language is reviewed and results of a longitudinal study of parent decontextualized language input in relation to child vocabulary development are explained. The main findings are that parents who provide their preschool children with more explanations and narrative utterances about past or future events in the input have children with larger vocabularies 1 year later, even with quantity of parent input and child prior vocabulary skill controlled. Recommendations for how to engage children in decontextualized language conversations are provided.},
  copyright = {Thieme Medical Publishers 333 Seventh Avenue, New York, NY 10001, USA.},
  langid = {english},
  keywords = {Decontextualized language,extended discourse,input,narrative,vocabulary}
}

@article{rowe2020,
  title = {Analyzing Input Quality along Three Dimensions: Interactive, Linguistic, and Conceptual},
  shorttitle = {Analyzing Input Quality along Three Dimensions},
  author = {Rowe, Meredith L. and Snow, Catherine E.},
  year = {2020},
  month = jan,
  journal = {Journal of Child Language},
  volume = {47},
  number = {1},
  pages = {5--21},
  publisher = {{Cambridge University Press}},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000655},
  urldate = {2022-09-08},
  abstract = {This paper provides an overview of the features of caregiver input that facilitate language learning across early childhood. We discuss three dimensions of input quality: interactive, linguistic, and conceptual. All three types of input features have been shown to predict children's language learning, though perhaps through somewhat different mechanisms. We argue that input best designed to promote language learning is interactionally supportive, linguistically adapted, and conceptually challenging for the child's age/level. Furthermore, input features interact across dimensions to promote learning. Some but not all qualities of input vary based on parent socioeconomic status, language, or culture, and contexts such as book-reading or pretend play generate uniquely facilitative input features. The review confirms that we know a great deal about the role of input quality in promoting children's development, but that there is much more to learn. Future research should examine input features across the boundaries of the dimensions distinguished here.},
  langid = {english},
  keywords = {caregiver input,conversational responsiveness,decontextualized language,extended discourse,linguistic complexity,semantic contingency},
  file = {/Users/eec35/Zotero/storage/G8ZAQA6X/Rowe and Snow - 2020 - Analyzing input quality along three dimensions in.pdf;/Users/eec35/Zotero/storage/XEGFECUG/83C958963F3746EA109D54BD1B8E13A6.html}
}

@article{rowland1984,
  title = {Preverbal {{Communication}} of {{Blind Infants}} and {{Their Mothers}}},
  author = {Rowland, Charity},
  year = {1984},
  month = sep,
  journal = {Journal of Visual Impairment \& Blindness},
  volume = {78},
  number = {7},
  pages = {297--302},
  publisher = {{SAGE Publications Inc}},
  issn = {0145-482X},
  doi = {10.1177/0145482X8407800701},
  urldate = {2022-09-15},
  abstract = {Films of interactions between five mothers and their blind infants, aged 11 months to 2 years, 8 months, made at regular intervals over six months, were analyzed to determine the development of communicative skills in each mother-infant dyad. It was found that, although the frequency of the infants? vocalizations was within normal limits, the vocalizations did not follow normal patterns of responsiveness, and the mothers? responses to them were weak and inconsistent. Suggestions are made for a highly structured program to enhance the communicative skills of parents and their blind infants.},
  langid = {english}
}

@article{rubio-fernandez2019,
  title = {Overinformative {{Speakers Are Cooperative}}: {{Revisiting}} the {{Gricean Maxim}} of {{Quantity}}},
  shorttitle = {Overinformative {{Speakers Are Cooperative}}},
  author = {{Rubio-Fernandez}, Paula},
  year = {2019},
  journal = {Cognitive Science},
  volume = {43},
  number = {11},
  pages = {e12797},
  issn = {1551-6709},
  doi = {10.1111/cogs.12797},
  urldate = {2022-08-25},
  abstract = {A pragmatic account of referential communication is developed which presents an alternative to traditional Gricean accounts by focusing on cooperativeness and efficiency, rather than informativity. The results of four language-production experiments support the view that speakers can be cooperative when producing redundant adjectives, doing so more often when color modification could facilitate the listener's search for the referent in the visual display (Experiment 1a). By contrast, when the listener knew which shape was the target, speakers did not produce redundant color adjectives (Experiment 1b). English speakers used redundant color adjectives more often than Spanish speakers, suggesting that speakers are sensitive to the differential efficiency of prenominal and postnominal modification (Experiment 2). Speakers were also cooperative when using redundant size adjectives (Experiment 3). Overall, these results show how discriminability affects a speaker's choice of referential expression above and beyond considerations of informativity, supporting the view that redundant speakers can be cooperative.},
  langid = {english},
  keywords = {Audience design,Cooperativeness,Efficiency,Informativity,Redundancy,Referential communication},
  file = {/Users/eec35/Zotero/storage/P3YX2B9S/Rubio-Fernandez - 2019 - Overinformative Speakers Are Cooperative Revisiti.pdf;/Users/eec35/Zotero/storage/WXLEZU6R/cogs.html}
}

@article{sandbank2016,
  title = {The {{Association Between Parental Mean Length}} of {{Utterance}} and {{Language Outcomes}} in {{Children With Disabilities}}: {{A Correlational Meta-Analysis}}},
  shorttitle = {The {{Association Between Parental Mean Length}} of {{Utterance}} and {{Language Outcomes}} in {{Children With Disabilities}}},
  author = {Sandbank, Micheal and Yoder, Paul},
  year = {2016},
  month = may,
  journal = {American Journal of Speech-Language Pathology},
  volume = {25},
  number = {2},
  pages = {240--251},
  issn = {1558-9110},
  doi = {10.1044/2015_AJSLP-15-0003},
  abstract = {PURPOSE: The purpose of this correlational meta-analysis was to examine the association between parental utterance length and language outcomes in children with disabilities and whether this association varies according to other child characteristics, such as age and disability type. This association can serve as a starting point for language intervention practices for children with disabilities. METHOD: We conducted a systematic search of 42 electronic databases to identify relevant studies. Twelve studies reporting on a total of 13 populations (including 257 participants) were identified. A random-effects model was used to estimate a combined effect size across all studies as well as separate effect sizes across studies in each disability category. RESULTS: The combined effect size across all studies suggests a weak positive association between parental input length and child language outcomes. However, subgroup analyses within disability categories suggest that this association may differ for children with autism. Results of 4 studies including 47 children with autism show that parental input length is strongly associated with positive language outcomes in this population. CONCLUSIONS: Present evidence suggests that clinicians should reconsider intervention practices that prescribe shorter, grammatically incomplete utterances, particularly when working with children with autism.},
  langid = {english},
  pmid = {27088766},
  keywords = {Adult,Autistic Disorder,Child,Disabled Children,Humans,Language,Parent-Child Relations,Parents}
}

@article{senju2013,
  title = {The Importance of the Eyes: Communication Skills in Infants of Blind Parents},
  shorttitle = {The Importance of the Eyes},
  author = {Senju, Atsushi and Tucker, Leslie and Pasco, Greg and Hudry, Kristelle and Elsabbagh, Mayada and Charman, Tony and Johnson, Mark H.},
  year = {2013},
  month = jun,
  journal = {Proceedings. Biological Sciences},
  volume = {280},
  number = {1760},
  pages = {20130436},
  issn = {1471-2954},
  doi = {10.1098/rspb.2013.0436},
  abstract = {The effects of selectively different experience of eye contact and gaze behaviour on the early development of five sighted infants of blind parents were investigated. Infants were assessed longitudinally at 6-10, 12-15 and 24-47 months. Face scanning and gaze following were assessed using eye tracking. In addition, established measures of autistic-like behaviours and standardized tests of cognitive, motor and linguistic development, as well as observations of naturalistic parent-child interaction were collected. These data were compared with those obtained from a larger group of sighted infants of sighted parents. Infants with blind parents did not show an overall decrease in eye contact or gaze following when they observed sighted adults on video or in live interactions, nor did they show any autistic-like behaviours. However, they directed their own eye gaze somewhat less frequently towards their blind mothers and also showed improved performance in visual memory and attention at younger ages. Being reared with significantly reduced experience of eye contact and gaze behaviour does not preclude sighted infants from developing typical gaze processing and other social-communication skills. Indeed, the need to switch between different types of communication strategy may actually enhance other skills during development.},
  langid = {english},
  pmcid = {PMC3652463},
  pmid = {23576790},
  keywords = {Child Development,{Child, Preschool},Communication,Eye Movements,Face,Female,Humans,Infant,Interpersonal Relations,Longitudinal Studies,Male,Parent-Child Relations,Parents,Visually Impaired Persons},
  file = {/Users/eec35/Zotero/storage/MDBNJE2V/Senju et al. - 2013 - The importance of the eyes communication skills i.pdf}
}

@article{snow1972,
  title = {Mothers' {{Speech}} to {{Children Learning Language}} on {{JSTOR}}},
  author = {Snow, Catherine E.},
  year = {1972},
  journal = {Child Development},
  volume = {43},
  pages = {549--565},
  urldate = {2022-09-15},
  file = {/Users/eec35/Zotero/storage/424EKZX5/1127555.html}
}

@article{snow1972a,
  title = {Mothers' {{Speech}} to {{Children Learning Language}}},
  author = {Snow, Catherine E.},
  year = {1972},
  journal = {Child Development},
  volume = {43},
  number = {2},
  eprint = {1127555},
  eprinttype = {jstor},
  pages = {549--565},
  publisher = {{[Wiley, Society for Research in Child Development]}},
  issn = {0009-3920},
  doi = {10.2307/1127555},
  urldate = {2023-05-05},
  abstract = {The assumption that language acquisition is relatively independent of the amount and kind of language input must be assessed in light of information about the speech actually heard by young children. The speech of middle-class mothers to 2-year-old children was found to be simpler and more redundant than their speech to 10-year-old children. The mothers modified their speech less when talking to children whose responses they could not observe, indicating that the children played some role in eliciting the speech modifications. Task difficulty did not contribute to the mothers' production of simplified, redundant speech. Experienced mothers were only slightly better than nonmothers in predicting the speech-style modifications required by young children. These findings indicate that children who are learning language have available a sample of speech which is simpler, more redundant, and less confusing than normal adult speech.},
  file = {/Users/eec35/Zotero/storage/XIF8NZXG/Snow - 1972 - Mothers' Speech to Children Learning Language.pdf}
}

@article{soderstrom2021,
  ids = {soderstrom2021a},
  title = {Developing a {{Cross-Cultural Annotation System}} and {{MetaCorpus}} for {{Studying Infants}}' {{Real World Language Experience}}},
  author = {Soderstrom, Melanie and Casillas, Marisa and Bergelson, Elika and Rosemberg, Celia and Alam, Florencia and Warlaumont, Anne S. and Bunce, John},
  year = {2021},
  month = may,
  journal = {Collabra: Psychology},
  volume = {7},
  number = {1},
  pages = {23445},
  issn = {2474-7394},
  doi = {10.1525/collabra.23445},
  urldate = {2022-08-24},
  abstract = {Recent issues around reproducibility, best practices, and cultural bias impact naturalistic observational approaches as much as experimental approaches, but there has been less focus on this area. Here, we present a new approach that leverages cross-laboratory collaborative, interdisciplinary efforts to examine important psychological questions. We illustrate this approach with a particular project that examines similarities and differences in children's early experiences with language. This project develops a comprehensive start-to-finish analysis pipeline by developing a flexible and systematic annotation system, and implementing this system across a sampling from a ``metacorpus'' of audiorecordings of diverse language communities. This resource is publicly available for use, sensitive to cultural differences, and flexible to address a variety of research questions. It is also uniquely suited for use in the development of tools for automated analysis.},
  file = {/Users/eec35/Zotero/storage/E9KQKVLD/Soderstrom et al. - 2021 - Developing a Cross-Cultural Annotation System and .pdf;/Users/eec35/Zotero/storage/QCHXUJ3N/Developing-a-Cross-Cultural-Annotation-System-and.html}
}

@article{tadic2013a,
  ids = {tadic2013},
  title = {Story Discourse and Use of Mental State Language between Mothers and School-Aged Children with and without Visual Impairment},
  author = {Tadi{\'c}, Valerija and Pring, Linda and Dale, Naomi},
  year = {2013},
  month = nov,
  journal = {International Journal of Language \& Communication Disorders},
  volume = {48},
  number = {6},
  pages = {679--688},
  issn = {1368-2822},
  doi = {10.1111/1460-6984.12040},
  urldate = {2023-04-11},
  abstract = {Background Lack of sight compromises insight into other people's mental states. Little is known about the role of maternal language in assisting the development of mental state language in children with visual impairment (VI). Aims To investigate mental state language strategies of mothers of school-aged children with VI and to compare these with mothers of comparable children with typically developing vision. To investigate whether the characteristics of mother\textendash child discourse were associated with the child's socio-communicative competence. Methods \& Procedures Mother\textendash child discourse with twelve 6\textendash 12-year-old children with VI was coded during a shared book-reading narrative and compared with 14 typically sighted children matched in age and verbal ability. Outcomes \& Results Mothers of children with VI elaborated more and made significantly more references to story characters' mental states and descriptive elaborations than mothers of sighted children. Mental state elaborations of mothers in the VI group related positively with the level produced by their children, with the association remaining after mothers' overall verbosity and children's developmental levels were controlled for. Frequency of maternal elaborations, including their mental state language, was related to socio-communicative competence of children with VI. Conclusions \& Implications The findings offer insights into the potential contribution of maternal verbal scaffolding to mentalistic language and social\textendash communicative competences of children with VI.},
  pmcid = {PMC4229064},
  pmid = {24165364},
  keywords = {Blind,Child,Child Behavior,Child Development,Child Language,Communication,Female,Humans,Language Development,Male,mental state language,mother-child discourse,Mother-Child Relations,Mothers,Narration,Reading,Social Behavior,Vision Disorders,visual impairment},
  file = {/Users/eec35/Zotero/storage/45DIVQI9/Tadić et al. - 2013 - Story discourse and use of mental state language b.pdf}
}

@book{templin1957,
  title = {Certain Language Skills in Children; Their Development and Interrelationships},
  author = {Templin, Mildred C.},
  year = {1957},
  series = {Certain Language Skills in Children; Their Development and Interrelationships},
  pages = {xviii, 183},
  publisher = {{University of Minnesota Press}},
  address = {{Minneapolis, MN, US}},
  abstract = {Normative data were secured on 480 children between the ages of 3 and 8 divided into 8 subsamples by age, and stratified for SES. Measures obtained were: articulation of speech sounds, sound discrimination, vocabulary, and verbalizations. Using the terminal status concept and the significance of differences between consecutively tested age groups, age trends were determined. The often-assumed superiority of girls over boys is not entirely substantiated. SES differences are significant. In comparison with previous studies, children today show greater loquacity, possibly reflecting the effect of mass media or other cultural changes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/eec35/Zotero/storage/MAZW5YI2/1957-07556-000.html}
}

@inproceedings{terragni2021,
  title = {Word {{Embedding-Based Topic Similarity Measures}}},
  booktitle = {Natural {{Language Processing}} and {{Information Systems}}},
  author = {Terragni, Silvia and Fersini, Elisabetta and Messina, Enza},
  editor = {M{\'e}tais, Elisabeth and Meziane, Farid and Horacek, Helmut and Kapetanios, Epaminondas},
  year = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {33--45},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-80599-9_4},
  abstract = {Topic models aim at discovering a set of hidden themes in a text corpus. A user might be interested in identifying the most similar topics of a given theme of interest. To accomplish this task, several similarity and distance metrics can be adopted. In this paper, we provide a comparison of the state-of-the-art topic similarity measures and propose novel metrics based on word embeddings. The proposed measures can overcome some limitations of the existing approaches, highlighting good capabilities in terms of several topic performance measures on benchmark datasets.},
  isbn = {978-3-030-80599-9},
  langid = {english},
  keywords = {Topic modeling,Topic similarity,Word embeddings},
  file = {/Users/eec35/Zotero/storage/VRVBWPVM/Terragni et al. - 2021 - Word Embedding-Based Topic Similarity Measures.pdf}
}

@article{thiessen2005,
  title = {Infant-{{Directed Speech Facilitates Word Segmentation}}},
  author = {Thiessen, Erik D. and Hill, Emily A. and Saffran, Jenny R.},
  year = {2005},
  month = jan,
  journal = {Infancy: The Official Journal of the International Society on Infant Studies},
  volume = {7},
  number = {1},
  pages = {53--71},
  issn = {1532-7078},
  doi = {10.1207/s15327078in0701_5},
  abstract = {There are reasons to believe that infant-directed (ID) speech may make language acquisition easier for infants. However, the effects of ID speech on infants' learning remain poorly understood. The experiments reported here assess whether ID speech facilitates word segmentation from fluent speech. One group of infants heard a set of nonsense sentences spoken with intonation contours characteristic of adult-directed (AD) speech, and the other group heard the same sentences spoken with intonation contours characteristic of ID speech. In both cases, the only cue to word boundaries was the statistical structure of the speech. Infants were able to distinguish words from syllable sequences spanning word boundaries after exposure to ID speech but not after hearing AD speech. These results suggest that ID speech facilitates word segmentation and may be useful for other aspects of language acquisition as well. Issues of direction of preference in preferential listening paradigms are also considered.},
  langid = {english},
  pmid = {33430544}
}

@article{tomasello1986,
  title = {Joint {{Attention}} and {{Early Language}}},
  author = {Tomasello, Michael and Farrar, Michael Jeffrey},
  year = {1986},
  month = dec,
  journal = {Child Development},
  volume = {57},
  number = {6},
  eprint = {1130423},
  eprinttype = {jstor},
  pages = {1454},
  issn = {00093920},
  doi = {10.2307/1130423},
  urldate = {2021-04-16},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/4CD3BM7P/Tomasello and Farrar - 1986 - Joint Attention and Early Language.pdf}
}

@article{troster1992,
  title = {Early Social-Emotional Development in Blind Infants},
  author = {Tr{\"o}ster, H. and Brambring, M.},
  year = {1992},
  journal = {Child: Care, Health and Development},
  volume = {18},
  number = {4},
  pages = {207--227},
  issn = {0305-1862},
  doi = {10.1111/j.1365-2214.1992.tb00355.x},
  abstract = {In order to study the impact of blindness on social and emotional development during the first year of life, the level of social-emotional development was compared in blind and sighted 9- and 12-month-old infants. The five 9-month-old and the 17 12-month-old blind infants were completely blind from birth and exhibited no further serious disabilities. Social-emotional development was assessed with a scale from the Bielefeld Developmental Test for Blind Infants and Preschoolers containing three subscales on emotions, social interaction and impulse control. Compared to non-disabled infants, blind infants exhibited a more limited repertoire of facial expressions and less responsiveness. They less frequently attempted to initiate contact with their mothers (self-initiated interactions) or comply with simple requests and prohibitions than sighted infants. These differences in the social-emotional development of blind and sighted infants are traced back to the effects of blindness on the mother-child interaction. The lack of visual perception appears to impede particularly the acquisition of a dialogue concept.},
  langid = {english},
  pmid = {1386004},
  keywords = {Blindness,Child,Child Development,Communication,Disabled Persons,Emotions,Facial Expression,Female,Humans,Infant,{Infant, Newborn},Interpersonal Relations,Male,Mother-Child Relations,Visual Perception}
}

@article{uccelli2019,
  title = {Children's {{Early Decontextualized Talk Predicts Academic Language Proficiency}} in {{Midadolescence}}},
  author = {Uccelli, Paola and {Demir-Lira}, {\"O}zlem Ece and Rowe, Meredith L. and Levine, Susan and {Goldin-Meadow}, Susan},
  year = {2019},
  month = sep,
  journal = {Child Development},
  volume = {90},
  number = {5},
  pages = {1650--1663},
  issn = {1467-8624},
  doi = {10.1111/cdev.13034},
  abstract = {This study examines whether children's decontextualized talk-talk about nonpresent events, explanations, or pretend-at 30~months predicts seventh-grade academic language proficiency (age 12). Academic language (AL) refers to the language of school texts. AL proficiency has been identified as an important predictor of adolescent text comprehension. Yet research on precursors to AL proficiency is scarce. Child decontextualized talk is known to be a predictor of early discourse development, but its relation to later language outcomes remains unclear. Forty-two children and their caregivers participated in this study. The proportion of child talk that was decontextualized emerged as a significant predictor of seventh-grade AL proficiency, even after controlling for socioeconomic status, parent decontextualized talk, child total words, child vocabulary, and child syntactic comprehension.},
  langid = {english},
  pmcid = {PMC6785988},
  pmid = {29359315},
  keywords = {Academic Performance,Child,{Child, Preschool},Comprehension,Female,Humans,Infant,Language,Language Development,Male,Parents,Social Class},
  file = {/Users/eec35/Zotero/storage/H7US86GX/Uccelli et al. - 2019 - Children's Early Decontextualized Talk Predicts Ac.pdf}
}

@article{urwin1983,
  title = {Dialogue and Cognitive Functioning in the Early Language Development of Three Blind Children: {{Normal}} and Deficient},
  author = {Urwin, Cathy},
  year = {1983},
  pages = {142--161},
  urldate = {2022-09-15},
  file = {/Users/eec35/Zotero/storage/ILIWTI95/scholar_lookup.html}
}

@article{urwin1984,
  title = {Language for Absent Things: Learning from Visually Handicapped Children},
  shorttitle = {Language for Absent Things},
  author = {Urwin, Cathy},
  year = {1984},
  month = sep,
  journal = {Topics in Language Disorders},
  volume = {4},
  number = {4},
  pages = {24},
  issn = {0271-8294},
  urldate = {2023-05-04},
  abstract = {An abstract is unavailable. This article is available as a PDF only.},
  langid = {american},
  file = {/Users/eec35/Zotero/storage/U7STU9QH/Language_for_absent_things__learning_from_visually.6.html}
}

@article{vandam2015,
  title = {Automated {{Vocal Analysis}} of {{Children}} with {{Hearing Loss}} and {{Their Typical}} and {{Atypical Peers}}},
  author = {VanDam, Mark and Oller, D. Kimbrough and Ambrose, Sophie E. and Gray, Sharmistha and Richards, Jeffrey A. and Xu, Dongxin and Gilkerson, Jill and Silbert, Noah H. and Moeller, Mary Pat},
  year = {2015},
  journal = {Ear and hearing},
  volume = {36},
  number = {4},
  pages = {e146-e152},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000138},
  urldate = {2023-04-04},
  abstract = {Objectives This study investigated automatic assessment of vocal development in children with hearing loss as compared with children who are typically developing, have language delays, and autism spectrum disorder. Statistical models are examined for performance in a classification model and to predict age within the four groups of children. Design The vocal analysis system analyzed over 1900 whole-day, naturalistic acoustic recordings from 273 toddlers and preschoolers comprising children who were typically developing, hard of hearing, language delayed, or autistic. Results Samples from children who were hard-of-hearing patterned more similarly to those of typically-developing children than to the language-delayed or autistic samples. The statistical models were able to classify children from the four groups examined and estimate developmental age based on automated vocal analysis. Conclusions This work shows a broad similarity between children with hearing loss and typically developing children, although children with hearing loss show some delay in their production of speech. Automatic acoustic analysis can now be used to quantitatively compare vocal development in children with and without speech-related disorders. The work may serve to better distinguish among various developmental disorders and ultimately contribute to improved intervention.},
  pmcid = {PMC4478108},
  pmid = {25587667},
  file = {/Users/eec35/Zotero/storage/2YB8YYDR/VanDam et al. - 2015 - Automated Vocal Analysis of Children with Hearing .pdf}
}

@book{vygotsky1978,
  title = {Mind in {{Society}}: {{Development}} of {{Higher Psychological Processes}}},
  shorttitle = {Mind in {{Society}}},
  author = {Vygotsky, L. S. and Cole, Michael},
  year = {1978},
  publisher = {{Harvard University Press}},
  abstract = {The great Russian psychologist L. S. Vygotsky has long been recognized as a pioneer in developmental psychology. But his theory of development has never been well understood in the West. Mind in Society corrects much of this misunderstanding. Carefully edited by a group of outstanding Vygotsky scholars, the book presents a unique selection of Vygotsky's important essays.},
  googlebooks = {RxjjUefze\_oC},
  isbn = {978-0-674-57629-2},
  langid = {english},
  keywords = {Psychology / General}
}

@article{watkins1998,
  title = {The {{Deaf Mentor Experimental Project}} for Young Children Who Are Deaf and Their Families},
  author = {Watkins, S. and Pittman, P. and Walden, B.},
  year = {1998},
  month = mar,
  journal = {American Annals of the Deaf},
  volume = {143},
  number = {1},
  pages = {29--34},
  issn = {0002-726X},
  doi = {10.1353/aad.2012.0098},
  abstract = {The Deaf Mentor Experimental Project investigated the efficacy of deaf mentor services to young deaf children and their families. These services focused on deaf adults (mentors), who made regular home visits to the children and their families; shared their language (American Sign Language), culture, and personal knowledge of deafness with the families; and served as role models for the children. The children also received regular home visits from a hearing parent adviser who helped the family promote the child's early listening, English, and literacy skills. The result was a bilingual-bicultural home environment for these children. The children who received deaf mentor services were compared to matched children who did not receive these services but who received parent adviser services. Children receiving this early bilingual-bicultural programming made greater language gains during treatment time, had considerably larger vocabularies, and scored higher on measures of communication, language, and English syntax than the matched children.},
  langid = {english},
  pmid = {9557330},
  keywords = {Adult,Child Language,{Child, Preschool},Deafness,Family,Female,Humans,Infant,{Infant, Newborn},Language Development,Male,Mentors,Multilingualism}
}

@article{weizman2001,
  title = {Lexical Input as Related to Children's Vocabulary Acquisition: Effects of Sophisticated Exposure and Support for Meaning},
  shorttitle = {Lexical Input as Related to Children's Vocabulary Acquisition},
  author = {Weizman, Z. O. and Snow, C. E.},
  year = {2001},
  month = mar,
  journal = {Developmental Psychology},
  volume = {37},
  number = {2},
  pages = {265--279},
  issn = {0012-1649},
  doi = {10.1037/0012-1649.37.2.265},
  abstract = {A corpus of nearly 150,000 maternal word-tokens used by 53 low-income mothers in 263 mother-child conversations in 5 settings (e.g., play, mealtime, and book readings) was studied. Ninety-nine percent of maternal lexical input consisted of the 3,000 most frequent words. Children's vocabulary performance in kindergarten and later in 2nd grade related more to the occurrence of sophisticated lexical items than to quantity of lexical input overall. Density of sophisticated words heard and the density with which such words were embedded in helpful or instructive interactions, at age 5 at home, independently predicted over a third of the variance in children's vocabulary performance in both kindergarten and 2nd grade. These two variables, with controls for maternal education, child nonverbal IQ, and amount of child's talk produced during the interactive settings, at age 5, predicted 50\% of the variance in children's 2nd-grade vocabulary.},
  langid = {english},
  pmid = {11269394},
  keywords = {Adult,{Child, Preschool},Female,Follow-Up Studies,Forecasting,Humans,Language Development,Male,Mother-Child Relations,Poverty,Vocabulary}
}

@misc{wijffels2023,
  title = {{{UDPipe}}},
  author = {Wijffels, Jan},
  year = {2023},
  month = jan,
  urldate = {2023-04-21},
  abstract = {The data preparation part of any Natural Language Processing flow consists of a number of important steps: Tokenization (1), Parts of Speech tagging (2), Lemmatization (3) and Dependency Parsing (4). This package allows you to do out-of-the-box annotation of these 4 steps and also allows you to train your own annotator models directly from R.}
}

@techreport{xu2009,
  title = {Reliability of the {{LENA Language Environment Analysis System}} in {{Young Children}}'s {{Natural Home Environment}}},
  author = {Xu, Dongxin and Yapanel, Umit and Gray, Sharmistha},
  year = {2009},
  month = feb,
  pages = {1--16},
  address = {{Boulder, CO}},
  institution = {{The LENA Foundation}},
  urldate = {2023-04-22},
  abstract = {The LENA language environment analysis system was designed to provide information about the language environment of infants and toddlers. In this technical report, we describe the reliability of the LENA System in terms of segmentation, adult word counts, and child vocalizations. We also describe unique sources of variability associated with data collection in the natural home environment.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/QY52AAWW/LTR-05-2_Reliability.pdf}
}

@article{yamashita2007a,
  ids = {yamashita2007},
  title = {A {{Stepwise AIC Method}} for {{Variable Selection}} in {{Linear Regression}}},
  author = {Yamashita, Toshie and Yamashita, Keizo and Kamimura, Ryotaro},
  year = {2007},
  month = oct,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {36},
  number = {13},
  pages = {2395--2403},
  publisher = {{Taylor \& Francis}},
  issn = {0361-0926},
  doi = {10.1080/03610920701215639},
  urldate = {2023-04-19},
  abstract = {In this article, we study stepwise AIC method for variable selection comparing with other stepwise method for variable selection, such as, Partial F, Partial Correlation, and Semi-Partial Correlation in linear regression modeling. Then we show mathematically that the stepwise AIC method and other stepwise methods lead to the same method as Partial F. Hence, there are more reasons to use the stepwise AIC method than the other stepwise methods for variable selection, since the stepwise AIC method is a model selection method that can be easily managed and can be widely extended to more generalized models and applied to non normally distributed data. We also treat problems that always appear in applications, that are validation of selected variables and problem of collinearity.},
  keywords = {AIC,Collinearity,Linear regression,Partial correlation,Partial F,Primary 62J05,Secondary 62J99,Semi-partial correlation,Stepwise variable selection,Validation}
}

@article{yoshinaga-itano2020,
  title = {Early {{Intervention}}, {{Parent Talk}}, and {{Pragmatic Language}} in {{Children With Hearing Loss}}},
  author = {{Yoshinaga-Itano}, Christine and Sedey, Allison L. and Mason, Craig A. and Wiggin, Mallene and Chung, Winnie},
  year = {2020},
  month = nov,
  journal = {Pediatrics},
  volume = {146},
  number = {Supplement\_3},
  pages = {S270-S277},
  issn = {0031-4005},
  doi = {10.1542/peds.2020-0242F},
  urldate = {2022-08-24},
  abstract = {Pragmatic language skills form the foundation for conversational competence, whereas deficits in this area are associated with behavioral problems and low literacy skills. Children who are deaf or hard of hearing demonstrate significant delays in this critical area of language. Our purpose with this research was to identify variables associated with pragmatic language ability in children who are deaf or hard of hearing.This was a longitudinal study of 124 children with bilateral hearing loss between 4 and 7 years of age living in Colorado. As part of a comprehensive speech and language assessment, pragmatic language skills were evaluated annually by using the Pragmatics Checklist.The children's pragmatic skills increased significantly with age. Higher levels of pragmatic language ability at 7 years of age were predicted by (1) meeting Early Hearing Detection and Intervention 1-3-6 guidelines (hearing screening by 1 month, identification of hearing loss by 3 months, and receiving intervention by 6 months of age), (2) greater quantity of parent talk, (3) higher nonverbal intelligence, (4) lesser degrees of hearing loss, and (5) higher maternal education.With the findings of this study, we underscore the importance of pediatricians and other health care professionals counseling parents about the value of adherence to the Early Hearing Detection and Intervention 1-3-6 guidelines with regard to intervention outcomes. The strong association between amount of child-directed parent talk in the first 4 years of life and pragmatic language outcomes at 7 years of age emphasizes the need for professionals to encourage parents to talk to their children as much as possible.},
  file = {/Users/eec35/Zotero/storage/PUXS9I6Q/Yoshinaga-Itano et al. - 2020 - Early Intervention, Parent Talk, and Pragmatic Lan.pdf;/Users/eec35/Zotero/storage/MFTYMEX2/Early-Intervention-Parent-Talk-and-Pragmatic.html}
}

@article{yu2012,
  title = {Embodied Attention and Word Learning by Toddlers},
  author = {Yu, Chen and Smith, Linda B.},
  year = {2012},
  month = nov,
  journal = {Cognition},
  volume = {125},
  number = {2},
  pages = {244--262},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2012.06.016},
  urldate = {2022-07-18},
  abstract = {Many theories of early word learning begin with the uncertainty inherent to learning a word from its co-occurrence with a visual scene. However, the relevant visual scene for infant word learning is neither from the adult theorist's view nor the mature partner's view, but is rather from the learner's personal view. Here we show that when 18-month old infants interacted with objects in play with their parents, they created moments in which a single object was visually dominant. If parents named the object during these moments of bottom-up selectivity, later forced-choice tests showed that infants learned the name, but did not when naming occurred during a less visually selective moment. The momentary visual input for parents and toddlers was captured via head cameras placed low on each participant's forehead as parents played with and named objects for their infant. Frame-by-frame analyses of the head camera images at and around naming moments were conducted to determine the visual properties at input that were associated with learning. The analyses indicated that learning occurred when bottom-up visual information was clean and uncluttered. The sensory-motor behaviors of infants and parents were also analyzed to determine how their actions on the objects may have created these optimal visual moments for learning. The results are discussed with respect to early word learning, embodied attention, and the social role of parents in early word learning.},
  langid = {english},
  keywords = {Embodied cognition,Language learning,Perception and action},
  file = {/Users/eec35/Zotero/storage/JQFN96VP/Yu and Smith - 2012 - Embodied attention and word learning by toddlers.pdf;/Users/eec35/Zotero/storage/9H8BQ7EH/S0010027712001369.html}
}

@article{yurovsky2013,
  title = {Statistical Word Learning at Scale: The Baby's View Is Better},
  shorttitle = {Statistical Word Learning at Scale},
  author = {Yurovsky, Daniel and Smith, Linda B. and Yu, Chen},
  year = {2013},
  journal = {Developmental Science},
  volume = {16},
  number = {6},
  pages = {959--966},
  issn = {1467-7687},
  doi = {10.1111/desc.12036},
  urldate = {2023-05-04},
  abstract = {A key question in early word learning is how children cope with the uncertainty in natural naming events. One potential mechanism for uncertainty reduction is cross-situational word learning \textendash{} tracking word/object co-occurrence statistics across naming events. But empirical and computational analyses of cross-situational learning have made strong assumptions about the nature of naming event ambiguity, assumptions that have been challenged by recent analyses of natural naming events. This paper shows that learning from ambiguous natural naming events depends on perspective. Natural naming events from parent\textendash child interactions were recorded from both a third-person tripod-mounted camera and from a head-mounted camera that produced a `child's-eye' view. Following the human simulation paradigm, adults were asked to learn artificial language labels by integrating across the most ambiguous of these naming events. Significant learning was found only from the child's perspective, pointing to the importance of considering statistical learning from an embodied perspective.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/28SE2EB8/Yurovsky et al. - 2013 - Statistical word learning at scale the baby's vie.pdf;/Users/eec35/Zotero/storage/FXJ5K4AY/desc.html}
}

@article{yurovsky2016,
  title = {Linguistic Input Is Tuned to Children's Developmental Level},
  author = {Yurovsky, Daniel and Doyle, Gabriel and Frank, Michael C},
  year = {2016},
  journal = {Cognitive Science},
  pages = {6},
  abstract = {Children rapidly learn a tremendous amount about language despite limitations imposed on them by their developing cognitive abilities. One possible explanation for this rapid learning is that caregivers tune the language they produce to these limitations, titrating the complexity of their speech to developmentally-appropriate levels. We test this hypothesis in a large-scale corpus analysis, measuring the contingency between parents' and children's speech over the first 5 years. Our results support the linguistic tuning hypothesis, showing a high degree of mostly parent-led coordination early in development that decreases as children become more proficient language learners and users.},
  langid = {english},
  file = {/Users/eec35/Zotero/storage/ENK6XPMY/Yurovsky et al. - Linguistic input is tuned to children’s developmen.pdf}
}

@misc{zotero-3547,
  title = {What {{Automated Vocal Analysis Reveals About}} the {{Vocal Production}} and {{Language Learning Environment}} of {{Young Children}} with {{Autism}} | {{SpringerLink}}},
  urldate = {2023-04-04},
  howpublished = {https://link.springer.com/article/10.1007/s10803-009-0902-5},
  file = {/Users/eec35/Zotero/storage/J462WWX6/s10803-009-0902-5.html}
}

@misc{zotero-3781,
  title = {Circumspection in Using Automated Measures: {{Talker}} Gender and Addressee Affect Error Rates for Adult Speech Detection in the {{Language ENvironment Analysis}} ({{LENA}}) System | {{SpringerLink}}},
  urldate = {2023-05-03},
  howpublished = {https://link.springer.com/article/10.3758/s13428-020-01419-y},
  file = {/Users/eec35/Zotero/storage/G87726FK/s13428-020-01419-y.html}
}
